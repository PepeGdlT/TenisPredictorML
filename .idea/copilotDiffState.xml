<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/generate_player_features.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/generate_player_features.py" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/notebooks/predict_tournament.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/notebooks/predict_tournament.ipynb" />
              <option name="originalContent" value="#%%&#10;" />
              <option name="updatedContent" value="{&#10; &quot;cells&quot;: [&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;# Predicción de Partidos del Australian Open 2025&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;Este notebook carga los datos de un torneo específico (en este caso, el Australian Open 2025), genera las features necesarias y utiliza el modelo entrenado para predecir los resultados.&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;import pandas as pd\n&quot;,&#10;    &quot;import numpy as np\n&quot;,&#10;    &quot;import joblib\n&quot;,&#10;    &quot;import json\n&quot;,&#10;    &quot;import sys\n&quot;,&#10;    &quot;import os\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Añadir el directorio src al path para poder importar los módulos\n&quot;,&#10;    &quot;sys.path.append(os.path.abspath('../src'))\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;from preprocess import preprocess_data\n&quot;,&#10;    &quot;from features import (create_elo_features, create_ranking_features, \n&quot;,&#10;    &quot;                      create_head_to_head_features, create_time_features, \n&quot;,&#10;    &quot;                      create_fatigue_features, create_recent_form_features)\n&quot;,&#10;    &quot;from utils import load_config&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 1. Cargar Datos del Torneo&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;tournament_df = pd.read_csv('../data/raw/test/atp_matches_2025.csv')&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 2. Cargar Datos Procesados (ELOs)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;with open('../data/processed/final_global_elos.json', 'r') as f:\n&quot;,&#10;    &quot;    global_elos = json.load(f)\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;with open('../data/processed/final_surface_elos.json', 'r') as f:\n&quot;,&#10;    &quot;    surface_elos = json.load(f)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 3. Preprocesamiento y Generación de Features&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;# Cargar configuración\n&quot;,&#10;    &quot;config = load_config('../src/config.yml')\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Preprocesar datos\n&quot;,&#10;    &quot;data = preprocess_data(tournament_df, config['preprocessing'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Generar Features\n&quot;,&#10;    &quot;data = create_elo_features(data, global_elos, surface_elos)\n&quot;,&#10;    &quot;data = create_ranking_features(data)\n&quot;,&#10;    &quot;data = create_time_features(data)\n&quot;,&#10;    &quot;data = create_head_to_head_features(data)\n&quot;,&#10;    &quot;data = create_fatigue_features(data, config['feature_engineering']['fatigue'])\n&quot;,&#10;    &quot;data = create_recent_form_features(data, config['feature_engineering']['form'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Seleccionar solo las columnas de features\n&quot;,&#10;    &quot;features_df = data[config['model']['features']]\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;print(\&quot;Features generadas exitosamente.\&quot;)\n&quot;,&#10;    &quot;features_df.head()&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 4. Cargar Modelo y Realizar Predicciones&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;# Cargar el modelo entrenado\n&quot;,&#10;    &quot;model = joblib.load('../outputs/models/atp_tennis_predictor.joblib')\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Realizar predicciones\n&quot;,&#10;    &quot;predictions = model.predict(features_df)\n&quot;,&#10;    &quot;prediction_probs = model.predict_proba(features_df)[:, 1] # Probabilidad de que gane el jugador 1&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 5. Comparar Resultados&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;results_df = data[['player_1', 'player_2', 'winner']].copy()\n&quot;,&#10;    &quot;results_df['predicted_winner_code'] = predictions\n&quot;,&#10;    &quot;results_df['p1_win_probability'] = prediction_probs\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Mapear códigos a nombres de jugadores\n&quot;,&#10;    &quot;results_df['predicted_winner'] = np.where(results_df['predicted_winner_code'] == 1, results_df['player_1'], results_df['player_2'])\n&quot;,&#10;    &quot;results_df['actual_winner'] = np.where(results_df['winner'] == 1, results_df['player_1'], results_df['player_2'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Mostrar resultados\n&quot;,&#10;    &quot;comparison_df = results_df[['player_1', 'player_2', 'actual_winner', 'predicted_winner', 'p1_win_probability']]\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;print(\&quot;Tabla de Comparación de Resultados:\&quot;)\n&quot;,&#10;    &quot;comparison_df&quot;&#10;   ]&#10;  }&#10; ],&#10; &quot;metadata&quot;: {&#10;  &quot;kernelspec&quot;: {&#10;   &quot;display_name&quot;: &quot;Python 3&quot;,&#10;   &quot;language&quot;: &quot;python&quot;,&#10;   &quot;name&quot;: &quot;python3&quot;&#10;  },&#10;  &quot;language_info&quot;: {&#10;   &quot;codemirror_mode&quot;: {&#10;    &quot;name&quot;: &quot;ipython&quot;,&#10;    &quot;version&quot;: 3&#10;   },&#10;   &quot;file_extension&quot;: &quot;.py&quot;,&#10;   &quot;mimetype&quot;: &quot;text/x-python&quot;,&#10;   &quot;name&quot;: &quot;python&quot;,&#10;   &quot;nbconvert_exporter&quot;: &quot;python&quot;,&#10;   &quot;pygments_lexer&quot;: &quot;ipython3&quot;,&#10;   &quot;version&quot;: &quot;3.11.0&quot;&#10;  }&#10; },&#10; &quot;nbformat&quot;: 4,&#10; &quot;nbformat_minor&quot;: 4&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/notebooks/si.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/notebooks/si.ipynb" />
              <option name="originalContent" value="#%%&#10;" />
              <option name="updatedContent" value="{&#10; &quot;cells&quot;: [&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;# Tennis Feature Engineering Notebook\n\nEste notebook crea un dataset limpio y balanceado para predicción de partidos de tenis, evitando data leakage y generando las features avanzadas que has pedido.&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 1. Cargar datos raw&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;import pandas as pd\nimport numpy as np\nimport os\nfrom src.data_loader import BASE_DIR\n\n# Cargar todos los datos raw de train y test\ntrain_folder = os.path.join(BASE_DIR, 'data', 'raw', 'train')\ntest_folder = os.path.join(BASE_DIR, 'data', 'raw', 'test')\n\ndef load_all_raw(folder):\n    dfs = []\n    for f in os.listdir(folder):\n        if f.endswith('.csv'):\n            df = pd.read_csv(os.path.join(folder, f))\n            dfs.append(df)\n    return pd.concat(dfs, ignore_index=True)\n\ndf_train_raw = load_all_raw(train_folder)\ndf_test_raw = load_all_raw(test_folder)\nprint('Train shape:', df_train_raw.shape)\nprint('Test shape:', df_test_raw.shape)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 2. Limpiar datos&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;from src.preprocess import clean_data\n\ndf_train = clean_data(df_train_raw)\ndf_test = clean_data(df_test_raw)\nprint('Train limpio:', df_train.shape)\nprint('Test limpio:', df_test.shape)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 3. Ingeniería de features&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;from src.features import add_all_features\n\n# Generar features avanzadas (ELO, H2H, etc.)\ndf_train_feat, final_global_elos, final_surface_elos, final_h2h = add_all_features(df_train)\ndf_test_feat, _, _, _ = add_all_features(df_test, initial_global_elos=final_global_elos, initial_surface_elos=final_surface_elos, initial_h2h=final_h2h)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 4. Crear dataset player_1/player_2 y target aleatorio&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;import random\n\ndef make_player1_player2_rows(df):\n    rows = []\n    for _, row in df.iterrows():\n        if random.random() &lt; 0.5:\n            p1, p2 = row['winner_name'], row['loser_name']\n            target = 1\n        else:\n            p1, p2 = row['loser_name'], row['winner_name']\n            target = 0\n        new_row = row.copy()\n        new_row['player_1'] = p1\n        new_row['player_2'] = p2\n        new_row['target'] = target\n        rows.append(new_row)\n    return pd.DataFrame(rows)\n\ndf_train_final = make_player1_player2_rows(df_train_feat)\ndf_test_final = make_player1_player2_rows(df_test_feat)\nprint('Train final:', df_train_final.shape)\nprint('Test final:', df_test_final.shape)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 5. Selección de features&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;features = [\n    'p_ace', 'p_df', 'p_1stIn', 'p_1stWon', 'p_2ndWon', 'p_bpSaved', 'p_retAceAgainst',\n    'elo_winner', 'elo_loser', 'elo_diff', 'surface_elo_winner', 'surface_elo_loser', 'surface_elo_diff',\n    'elo_advantage', 'surface_elo_advantage', 'elo_surface_interaction', 'elo_consistency',\n    'matches_played', 'matches_surface_played', 'last_k_matches',\n    'h2h_count', 'h2h_balance', 'h2h_surface',\n    # Puedes añadir más features aquí\n]\n\nX_train = df_train_final[features]\ny_train = df_train_final['target']\nX_test = df_test_final[features]\ny_test = df_test_final['target']&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 6. Guardar dataset final&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;output_dir = os.path.join(BASE_DIR, 'data', 'processed')\ndf_train_final.to_csv(os.path.join(output_dir, 'train_final.csv'), index=False)\ndf_test_final.to_csv(os.path.join(output_dir, 'test_final.csv'), index=False)\nprint('Datasets finales guardados.')&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 7. Auditoría de fuga de información&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;from src.audit_leakage import audit_feature_leakage\n\naudit_feature_leakage(X_train, y_train)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 8. Modelado (opcional)\n\nPuedes seguir con el modelado usando el script model.py o añadir una celda aquí para probar modelos.&quot;&#10;   ]&#10;  }&#10; ],&#10; &quot;metadata&quot;: {&#10;  &quot;kernelspec&quot;: {&#10;   &quot;display_name&quot;: &quot;Python 3&quot;,&#10;   &quot;language&quot;: &quot;python&quot;,&#10;   &quot;name&quot;: &quot;python3&quot;&#10;  },&#10;  &quot;language_info&quot;: {&#10;   &quot;name&quot;: &quot;python&quot;,&#10;   &quot;version&quot;: &quot;3.13&quot;&#10;  }&#10; },&#10; &quot;nbformat&quot;: 4,&#10; &quot;nbformat_minor&quot;: 2&#10;}&#10;// ...existing code...&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/notebooks/tennis_feature_engineering.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/notebooks/tennis_feature_engineering.ipynb" />
              <option name="originalContent" value="#%% md&#10;# Tennis Feature Engineering Notebook&#10;&#10;Este notebook crea un dataset limpio y balanceado para predicción de partidos de tenis, evitando data leakage y generando las features avanzadas que has pedido.&#10;#%% md&#10;## 1. Cargar datos raw usando data_loader&#10;#%%&#10;# Imports globales para todo el notebook&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;import random&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import pickle&#10;from pathlib import Path&#10;&#10;# Imports del proyecto&#10;from src.data_loader import load_and_preprocess_data&#10;from src.features import add_all_features, get_curated_features, export_pca_report, diagnose_pca_group&#10;from src.audit_leakage import check_index_overlap, check_temporal_split, compare_feature_distributions, quick_permutation_target_test, feature_shuffle_ablation, audit_feature_leakage&#10;from src.enhanced_validation import comprehensive_model_audit, advanced_temporal_validation, stability_analysis, feature_importance_stability&#10;&#10;# ML imports&#10;from xgboost import XGBClassifier&#10;from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit&#10;from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss, brier_score_loss&#10;from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.naive_bayes import GaussianNB&#10;from sklearn.calibration import CalibratedClassifierCV&#10;from sklearn.impute import SimpleImputer&#10;&#10;&#10;plt.style.use('seaborn-v0_8')&#10;sns.set_palette(&quot;husl&quot;)&#10;&#10;# Usar el data_loader para cargar y limpiar datos&#10;print(&quot; Cargando y procesando datos con data_loader...&quot;)&#10;df_train, df_test = load_and_preprocess_data()&#10;print(f' Train shape: {df_train.shape}')&#10;print(f' Test shape: {df_test.shape}')&#10;#%% md&#10;## 2. Ingeniería de features MEJORADA&#10;#%%&#10;# Train: calcula históricos con features mejoradas de fatiga y sin FutureWarnings&#10;print(' Calculando features históricas para TRAIN...')&#10;(df_train_final, df_train_full, final_global_elos, final_surface_elos, final_h2h, final_stats, pca_state) = add_all_features(&#10;    df_train,&#10;    mode=&quot;train&quot;,&#10;    fast=False,  # Usar VIF completo para mejor limpieza&#10;    return_pca_state=True,&#10;    return_full=True&#10;)&#10;print('✅ Features históricas TRAIN calculadas.')&#10;&#10;print(' Calculando features históricas para TEST...')&#10;(df_test_final, df_test_full, _, _, _, _) = add_all_features(&#10;    df_test,&#10;    initial_global_elos=final_global_elos,&#10;    initial_surface_elos=final_surface_elos,&#10;    initial_h2h=final_h2h,&#10;    initial_stats=final_stats,&#10;    mode=&quot;inference&quot;,&#10;    fast=False,&#10;    pca_state=pca_state,&#10;    randomize_players=True,  # Balancear labels en test también&#10;    return_pca_state=False,&#10;    return_full=True&#10;)&#10;print('✅ Features históricas TEST calculadas.')&#10;&#10;#%% md&#10;### 3.1 Reporte PCA y diagnóstico de grupos clave MEJORADO&#10;#%%&#10;pca_report = export_pca_report(pca_state)&#10;print(&quot; Reporte PCA por grupo:&quot;)&#10;display(pca_report.sort_values('pc1_var', ascending=False))&#10;&#10;# Diagnóstico de grupos clave con nuevas features de fatiga&#10;try:&#10;    print('\n Diagnóstico grupo fatigue (features combinadas):')&#10;    fatigue_diag = diagnose_pca_group(df_train_final, 'fatigue', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;    print(f&quot;   - Top loadings PC1: {fatigue_diag['pc1_loadings_sorted'][:3]}&quot;)&#10;&#10;    print('\n Diagnóstico grupo fatigue_raw:')&#10;    fatigue_raw_diag = diagnose_pca_group(df_train_final, 'fatigue_raw', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_raw_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_raw_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;    print('\n Diagnóstico grupo fatigue_individual:')&#10;    fatigue_ind_diag = diagnose_pca_group(df_train_final, 'fatigue_individual', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_ind_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_ind_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;    print('\n Diagnóstico grupo elo_core:')&#10;    elo_diag = diagnose_pca_group(df_train_final, 'elo_core', pca_state)&#10;    print(f&quot;   - Componentes: {elo_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {elo_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;except Exception as e:&#10;    print(f'⚠️ Error diagnóstico PCA: {e}')&#10;#%% md&#10;## 4. Selección de features&#10;#%%&#10;features = get_curated_features(df_train_final)&#10;features = [f for f in features if f in df_test_final.columns and f in df_train_final.columns]&#10;print(f'Features seleccionadas. Total: {len(features)}')&#10;&#10;# Reasignar matrices de entrenamiento/test&#10;X_train = df_train_final[features]&#10;X_test = df_test_final[features]&#10;y_train = df_train_final['target']&#10;y_test = df_test_final['target']&#10;print(f&quot;Shapes -&gt; X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}&quot;)&#10;#%% md&#10;## 5. Guardar dataset final&#10;#%%&#10;from src.data_loader import BASE_DIR&#10;&#10;output_dir = os.path.join(BASE_DIR, 'data', 'processed')&#10;os.makedirs(output_dir, exist_ok=True)&#10;df_train_final.to_csv(os.path.join(output_dir, 'train_final.csv'), index=False)&#10;df_test_final.to_csv(os.path.join(output_dir, 'test_final.csv'), index=False)&#10;df_train_full.to_csv(os.path.join(output_dir, 'train_full.csv'), index=False)&#10;df_test_full.to_csv(os.path.join(output_dir, 'test_full.csv'), index=False)&#10;print('✅ Datasets finales guardados.')&#10;#%% md&#10;## 6. AUDITORÍA AVANZADA DE FUGA DE INFORMACIÓN&#10;#%%&#10;# Construir índices para validación temporal&#10;_df_train_full = df_train_full.copy()&#10;_df_test_full = df_test_full.copy()&#10;_df_train_full['__split'] = 'train'&#10;_df_test_full['__split'] = 'test'&#10;_df_all_full = pd.concat([_df_train_full, _df_test_full], ignore_index=True)&#10;train_idx = _df_all_full.index[_df_all_full['__split'] == 'train']&#10;test_idx = _df_all_full.index[_df_all_full['__split'] == 'test']&#10;&#10;print(&quot; AUDITORÍA COMPLETA DE DATA LEAKAGE&quot;)&#10;print(&quot;=&quot; * 50)&#10;&#10;# 1. Verificaciones básicas&#10;check_index_overlap(df_train_final, df_test_final)&#10;check_temporal_split(_df_all_full, train_idx, test_idx)&#10;&#10;# 2. Auditoría de correlaciones&#10;X_leak_audit = df_train_final.drop(columns=['target'], errors='ignore').select_dtypes(include=[np.number])&#10;corrs = audit_feature_leakage(X_leak_audit, y_train)&#10;&#10;# 3. Comparación de distribuciones de features top&#10;top_feats = corrs.head(20).index.tolist()&#10;print(f&quot;\n Comparando distribuciones de top {len(top_feats[:10])} features:&quot;)&#10;compare_feature_distributions(df_train_final, df_test_final, top_feats[:10])&#10;&#10;# 4. Test de permutación de target&#10;print(f&quot;\n Test de permutación de target:&quot;)&#10;model_base = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,&#10;                          eval_metric='logloss', random_state=42)&#10;quick_permutation_target_test(model_base,&#10;                              X_train, y_train, X_test, y_test,&#10;                              n_trials=1, random_state=42)&#10;&#10;# 5. Feature shuffle ablation&#10;print(f&quot;\n Ablación por shuffle de top features:&quot;)&#10;feature_shuffle_ablation(model_base, X_train, y_train, X_test, y_test,&#10;                         top_features=top_feats[:5], random_state=42)&#10;#%% md&#10;## 7. VALIDACIÓN TEMPORAL AVANZADA&#10;#%%&#10;print(&quot; VALIDACIÓN TEMPORAL AVANZADA&quot;)&#10;print(&quot;=&quot; * 40)&#10;&#10;# Detectar columna de fechas&#10;date_col = None&#10;for col in ['tourney_date', 'match_date', 'date']:&#10;    if col in df_train_full.columns:&#10;        date_col = col&#10;        break&#10;&#10;if date_col is not None:&#10;    train_dates = df_train_full[date_col]&#10;&#10;    # Validación temporal con múltiples splits&#10;    print(&quot;\n Validación con múltiples ventanas temporales:&quot;)&#10;    temporal_results = advanced_temporal_validation(&#10;        X_train, y_train, train_dates, model_base, n_splits=5, test_months=3&#10;    )&#10;&#10;    if not temporal_results.empty:&#10;        print(&quot;\nResultados por split temporal:&quot;)&#10;        display(temporal_results)&#10;        print(f&quot;\n Resumen:&quot;)&#10;        print(f&quot;   - AUC promedio: {temporal_results['auc'].mean():.4f} ±{temporal_results['auc'].std():.4f}&quot;)&#10;        print(f&quot;   - LogLoss promedio: {temporal_results['logloss'].mean():.4f} ±{temporal_results['logloss'].std():.4f}&quot;)&#10;        print(f&quot;   - Rango AUC: [{temporal_results['auc'].min():.4f}, {temporal_results['auc'].max():.4f}]&quot;)&#10;&#10;        # Alerta si hay caída significativa de performance&#10;        auc_drop = temporal_results['auc'].max() - temporal_results['auc'].min()&#10;        if auc_drop &gt; 0.05:&#10;            print(f&quot;⚠️  ALERTA: Caída de AUC de {auc_drop:.3f} entre splits - posible overfitting temporal&quot;)&#10;    else:&#10;        print(&quot;❌ No se pudieron crear splits temporales válidos&quot;)&#10;else:&#10;    print(&quot;❌ No se encontró columna de fecha para validación temporal&quot;)&#10;&#10;# Análisis de estabilidad con bootstrap&#10;print(f&quot;\n Análisis de estabilidad (Bootstrap):&quot;)&#10;stability_results = stability_analysis(X_train, y_train, model_base, n_bootstrap=20)&#10;print(f&quot;   - AUC medio: {stability_results['mean_auc']:.4f} ±{stability_results['std_auc']:.4f}&quot;)&#10;print(f&quot;   - Rango: [{stability_results['min_auc']:.4f}, {stability_results['max_auc']:.4f}]&quot;)&#10;&#10;if stability_results['std_auc'] &gt; 0.02:&#10;    print(f&quot;⚠️  ALERTA: Alta variabilidad ({stability_results['std_auc']:.3f}) - modelo inestable&quot;)&#10;&#10;# Estabilidad de feature importance&#10;print(f&quot;\n Estabilidad de Feature Importance:&quot;)&#10;feat_stability = feature_importance_stability(X_train, y_train, model_base, n_iterations=15)&#10;print(&quot;Top 10 features más estables (menor coeficiente de variación):&quot;)&#10;display(feat_stability.head(10)[['mean', 'std', 'cv']])&#10;&#10;highly_unstable = feat_stability[feat_stability['cv'] &gt; 0.5]&#10;if len(highly_unstable) &gt; 0:&#10;    print(f&quot;⚠️  Features muy inestables (CV &gt; 0.5): {len(highly_unstable)}&quot;)&#10;#%% md&#10;## 8. Grid Search CON VALIDACIÓN TEMPORAL&#10;#%%&#10;print(&quot; Realizando Grid Search para XGBoost con validación temporal...&quot;)&#10;param_grid = {&#10;    'n_estimators': [100, 200, 300],&#10;    'max_depth': [6, 8, 10],&#10;    'learning_rate': [0.05, 0.1, 0.15],&#10;    'subsample': [0.8, 0.9],&#10;    'colsample_bytree': [0.5, 0.7],&#10;}&#10;&#10;xgb_base = XGBClassifier(&#10;    random_state=42,&#10;    eval_metric='logloss',&#10;    reg_alpha=0.3,   # L1&#10;    reg_lambda=1.0,   # L2&#10;    min_child_weight=3&#10;)&#10;tscv = TimeSeriesSplit(n_splits=5)&#10;grid_search = GridSearchCV(&#10;    xgb_base,&#10;    param_grid,&#10;    cv=tscv,&#10;    scoring='neg_log_loss',   # o 'roc_auc'&#10;    n_jobs=-1,&#10;    verbose=1&#10;)&#10;&#10;grid_search.fit(X_train, y_train)&#10;&#10;print(f&quot;Mejores parámetros: {grid_search.best_params_}&quot;)&#10;print(f&quot;Mejor CV score (log loss): {grid_search.best_score_:.4f}&quot;)&#10;#%% md&#10;## 9. Entrenamiento del Modelo Optimizado&#10;#%%&#10;# 1. Reemplazar infinitos por NaN&#10;X_train = X_train.replace([np.inf, -np.inf], np.nan)&#10;X_test = X_test.replace([np.inf, -np.inf], np.nan)&#10;&#10;# 2. Pipeline con imputación por media&#10;imputer = SimpleImputer(strategy=&quot;mean&quot;)&#10;X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)&#10;X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)&#10;print(&quot;Tras imputación -&gt; X_train filas:&quot;, len(X_train), &quot;X_test filas:&quot;, len(X_test))&#10;&#10;# 3. Entrenar modelo optimizado con mejores hiperparámetros encontrados&#10;best_model = XGBClassifier(**grid_search.best_params_, random_state=42, eval_metric='logloss')&#10;best_model.fit(X_train, y_train)&#10;&#10;# 4. Predicciones&#10;y_pred_optimized = best_model.predict(X_test)&#10;y_proba_optimized = best_model.predict_proba(X_test)[:, 1]&#10;&#10;# 5. Métricas principales&#10;acc_optimized = accuracy_score(y_test, y_pred_optimized)&#10;auc_optimized = roc_auc_score(y_test, y_proba_optimized)&#10;logloss = log_loss(y_test, y_proba_optimized)&#10;brier = brier_score_loss(y_test, y_proba_optimized)&#10;&#10;print(f&quot;Modelo optimizado - Accuracy: {acc_optimized:.4f}, AUC: {auc_optimized:.4f}, &quot;&#10;      f&quot;LogLoss: {logloss:.4f}, Brier: {brier:.4f}&quot;)&#10;&#10;# 6. Calibrar probabilidades (para apuestas / probas realistas)&#10;tscv = TimeSeriesSplit(n_splits=3)&#10;calibrated_model = CalibratedClassifierCV(best_model, method=&quot;isotonic&quot;, cv=tscv)&#10;calibrated_model.fit(X_train, y_train)&#10;&#10;y_proba_cal = calibrated_model.predict_proba(X_test)[:, 1]&#10;logloss_cal = log_loss(y_test, y_proba_cal)&#10;brier_cal = brier_score_loss(y_test, y_proba_cal)&#10;&#10;print(f&quot;Modelo calibrado - LogLoss: {logloss_cal:.4f}, Brier: {brier_cal:.4f}&quot;)&#10;#%% md&#10;## 10. Comparación de Algoritmos&#10;#%%&#10;models = {&#10;    'XGBoost Optimizado': best_model,&#10;    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),&#10;    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42),&#10;    'Logistic Regression': LogisticRegression(max_iter=5500, random_state=42),&#10;    'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),&#10;    'Naive Bayes': GaussianNB()&#10;}&#10;results = []&#10;for name, model in models.items():&#10;    print(f&quot;Entrenando {name}...&quot;)&#10;    if name != 'XGBoost Optimizado':&#10;        model.fit(X_train, y_train)&#10;    y_pred = model.predict(X_test)&#10;    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None&#10;    acc = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None&#10;    results.append({'Modelo': name, 'Accuracy': acc, 'AUC': auc if auc else 'N/A'})&#10;results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)&#10;print(&quot;\nResultados de comparación:&quot;)&#10;print(results_df.round(4))&#10;#%% md&#10;## 11. Visualización de Resultados de Modelos&#10;#%%&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 6))&#10;numeric_results = results_df[results_df['AUC'] != 'N/A'].copy()&#10;numeric_results['AUC'] = pd.to_numeric(numeric_results['AUC'])&#10;axes[0].barh(numeric_results['Modelo'], numeric_results['Accuracy'], alpha=0.8)&#10;axes[0].set_title('Comparación de Accuracy', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Accuracy')&#10;axes[0].grid(True, alpha=0.3, axis='x')&#10;axes[1].barh(numeric_results['Modelo'], numeric_results['AUC'], alpha=0.8, color='orange')&#10;axes[1].set_title('Comparación de AUC', fontsize=14, pad=20)&#10;axes[1].set_xlabel('AUC')&#10;axes[1].grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;#%% md&#10;## 12. Ensemble de Modelos&#10;#%%&#10;ensemble = VotingClassifier(estimators=[&#10;    ('xgb', best_model),&#10;    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),&#10;    ('gb', GradientBoostingClassifier(n_estimators=200, max_depth=8, random_state=42))&#10;], voting='soft')&#10;ensemble.fit(X_train, y_train)&#10;y_pred_ensemble = ensemble.predict(X_test)&#10;y_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]&#10;acc_ensemble = accuracy_score(y_test, y_pred_ensemble)&#10;auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)&#10;print(f&quot;Ensemble - Accuracy: {acc_ensemble:.4f}, AUC: {auc_ensemble:.4f}&quot;)&#10;print(f&quot;Mejora sobre mejor modelo individual: +{acc_ensemble - acc_optimized:.4f}&quot;)&#10;#%% md&#10;## 13.  Análisis de Features e Interpretabilidad&#10;&#10;#%%&#10;# Importancia de features&#10;importances = best_model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': X_train.columns,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;# Normalización y acumulado&#10;feature_importance_df['Normalized'] = feature_importance_df['Importance'] / feature_importance_df['Importance'].sum()&#10;feature_importance_df['Cumulative'] = feature_importance_df['Normalized'].cumsum()&#10;&#10;# Visualización top 12&#10;plt.figure(figsize=(12, 8))&#10;top_features = feature_importance_df.head(12)&#10;sns.barplot(data=top_features, x='Importance', y='Feature')&#10;plt.title('Importancia de features en el modelo optimizado', fontsize=16, pad=20)&#10;plt.xlabel('Importancia Relativa')&#10;plt.ylabel('Feature')&#10;plt.grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;# Imprimir ranking&#10;print(&quot;Top 20 Features más importantes:&quot;)&#10;print(feature_importance_df.head(20).round(4))&#10;&#10;# Análisis de concentración&#10;n_features_80 = (feature_importance_df['Cumulative'] &lt;= 0.8).sum() + 1&#10;n_features_95 = (feature_importance_df['Cumulative'] &lt;= 0.95).sum() + 1&#10;&#10;print(f&quot;\nAnálisis de concentración:&quot;)&#10;print(f&quot;   {n_features_80} features explican el 80% de la importancia&quot;)&#10;print(f&quot;   {n_features_95} features explican el 95% de la importancia&quot;)&#10;#%% md&#10;### 14. Análisis de Errores del Modelo&#10;&#10;#%%&#10;# análisis detallado de errores&#10;# Usar el dataframe de test final para el análisis de errores&#10;if 'df_test_final' in locals():&#10;    df_test_analysis = df_test_final.copy()&#10;&#10;df_test_analysis['pred'] = y_pred_optimized&#10;df_test_analysis['pred_proba'] = y_proba_optimized&#10;df_test_analysis['correct'] = (df_test_analysis['pred'] == df_test_analysis['target'])&#10;&#10;# estadísticas de errores&#10;total_errors = (~df_test_analysis['correct']).sum()&#10;error_rate = total_errors / len(df_test_analysis)&#10;&#10;print(f&quot;análisis de errores:&quot;)&#10;print(f&quot;   total errores: {total_errors:,} de {len(df_test_analysis):,} ({error_rate:.2%})&quot;)&#10;&#10;# tipos de errores&#10;false_positives = len(df_test_analysis[(df_test_analysis['target'] == 0) &amp; (df_test_analysis['pred'] == 1)])&#10;false_negatives = len(df_test_analysis[(df_test_analysis['target'] == 1) &amp; (df_test_analysis['pred'] == 0)])&#10;&#10;print(f&quot;   falsos positivos: {false_positives:,}&quot;)&#10;print(f&quot;   falsos negativos: {false_negatives:,}&quot;)&#10;&#10;# análisis por confianza de predicción&#10;confidence_bins = pd.cut(df_test_analysis['pred_proba'], bins=[0, 0.3, 0.7, 1.0], labels=['Baja', 'Media', 'Alta'])&#10;confidence_accuracy = df_test_analysis.groupby(confidence_bins, observed=False)['correct'].agg(['count', 'mean']).round(4)&#10;&#10;print(f&quot;accuracy por nivel de confianza:&quot;)&#10;print(confidence_accuracy)&#10;&#10;# matriz de confusión mejorada&#10;plt.figure(figsize=(8, 6))&#10;cm = confusion_matrix(y_test, y_pred_optimized)&#10;sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',&#10;           xticklabels=['Perdedor Predicho', 'Ganador Predicho'],&#10;           yticklabels=['Perdedor Real', 'Ganador Real'])&#10;plt.title('matriz de confusión del modelo optimizado', fontsize=14, pad=20)&#10;plt.ylabel('Valor Real')&#10;plt.xlabel('Predicción')&#10;plt.tight_layout()&#10;plt.show()&#10;#%% md&#10;## 15. Guardar Modelo y Estados en Outputs&#10;&#10;#%%&#10;# Crear directorio outputs si no existe&#10;outputs_dir = Path('../outputs')&#10;outputs_dir.mkdir(exist_ok=True)&#10;&#10;print(&quot; Guardando modelo y estados en outputs/...&quot;)&#10;&#10;# 1. Guardar el mejor modelo entrenado&#10;print(&quot; Guardando modelo XGBoost optimizado...&quot;)&#10;with open(outputs_dir / 'best_xgb_model.pkl', 'wb') as f:&#10;    pickle.dump(best_model, f)&#10;&#10;# 2. Guardar modelo calibrado&#10;print(&quot; Guardando modelo calibrado...&quot;)&#10;with open(outputs_dir / 'calibrated_model.pkl', 'wb') as f:&#10;    pickle.dump(calibrated_model, f)&#10;&#10;# 3. Guardar ensemble&#10;print(&quot; Guardando ensemble...&quot;)&#10;with open(outputs_dir / 'ensemble_model.pkl', 'wb') as f:&#10;    pickle.dump(ensemble, f)&#10;&#10;# 4. Guardar imputer para preprocessing&#10;print(&quot; Guardando imputer...&quot;)&#10;with open(outputs_dir / 'imputer.pkl', 'wb') as f:&#10;    pickle.dump(imputer, f)&#10;&#10;# 5. Guardar estados históricos para la aplicación web&#10;print(&quot; Guardando estados históricos...&quot;)&#10;training_states = {&#10;    'final_global_elos': final_global_elos,&#10;    'final_surface_elos': final_surface_elos,&#10;    'final_h2h': final_h2h,&#10;    'final_stats': final_stats,&#10;    'pca_state': pca_state,&#10;    'feature_columns': features,&#10;    'model_metrics': {&#10;        'accuracy': acc_optimized,&#10;        'auc': auc_optimized,&#10;        'logloss': logloss,&#10;        'brier': brier,&#10;        'accuracy_ensemble': acc_ensemble,&#10;        'auc_ensemble': auc_ensemble&#10;    },&#10;    'best_params': grid_search.best_params_&#10;}&#10;&#10;with open(outputs_dir / 'training_states.pkl', 'wb') as f:&#10;    pickle.dump(training_states, f)&#10;&#10;# 6. Guardar lista de jugadores únicos para la app web&#10;print(&quot; Guardando lista de jugadores...&quot;)&#10;all_players = set()&#10;for df in [df_train_full, df_test_full]:&#10;    if 'player_1' in df.columns:&#10;        all_players.update(df['player_1'].dropna().unique())&#10;    if 'player_2' in df.columns:&#10;        all_players.update(df['player_2'].dropna().unique())&#10;    # También buscar en formato winner/loser&#10;    if 'winner_name' in df.columns:&#10;        all_players.update(df['winner_name'].dropna().unique())&#10;    if 'loser_name' in df.columns:&#10;        all_players.update(df['loser_name'].dropna().unique())&#10;&#10;players_list = sorted(list(all_players))&#10;&#10;with open(outputs_dir / 'players_list.pkl', 'wb') as f:&#10;    pickle.dump(players_list, f)&#10;&#10;# 6.5. NUEVO: Guardar features más recientes de cada jugador&#10;print(&quot; Extrayendo y guardando features más recientes de cada jugador...&quot;)&#10;&#10;def extract_latest_player_features(df_model, df_full, features_list, players_list):&#10;    &quot;&quot;&quot;&#10;    Extraer las features más recientes para cada jugador único&#10;    CORREGIDO: Para usar las columnas reales de los datos&#10;    &quot;&quot;&quot;&#10;    player_features = {}&#10;&#10;    # Combinar ambos DataFrames para tener todo el histórico&#10;    combined_df_model = pd.concat([df_train_final, df_test_final], ignore_index=True)&#10;    combined_df_full = pd.concat([df_train_full, df_test_full], ignore_index=True)&#10;&#10;    # Asegurar que hay una columna de orden temporal&#10;    if 'tourney_date' not in combined_df_full.columns:&#10;        # Usar índice como proxy de orden temporal&#10;        combined_df_full['temp_order'] = combined_df_full.index&#10;        sort_col = 'temp_order'&#10;    else:&#10;        sort_col = 'tourney_date'&#10;        combined_df_full['tourney_date'] = pd.to_datetime(combined_df_full['tourney_date'], errors='coerce')&#10;        combined_df_full = combined_df_full.sort_values('tourney_date')&#10;        combined_df_model = combined_df_model.iloc[combined_df_full.index]&#10;&#10;    print(f&quot;   Procesando {len(players_list)} jugadores únicos...&quot;)&#10;&#10;    for i, player in enumerate(players_list):&#10;        if i % 500 == 0:&#10;            print(f&quot;   Procesado {i}/{len(players_list)} jugadores...&quot;)&#10;&#10;        # Buscar las filas más recientes donde aparece el jugador&#10;        player_rows = []&#10;&#10;        # CORREGIDO: Usar las columnas reales que existen&#10;        # Como player_1 (en df_full)&#10;        if 'player_1' in combined_df_full.columns:&#10;            mask = combined_df_full['player_1'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(combined_df_full[mask].index.tolist())&#10;&#10;        # Como player_2 (en df_full)&#10;        if 'player_2' in combined_df_full.columns:&#10;            mask = combined_df_full['player_2'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(combined_df_full[mask].index.tolist())&#10;&#10;        if not player_rows:&#10;            # Jugador no encontrado, usar features neutras&#10;            model_features = {col: 0.0 for col in features_list}&#10;            metadata = {&#10;                'last_match_date': None,&#10;                'total_matches': 0,&#10;                'global_elo': 1500,&#10;                'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500}&#10;            }&#10;        else:&#10;            # Obtener la fila más reciente&#10;            latest_idx = max(player_rows)&#10;&#10;            # Extraer features del modelo (df_model) - verificar que el índice existe&#10;            if latest_idx &lt; len(combined_df_model):&#10;                model_row = combined_df_model.iloc[latest_idx]&#10;&#10;                # Extraer solo las features que usa el modelo&#10;                model_features = {}&#10;                for feature in features_list:&#10;                    if feature in model_row:&#10;                        value = model_row[feature]&#10;                        try:&#10;                            if pd.notna(value) and np.isfinite(float(value)):&#10;                                model_features[feature] = float(value)&#10;                            else:&#10;                                model_features[feature] = 0.0&#10;                        except (ValueError, TypeError):&#10;                            model_features[feature] = 0.0&#10;                    else:&#10;                        model_features[feature] = 0.0&#10;            else:&#10;                # Fallback: features en cero&#10;                model_features = {col: 0.0 for col in features_list}&#10;&#10;            # Metadata adicional del df_full&#10;            if latest_idx &lt; len(combined_df_full):&#10;                full_row = combined_df_full.iloc[latest_idx]&#10;&#10;                # CORREGIDO: Usar nombres de columnas correctos&#10;                metadata = {&#10;                    'last_match_date': str(full_row.get('tourney_date', '')),&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': full_row.get('elo_p1', 1500) if 'elo_p1' in full_row else 1500,&#10;                    'surface_elos': {&#10;                        'hard': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,&#10;                        'clay': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,  # No hay específica por superficie&#10;                        'grass': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,&#10;                    },&#10;                    'last_tournament': full_row.get('tourney_name', 'Unknown'),&#10;                    'last_surface': full_row.get('surface', 'Unknown'),&#10;                    'last_opponent': full_row.get('player_2' if 'player_1' in combined_df_full.columns and player in str(full_row.get('player_1', '')) else 'player_1', 'Unknown')&#10;                }&#10;            else:&#10;                metadata = {&#10;                    'last_match_date': None,&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': 1500,&#10;                    'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500},&#10;                    'last_tournament': 'Unknown',&#10;                    'last_surface': 'Unknown',&#10;                    'last_opponent': 'Unknown'&#10;                }&#10;&#10;        player_features[player] = {&#10;            'model_features': model_features,&#10;            'metadata': metadata&#10;        }&#10;&#10;    return player_features&#10;&#10;# Extraer features para todos los jugadores&#10;player_features = extract_latest_player_features(&#10;    df_train_final, df_train_full, features, players_list&#10;)&#10;&#10;# Guardar archivo de features de jugadores&#10;print(&quot; Guardando features de jugadores...&quot;)&#10;with open(outputs_dir / 'player_features.pkl', 'wb') as f:&#10;    pickle.dump(player_features, f)&#10;&#10;# Guardar también en CSV para inspección&#10;print(&quot; Guardando CSV de inspección...&quot;)&#10;player_df_list = []&#10;for player, features_dict in player_features.items():&#10;    row = {'player_name': player}&#10;    row.update(features_dict['model_features'])&#10;    row.update({&#10;        'last_match_date': features_dict['metadata']['last_match_date'],&#10;        'total_matches': features_dict['metadata']['total_matches'],&#10;        'global_elo': features_dict['metadata']['global_elo'],&#10;        'surface_elos': str(features_dict['metadata']['surface_elos'])&#10;    })&#10;    player_df_list.append(row)&#10;&#10;player_df = pd.DataFrame(player_df_list)&#10;player_df.to_csv(outputs_dir / 'player_features.csv', index=False)&#10;&#10;print(f&quot;✅ Features de jugadores guardadas: {len(player_features)} jugadores&quot;)&#10;print(f&quot; Archivos creados: player_features.pkl, player_features.csv&quot;)&#10;&#10;#%% md&#10;## 16. Resumen Ejecutivo y Conclusiones&#10;&#10;#%%&#10;# resumen final del proyecto&#10;print(&quot;=&quot; * 80)&#10;print(&quot;resumen ejecutivo - tennis match predictor&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;# Adaptación de variables para robustez&#10;train_df = df_train_final if 'df_train_final' in locals() else df_train_full&#10;&#10;test_df = df_test_final if 'df_test_final' in locals() else df_test_full&#10;&#10;# Features disponibles&#10;features_list = features if 'features' in locals() else (&#10;    features if 'available_features' in locals() else train_df.columns.tolist()&#10;)&#10;&#10;print(f&quot;\ndatos procesados:&quot;)&#10;if 'tourney_date' in train_df.columns and 'tourney_date' in test_df.columns:&#10;    print(f&quot;   período de entrenamiento: {pd.to_datetime(train_df['tourney_date'], errors='coerce').dt.year.min()}-{pd.to_datetime(train_df['tourney_date'], errors='coerce').dt.year.max()}&quot;)&#10;    print(f&quot;   período de test: {pd.to_datetime(test_df['tourney_date'], errors='coerce').dt.year.min()}-{pd.to_datetime(test_df['tourney_date'], errors='coerce').dt.year.max()}&quot;)&#10;print(f&quot;   total partidos analizados: {len(train_df) + len(test_df):,}&quot;)&#10;print(f&quot;   features engineered: {len(features_list)}&quot;)&#10;&#10;print(f&quot;\nrendimiento del modelo:&quot;)&#10;print(f&quot;   mejor modelo: XGBoost optimizado&quot;)&#10;print(f&quot;   accuracy: {acc_optimized:.4f} ({acc_optimized:.1%})&quot;)&#10;print(f&quot;   AUC: {auc_optimized:.4f}&quot;)&#10;print(f&quot;   ensemble accuracy: {acc_ensemble:.4f} ({(acc_ensemble-acc_optimized)*100:+.2f}% mejora)&quot;)&#10;&#10;print(f&quot;\nfeatures más importantes:&quot;)&#10;if 'feature_importance_df' in locals():&#10;    top_5_features = feature_importance_df.head(5)&#10;    for idx, row in top_5_features.iterrows():&#10;        print(f&quot;   {idx+1}. {row['Feature']}: {row['Importance']:.3f} ({row['Importance']:.1%})&quot;)&#10;else:&#10;    print(&quot;   (No se encontró feature_importance_df)&quot;)&#10;&#10;print(f&quot;\ninsights clave:&quot;)&#10;print(f&quot;   las features categóricas (elo_advantage, tier_diff) son más predictivas&quot;)&#10;print(f&quot;   el ranking ATP es más informativo que el ELO calculado&quot;)&#10;print(f&quot;   el H2H tiene impacto mínimo en predicciones generales&quot;)&#10;print(f&quot;   los Big 3 muestran patrones únicos de dominancia por superficie&quot;)&#10;print(f&quot;   el modelo es altamente preciso (~99%) para datos históricos&quot;)&#10;&#10;print(f&quot;\nrecomendaciones:&quot;)&#10;print(f&quot;   usar XGBoost optimizado para predicciones en producción&quot;)&#10;print(f&quot;   enfocar feature engineering en rankings y diferencias de nivel&quot;)&#10;print(f&quot;   considerar factores temporales para predicciones futuras&quot;)&#10;print(f&quot;   validar con datos de torneos 2025 cuando estén disponibles&quot;)&#10;&#10;print(f&quot;\naplicaciones:&quot;)&#10;print(f&quot;   sistema de predicción en tiempo real&quot;)&#10;print(f&quot;   análisis para casas de apuestas&quot;)&#10;print(f&quot;   comentarios deportivos automatizados&quot;)&#10;print(f&quot;   análisis estratégico para jugadores/entrenadores&quot;)&#10;&#10;print(&quot;=&quot; * 80)&#10;print(&quot;¡proyecto completado exitosamente!&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;#%%&#10;" />
              <option name="updatedContent" value="#%% md&#10;# Tennis Feature Engineering Notebook&#10;&#10;Este notebook crea un dataset limpio y balanceado para predicción de partidos de tenis, evitando data leakage y generando las features avanzadas que has pedido.&#10;#%% md&#10;## 1. Cargar datos raw usando data_loader&#10;#%%&#10;# Imports globales para todo el notebook&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;import random&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import pickle&#10;from pathlib import Path&#10;&#10;# Imports del proyecto&#10;from src.data_loader import load_and_preprocess_data&#10;from src.features import add_all_features, get_curated_features, export_pca_report, diagnose_pca_group&#10;from src.audit_leakage import check_index_overlap, check_temporal_split, compare_feature_distributions, quick_permutation_target_test, feature_shuffle_ablation, audit_feature_leakage&#10;from src.enhanced_validation import comprehensive_model_audit, advanced_temporal_validation, stability_analysis, feature_importance_stability&#10;&#10;# ML imports&#10;from xgboost import XGBClassifier&#10;from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit&#10;from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss, brier_score_loss&#10;from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.naive_bayes import GaussianNB&#10;from sklearn.calibration import CalibratedClassifierCV&#10;from sklearn.impute import SimpleImputer&#10;&#10;&#10;plt.style.use('seaborn-v0_8')&#10;sns.set_palette(&quot;husl&quot;)&#10;&#10;# Usar el data_loader para cargar y limpiar datos&#10;print(&quot; Cargando y procesando datos con data_loader...&quot;)&#10;df_train, df_test = load_and_preprocess_data()&#10;print(f' Train shape: {df_train.shape}')&#10;print(f' Test shape: {df_test.shape}')&#10;#%% md&#10;## 2. Ingeniería de features MEJORADA&#10;#%%&#10;# Train: calcula históricos con features mejoradas de fatiga y sin FutureWarnings&#10;print(' Calculando features históricas para TRAIN...')&#10;(df_train_final, df_train_full, final_global_elos, final_surface_elos, final_h2h, final_stats, pca_state) = add_all_features(&#10;    df_train,&#10;    mode=&quot;train&quot;,&#10;    fast=False,  # Usar VIF completo para mejor limpieza&#10;    return_pca_state=True,&#10;    return_full=True&#10;)&#10;print('✅ Features históricas TRAIN calculadas.')&#10;&#10;print(' Calculando features históricas para TEST...')&#10;(df_test_final, df_test_full, _, _, _, _) = add_all_features(&#10;    df_test,&#10;    initial_global_elos=final_global_elos,&#10;    initial_surface_elos=final_surface_elos,&#10;    initial_h2h=final_h2h,&#10;    initial_stats=final_stats,&#10;    mode=&quot;inference&quot;,&#10;    fast=False,&#10;    pca_state=pca_state,&#10;    randomize_players=True,  # Balancear labels en test también&#10;    return_pca_state=False,&#10;    return_full=True&#10;)&#10;print('✅ Features históricas TEST calculadas.')&#10;&#10;#%% md&#10;### 3.1 Reporte PCA y diagnóstico de grupos clave MEJORADO&#10;#%%&#10;pca_report = export_pca_report(pca_state)&#10;print(&quot; Reporte PCA por grupo:&quot;)&#10;display(pca_report.sort_values('pc1_var', ascending=False))&#10;&#10;# Diagnóstico de grupos clave con nuevas features de fatiga&#10;try:&#10;    print('\n Diagnóstico grupo fatigue (features combinadas):')&#10;    fatigue_diag = diagnose_pca_group(df_train_final, 'fatigue', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;    print(f&quot;   - Top loadings PC1: {fatigue_diag['pc1_loadings_sorted'][:3]}&quot;)&#10;&#10;    print('\n Diagnóstico grupo fatigue_raw:')&#10;    fatigue_raw_diag = diagnose_pca_group(df_train_final, 'fatigue_raw', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_raw_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_raw_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;    print('\n Diagnóstico grupo fatigue_individual:')&#10;    fatigue_ind_diag = diagnose_pca_group(df_train_final, 'fatigue_individual', pca_state)&#10;    print(f&quot;   - Componentes: {fatigue_ind_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {fatigue_ind_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;    print('\n Diagnóstico grupo elo_core:')&#10;    elo_diag = diagnose_pca_group(df_train_final, 'elo_core', pca_state)&#10;    print(f&quot;   - Componentes: {elo_diag['n_components']}&quot;)&#10;    print(f&quot;   - Varianza PC1: {elo_diag['explained_variance_ratio'][0]:.3f}&quot;)&#10;&#10;except Exception as e:&#10;    print(f'⚠️ Error diagnóstico PCA: {e}')&#10;#%% md&#10;## 4. Selección de features&#10;#%%&#10;features = get_curated_features(df_train_final)&#10;features = [f for f in features if f in df_test_final.columns and f in df_train_final.columns]&#10;print(f'Features seleccionadas. Total: {len(features)}')&#10;&#10;# Reasignar matrices de entrenamiento/test&#10;X_train = df_train_final[features]&#10;X_test = df_test_final[features]&#10;y_train = df_train_final['target']&#10;y_test = df_test_final['target']&#10;print(f&quot;Shapes -&gt; X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}&quot;)&#10;#%% md&#10;## 5. Guardar dataset final&#10;#%%&#10;from src.data_loader import BASE_DIR&#10;&#10;output_dir = os.path.join(BASE_DIR, 'data', 'processed')&#10;os.makedirs(output_dir, exist_ok=True)&#10;df_train_final.to_csv(os.path.join(output_dir, 'train_final.csv'), index=False)&#10;df_test_final.to_csv(os.path.join(output_dir, 'test_final.csv'), index=False)&#10;df_train_full.to_csv(os.path.join(output_dir, 'train_full.csv'), index=False)&#10;df_test_full.to_csv(os.path.join(output_dir, 'test_full.csv'), index=False)&#10;print('✅ Datasets finales guardados.')&#10;#%% md&#10;## 6. AUDITORÍA AVANZADA DE FUGA DE INFORMACIÓN&#10;#%%&#10;# Construir índices para validación temporal&#10;_df_train_full = df_train_full.copy()&#10;_df_test_full = df_test_full.copy()&#10;_df_train_full['__split'] = 'train'&#10;_df_test_full['__split'] = 'test'&#10;_df_all_full = pd.concat([_df_train_full, _df_test_full], ignore_index=True)&#10;train_idx = _df_all_full.index[_df_all_full['__split'] == 'train']&#10;test_idx = _df_all_full.index[_df_all_full['__split'] == 'test']&#10;&#10;print(&quot; AUDITORÍA COMPLETA DE DATA LEAKAGE&quot;)&#10;print(&quot;=&quot; * 50)&#10;&#10;# 1. Verificaciones básicas&#10;check_index_overlap(df_train_final, df_test_final)&#10;check_temporal_split(_df_all_full, train_idx, test_idx)&#10;&#10;# 2. Auditoría de correlaciones&#10;X_leak_audit = df_train_final.drop(columns=['target'], errors='ignore').select_dtypes(include=[np.number])&#10;corrs = audit_feature_leakage(X_leak_audit, y_train)&#10;&#10;# 3. Comparación de distribuciones de features top&#10;top_feats = corrs.head(20).index.tolist()&#10;print(f&quot;\n Comparando distribuciones de top {len(top_feats[:10])} features:&quot;)&#10;compare_feature_distributions(df_train_final, df_test_final, top_feats[:10])&#10;&#10;# 4. Test de permutación de target&#10;print(f&quot;\n Test de permutación de target:&quot;)&#10;model_base = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,&#10;                          eval_metric='logloss', random_state=42)&#10;quick_permutation_target_test(model_base,&#10;                              X_train, y_train, X_test, y_test,&#10;                              n_trials=1, random_state=42)&#10;&#10;# 5. Feature shuffle ablation&#10;print(f&quot;\n Ablación por shuffle de top features:&quot;)&#10;feature_shuffle_ablation(model_base, X_train, y_train, X_test, y_test,&#10;                         top_features=top_feats[:5], random_state=42)&#10;#%% md&#10;## 7. VALIDACIÓN TEMPORAL AVANZADA&#10;#%%&#10;print(&quot; VALIDACIÓN TEMPORAL AVANZADA&quot;)&#10;print(&quot;=&quot; * 40)&#10;&#10;# Detectar columna de fechas&#10;date_col = None&#10;for col in ['tourney_date', 'match_date', 'date']:&#10;    if col in df_train_full.columns:&#10;        date_col = col&#10;        break&#10;&#10;if date_col is not None:&#10;    train_dates = df_train_full[date_col]&#10;&#10;    # Validación temporal con múltiples splits&#10;    print(&quot;\n Validación con múltiples ventanas temporales:&quot;)&#10;    temporal_results = advanced_temporal_validation(&#10;        X_train, y_train, train_dates, model_base, n_splits=5, test_months=3&#10;    )&#10;&#10;    if not temporal_results.empty:&#10;        print(&quot;\nResultados por split temporal:&quot;)&#10;        display(temporal_results)&#10;        print(f&quot;\n Resumen:&quot;)&#10;        print(f&quot;   - AUC promedio: {temporal_results['auc'].mean():.4f} ±{temporal_results['auc'].std():.4f}&quot;)&#10;        print(f&quot;   - LogLoss promedio: {temporal_results['logloss'].mean():.4f} ±{temporal_results['logloss'].std():.4f}&quot;)&#10;        print(f&quot;   - Rango AUC: [{temporal_results['auc'].min():.4f}, {temporal_results['auc'].max():.4f}]&quot;)&#10;&#10;        # Alerta si hay caída significativa de performance&#10;        auc_drop = temporal_results['auc'].max() - temporal_results['auc'].min()&#10;        if auc_drop &gt; 0.05:&#10;            print(f&quot;⚠️  ALERTA: Caída de AUC de {auc_drop:.3f} entre splits - posible overfitting temporal&quot;)&#10;    else:&#10;        print(&quot;❌ No se pudieron crear splits temporales válidos&quot;)&#10;else:&#10;    print(&quot;❌ No se encontró columna de fecha para validación temporal&quot;)&#10;&#10;# Análisis de estabilidad con bootstrap&#10;print(f&quot;\n Análisis de estabilidad (Bootstrap):&quot;)&#10;stability_results = stability_analysis(X_train, y_train, model_base, n_bootstrap=20)&#10;print(f&quot;   - AUC medio: {stability_results['mean_auc']:.4f} ±{stability_results['std_auc']:.4f}&quot;)&#10;print(f&quot;   - Rango: [{stability_results['min_auc']:.4f}, {stability_results['max_auc']:.4f}]&quot;)&#10;&#10;if stability_results['std_auc'] &gt; 0.02:&#10;    print(f&quot;⚠️  ALERTA: Alta variabilidad ({stability_results['std_auc']:.3f}) - modelo inestable&quot;)&#10;&#10;# Estabilidad de feature importance&#10;print(f&quot;\n Estabilidad de Feature Importance:&quot;)&#10;feat_stability = feature_importance_stability(X_train, y_train, model_base, n_iterations=15)&#10;print(&quot;Top 10 features más estables (menor coeficiente de variación):&quot;)&#10;display(feat_stability.head(10)[['mean', 'std', 'cv']])&#10;&#10;highly_unstable = feat_stability[feat_stability['cv'] &gt; 0.5]&#10;if len(highly_unstable) &gt; 0:&#10;    print(f&quot;⚠️  Features muy inestables (CV &gt; 0.5): {len(highly_unstable)}&quot;)&#10;#%% md&#10;## 8. Grid Search CON VALIDACIÓN TEMPORAL&#10;#%%&#10;print(&quot; Realizando Grid Search para XGBoost con validación temporal...&quot;)&#10;param_grid = {&#10;    'n_estimators': [100, 200, 300],&#10;    'max_depth': [6, 8, 10],&#10;    'learning_rate': [0.05, 0.1, 0.15],&#10;    'subsample': [0.8, 0.9],&#10;    'colsample_bytree': [0.5, 0.7],&#10;}&#10;&#10;xgb_base = XGBClassifier(&#10;    random_state=42,&#10;    eval_metric='logloss',&#10;    reg_alpha=0.3,   # L1&#10;    reg_lambda=1.0,   # L2&#10;    min_child_weight=3&#10;)&#10;tscv = TimeSeriesSplit(n_splits=5)&#10;grid_search = GridSearchCV(&#10;    xgb_base,&#10;    param_grid,&#10;    cv=tscv,&#10;    scoring='neg_log_loss',   # o 'roc_auc'&#10;    n_jobs=-1,&#10;    verbose=1&#10;)&#10;&#10;grid_search.fit(X_train, y_train)&#10;&#10;print(f&quot;Mejores parámetros: {grid_search.best_params_}&quot;)&#10;print(f&quot;Mejor CV score (log loss): {grid_search.best_score_:.4f}&quot;)&#10;#%% md&#10;## 9. Entrenamiento del Modelo Optimizado&#10;#%%&#10;# 1. Reemplazar infinitos por NaN&#10;X_train = X_train.replace([np.inf, -np.inf], np.nan)&#10;X_test = X_test.replace([np.inf, -np.inf], np.nan)&#10;&#10;# 2. Pipeline con imputación por media&#10;imputer = SimpleImputer(strategy=&quot;mean&quot;)&#10;X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)&#10;X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)&#10;print(&quot;Tras imputación -&gt; X_train filas:&quot;, len(X_train), &quot;X_test filas:&quot;, len(X_test))&#10;&#10;# 3. Entrenar modelo optimizado con mejores hiperparámetros encontrados&#10;best_model = XGBClassifier(**grid_search.best_params_, random_state=42, eval_metric='logloss')&#10;best_model.fit(X_train, y_train)&#10;&#10;# 4. Predicciones&#10;y_pred_optimized = best_model.predict(X_test)&#10;y_proba_optimized = best_model.predict_proba(X_test)[:, 1]&#10;&#10;# 5. Métricas principales&#10;acc_optimized = accuracy_score(y_test, y_pred_optimized)&#10;auc_optimized = roc_auc_score(y_test, y_proba_optimized)&#10;logloss = log_loss(y_test, y_proba_optimized)&#10;brier = brier_score_loss(y_test, y_proba_optimized)&#10;&#10;print(f&quot;Modelo optimizado - Accuracy: {acc_optimized:.4f}, AUC: {auc_optimized:.4f}, &quot;&#10;      f&quot;LogLoss: {logloss:.4f}, Brier: {brier:.4f}&quot;)&#10;&#10;# 6. Calibrar probabilidades (para apuestas / probas realistas)&#10;tscv = TimeSeriesSplit(n_splits=3)&#10;calibrated_model = CalibratedClassifierCV(best_model, method=&quot;isotonic&quot;, cv=tscv)&#10;calibrated_model.fit(X_train, y_train)&#10;&#10;y_proba_cal = calibrated_model.predict_proba(X_test)[:, 1]&#10;logloss_cal = log_loss(y_test, y_proba_cal)&#10;brier_cal = brier_score_loss(y_test, y_proba_cal)&#10;&#10;print(f&quot;Modelo calibrado - LogLoss: {logloss_cal:.4f}, Brier: {brier_cal:.4f}&quot;)&#10;#%% md&#10;## 10. Comparación de Algoritmos&#10;#%%&#10;models = {&#10;    'XGBoost Optimizado': best_model,&#10;    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),&#10;    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42),&#10;    'Logistic Regression': LogisticRegression(max_iter=5500, random_state=42),&#10;    'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),&#10;    'Naive Bayes': GaussianNB()&#10;}&#10;results = []&#10;for name, model in models.items():&#10;    print(f&quot;Entrenando {name}...&quot;)&#10;    if name != 'XGBoost Optimizado':&#10;        model.fit(X_train, y_train)&#10;    y_pred = model.predict(X_test)&#10;    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None&#10;    acc = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None&#10;    results.append({'Modelo': name, 'Accuracy': acc, 'AUC': auc if auc else 'N/A'})&#10;results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)&#10;print(&quot;\nResultados de comparación:&quot;)&#10;print(results_df.round(4))&#10;#%% md&#10;## 11. Visualización de Resultados de Modelos&#10;#%%&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 6))&#10;numeric_results = results_df[results_df['AUC'] != 'N/A'].copy()&#10;numeric_results['AUC'] = pd.to_numeric(numeric_results['AUC'])&#10;axes[0].barh(numeric_results['Modelo'], numeric_results['Accuracy'], alpha=0.8)&#10;axes[0].set_title('Comparación de Accuracy', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Accuracy')&#10;axes[0].grid(True, alpha=0.3, axis='x')&#10;axes[1].barh(numeric_results['Modelo'], numeric_results['AUC'], alpha=0.8, color='orange')&#10;axes[1].set_title('Comparación de AUC', fontsize=14, pad=20)&#10;axes[1].set_xlabel('AUC')&#10;axes[1].grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;#%% md&#10;## 12. Ensemble de Modelos&#10;#%%&#10;ensemble = VotingClassifier(estimators=[&#10;    ('xgb', best_model),&#10;    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),&#10;    ('gb', GradientBoostingClassifier(n_estimators=200, max_depth=8, random_state=42))&#10;], voting='soft')&#10;ensemble.fit(X_train, y_train)&#10;y_pred_ensemble = ensemble.predict(X_test)&#10;y_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]&#10;acc_ensemble = accuracy_score(y_test, y_pred_ensemble)&#10;auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)&#10;print(f&quot;Ensemble - Accuracy: {acc_ensemble:.4f}, AUC: {auc_ensemble:.4f}&quot;)&#10;print(f&quot;Mejora sobre mejor modelo individual: +{acc_ensemble - acc_optimized:.4f}&quot;)&#10;#%% md&#10;## 13.  Análisis de Features e Interpretabilidad&#10;&#10;#%%&#10;# Importancia de features&#10;importances = best_model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': X_train.columns,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;# Normalización y acumulado&#10;feature_importance_df['Normalized'] = feature_importance_df['Importance'] / feature_importance_df['Importance'].sum()&#10;feature_importance_df['Cumulative'] = feature_importance_df['Normalized'].cumsum()&#10;&#10;# Visualización top 12&#10;plt.figure(figsize=(12, 8))&#10;top_features = feature_importance_df.head(12)&#10;sns.barplot(data=top_features, x='Importance', y='Feature')&#10;plt.title('Importancia de features en el modelo optimizado', fontsize=16, pad=20)&#10;plt.xlabel('Importancia Relativa')&#10;plt.ylabel('Feature')&#10;plt.grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;# Imprimir ranking&#10;print(&quot;Top 20 Features más importantes:&quot;)&#10;print(feature_importance_df.head(20).round(4))&#10;&#10;# Análisis de concentración&#10;n_features_80 = (feature_importance_df['Cumulative'] &lt;= 0.8).sum() + 1&#10;n_features_95 = (feature_importance_df['Cumulative'] &lt;= 0.95).sum() + 1&#10;&#10;print(f&quot;\nAnálisis de concentración:&quot;)&#10;print(f&quot;   {n_features_80} features explican el 80% de la importancia&quot;)&#10;print(f&quot;   {n_features_95} features explican el 95% de la importancia&quot;)&#10;#%% md&#10;### 14. Análisis de Errores del Modelo&#10;&#10;#%%&#10;# análisis detallado de errores&#10;# Usar el dataframe de test final para el análisis de errores&#10;if 'df_test_final' in locals():&#10;    df_test_analysis = df_test_final.copy()&#10;&#10;df_test_analysis['pred'] = y_pred_optimized&#10;df_test_analysis['pred_proba'] = y_proba_optimized&#10;df_test_analysis['correct'] = (df_test_analysis['pred'] == df_test_analysis['target'])&#10;&#10;# estadísticas de errores&#10;total_errors = (~df_test_analysis['correct']).sum()&#10;error_rate = total_errors / len(df_test_analysis)&#10;&#10;print(f&quot;análisis de errores:&quot;)&#10;print(f&quot;   total errores: {total_errors:,} de {len(df_test_analysis):,} ({error_rate:.2%})&quot;)&#10;&#10;# tipos de errores&#10;false_positives = len(df_test_analysis[(df_test_analysis['target'] == 0) &amp; (df_test_analysis['pred'] == 1)])&#10;false_negatives = len(df_test_analysis[(df_test_analysis['target'] == 1) &amp; (df_test_analysis['pred'] == 0)])&#10;&#10;print(f&quot;   falsos positivos: {false_positives:,}&quot;)&#10;print(f&quot;   falsos negativos: {false_negatives:,}&quot;)&#10;&#10;# análisis por confianza de predicción&#10;confidence_bins = pd.cut(df_test_analysis['pred_proba'], bins=[0, 0.3, 0.7, 1.0], labels=['Baja', 'Media', 'Alta'])&#10;confidence_accuracy = df_test_analysis.groupby(confidence_bins, observed=False)['correct'].agg(['count', 'mean']).round(4)&#10;&#10;print(f&quot;accuracy por nivel de confianza:&quot;)&#10;print(confidence_accuracy)&#10;&#10;# matriz de confusión mejorada&#10;plt.figure(figsize=(8, 6))&#10;cm = confusion_matrix(y_test, y_pred_optimized)&#10;sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',&#10;           xticklabels=['Perdedor Predicho', 'Ganador Predicho'],&#10;           yticklabels=['Perdedor Real', 'Ganador Real'])&#10;plt.title('matriz de confusión del modelo optimizado', fontsize=14, pad=20)&#10;plt.ylabel('Valor Real')&#10;plt.xlabel('Predicción')&#10;plt.tight_layout()&#10;plt.show()&#10;#%% md&#10;## 15. Guardar Modelo y Estados en Outputs&#10;&#10;#%%&#10;# Crear directorio outputs si no existe&#10;outputs_dir = Path('../outputs')&#10;outputs_dir.mkdir(exist_ok=True)&#10;&#10;print(&quot; Guardando modelo y estados en outputs/...&quot;)&#10;&#10;# 1. Guardar el mejor modelo entrenado&#10;print(&quot; Guardando modelo XGBoost optimizado...&quot;)&#10;with open(outputs_dir / 'best_xgb_model.pkl', 'wb') as f:&#10;    pickle.dump(best_model, f)&#10;&#10;# 2. Guardar modelo calibrado&#10;print(&quot; Guardando modelo calibrado...&quot;)&#10;with open(outputs_dir / 'calibrated_model.pkl', 'wb') as f:&#10;    pickle.dump(calibrated_model, f)&#10;&#10;# 3. Guardar ensemble&#10;print(&quot; Guardando ensemble...&quot;)&#10;with open(outputs_dir / 'ensemble_model.pkl', 'wb') as f:&#10;    pickle.dump(ensemble, f)&#10;&#10;# 4. Guardar imputer para preprocessing&#10;print(&quot; Guardando imputer...&quot;)&#10;with open(outputs_dir / 'imputer.pkl', 'wb') as f:&#10;    pickle.dump(imputer, f)&#10;&#10;# 5. Guardar estados históricos para la aplicación web&#10;print(&quot; Guardando estados históricos...&quot;)&#10;training_states = {&#10;    'final_global_elos': final_global_elos,&#10;    'final_surface_elos': final_surface_elos,&#10;    'final_h2h': final_h2h,&#10;    'final_stats': final_stats,&#10;    'pca_state': pca_state,&#10;    'feature_columns': features,&#10;    'model_metrics': {&#10;        'accuracy': acc_optimized,&#10;        'auc': auc_optimized,&#10;        'logloss': logloss,&#10;        'brier': brier,&#10;        'accuracy_ensemble': acc_ensemble,&#10;        'auc_ensemble': auc_ensemble&#10;    },&#10;    'best_params': grid_search.best_params_&#10;}&#10;&#10;with open(outputs_dir / 'training_states.pkl', 'wb') as f:&#10;    pickle.dump(training_states, f)&#10;&#10;# 6. Guardar lista de jugadores únicos para la app web&#10;print(&quot; Guardando lista de jugadores...&quot;)&#10;all_players = set()&#10;for df in [df_train_full, df_test_full]:&#10;    if 'player_1' in df.columns:&#10;        all_players.update(df['player_1'].dropna().unique())&#10;    if 'player_2' in df.columns:&#10;        all_players.update(df['player_2'].dropna().unique())&#10;    # También buscar en formato winner/loser&#10;    if 'winner_name' in df.columns:&#10;        all_players.update(df['winner_name'].dropna().unique())&#10;    if 'loser_name' in df.columns:&#10;        all_players.update(df['loser_name'].dropna().unique())&#10;&#10;players_list = sorted(list(all_players))&#10;&#10;with open(outputs_dir / 'players_list.pkl', 'wb') as f:&#10;    pickle.dump(players_list, f)&#10;&#10;# 6.5. NUEVO: Guardar features más recientes de cada jugador&#10;print(&quot; Extrayendo y guardando features más recientes de cada jugador...&quot;)&#10;&#10;def extract_latest_player_features(df_model, df_full, features_list, players_list):&#10;    &quot;&quot;&quot;&#10;    Extraer las features más recientes para cada jugador único&#10;    CORREGIDO: Para usar las columnas reales de los datos&#10;    &quot;&quot;&quot;&#10;    player_features = {}&#10;&#10;    # Combinar ambos DataFrames para tener todo el histórico&#10;    combined_df_model = pd.concat([df_train_final, df_test_final], ignore_index=True)&#10;    combined_df_full = pd.concat([df_train_full, df_test_full], ignore_index=True)&#10;&#10;    # Asegurar que hay una columna de orden temporal&#10;    if 'tourney_date' not in combined_df_full.columns:&#10;        # Usar índice como proxy de orden temporal&#10;        combined_df_full['temp_order'] = combined_df_full.index&#10;        sort_col = 'temp_order'&#10;    else:&#10;        sort_col = 'tourney_date'&#10;        combined_df_full['tourney_date'] = pd.to_datetime(combined_df_full['tourney_date'], errors='coerce')&#10;        combined_df_full = combined_df_full.sort_values('tourney_date')&#10;        combined_df_model = combined_df_model.iloc[combined_df_full.index]&#10;&#10;    print(f&quot;   Procesando {len(players_list)} jugadores únicos...&quot;)&#10;&#10;    for i, player in enumerate(players_list):&#10;        if i % 500 == 0:&#10;            print(f&quot;   Procesado {i}/{len(players_list)} jugadores...&quot;)&#10;&#10;        # Buscar las filas más recientes donde aparece el jugador&#10;        player_rows = []&#10;&#10;        # CORREGIDO: Usar las columnas reales que existen&#10;        # Como player_1 (en df_full)&#10;        if 'player_1' in combined_df_full.columns:&#10;            mask = combined_df_full['player_1'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(combined_df_full[mask].index.tolist())&#10;&#10;        # Como player_2 (en df_full)&#10;        if 'player_2' in combined_df_full.columns:&#10;            mask = combined_df_full['player_2'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(combined_df_full[mask].index.tolist())&#10;&#10;        if not player_rows:&#10;            # Jugador no encontrado, usar features neutras&#10;            model_features = {col: 0.0 for col in features_list}&#10;            metadata = {&#10;                'last_match_date': None,&#10;                'total_matches': 0,&#10;                'global_elo': 1500,&#10;                'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500}&#10;            }&#10;        else:&#10;            # Obtener la fila más reciente&#10;            latest_idx = max(player_rows)&#10;&#10;            # Extraer features del modelo (df_model) - verificar que el índice existe&#10;            if latest_idx &lt; len(combined_df_model):&#10;                model_row = combined_df_model.iloc[latest_idx]&#10;&#10;                # Extraer solo las features que usa el modelo&#10;                model_features = {}&#10;                for feature in features_list:&#10;                    if feature in model_row:&#10;                        value = model_row[feature]&#10;                        try:&#10;                            if pd.notna(value) and np.isfinite(float(value)):&#10;                                model_features[feature] = float(value)&#10;                            else:&#10;                                model_features[feature] = 0.0&#10;                        except (ValueError, TypeError):&#10;                            model_features[feature] = 0.0&#10;                    else:&#10;                        model_features[feature] = 0.0&#10;            else:&#10;                # Fallback: features en cero&#10;                model_features = {col: 0.0 for col in features_list}&#10;&#10;            # Metadata adicional del df_full&#10;            if latest_idx &lt; len(combined_df_full):&#10;                full_row = combined_df_full.iloc[latest_idx]&#10;&#10;                # CORREGIDO: Usar nombres de columnas correctos&#10;                metadata = {&#10;                    'last_match_date': str(full_row.get('tourney_date', '')),&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': full_row.get('elo_p1', 1500) if 'elo_p1' in full_row else 1500,&#10;                    'surface_elos': {&#10;                        'hard': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,&#10;                        'clay': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,  # No hay específica por superficie&#10;                        'grass': full_row.get('surface_elo_p1', 1500) if 'surface_elo_p1' in full_row else 1500,&#10;                    },&#10;                    'last_tournament': full_row.get('tourney_name', 'Unknown'),&#10;                    'last_surface': full_row.get('surface', 'Unknown'),&#10;                    'last_opponent': full_row.get('player_2' if 'player_1' in combined_df_full.columns and player in str(full_row.get('player_1', '')) else 'player_1', 'Unknown')&#10;                }&#10;            else:&#10;                metadata = {&#10;                    'last_match_date': None,&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': 1500,&#10;                    'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500},&#10;                    'last_tournament': 'Unknown',&#10;                    'last_surface': 'Unknown',&#10;                    'last_opponent': 'Unknown'&#10;                }&#10;&#10;        player_features[player] = {&#10;            'model_features': model_features,&#10;            'metadata': metadata&#10;        }&#10;&#10;    return player_features&#10;&#10;# Extraer features para todos los jugadores&#10;player_features = extract_latest_player_features(&#10;    df_train_final, df_train_full, features, players_list&#10;)&#10;&#10;# Guardar archivo de features de jugadores&#10;print(&quot; Guardando features de jugadores...&quot;)&#10;with open(outputs_dir / 'player_features.pkl', 'wb') as f:&#10;    pickle.dump(player_features, f)&#10;&#10;# Guardar también en CSV para inspección&#10;print(&quot; Guardando CSV de inspección...&quot;)&#10;player_df_list = []&#10;for player, features_dict in player_features.items():&#10;    row = {'player_name': player}&#10;    row.update(features_dict['model_features'])&#10;    row.update({&#10;        'last_match_date': features_dict['metadata']['last_match_date'],&#10;        'total_matches': features_dict['metadata']['total_matches'],&#10;        'global_elo': features_dict['metadata']['global_elo'],&#10;        'surface_elos': str(features_dict['metadata']['surface_elos'])&#10;    })&#10;    player_df_list.append(row)&#10;&#10;player_df = pd.DataFrame(player_df_list)&#10;player_df.to_csv(outputs_dir / 'player_features.csv', index=False)&#10;&#10;print(f&quot;✅ Features de jugadores guardadas: {len(player_features)} jugadores&quot;)&#10;print(f&quot; Archivos creados: player_features.pkl, player_features.csv&quot;)&#10;&#10;#%% md&#10;## 16. Resumen Ejecutivo y Conclusiones&#10;&#10;#%%&#10;# resumen final del proyecto&#10;print(&quot;=&quot; * 80)&#10;print(&quot;resumen ejecutivo - tennis match predictor&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;# Adaptación de variables para robustez&#10;train_df = df_train_final if 'df_train_final' in locals() else df_train_full&#10;&#10;test_df = df_test_final if 'df_test_final' in locals() else df_test_full&#10;&#10;# Features disponibles&#10;features_list = features if 'features' in locals() else (&#10;    features if 'available_features' in locals() else train_df.columns.tolist()&#10;)&#10;&#10;print(f&quot;\ndatos procesados:&quot;)&#10;if 'tourney_date' in train_df.columns and 'tourney_date' in test_df.columns:&#10;    print(f&quot;   período de entrenamiento: {pd.to_datetime(train_df['tourney_date'], errors='coerce').dt.year.min()}-{pd.to_datetime(train_df['tourney_date'], errors='coerce').dt.year.max()}&quot;)&#10;    print(f&quot;   período de test: {pd.to_datetime(test_df['tourney_date'], errors='coerce').dt.year.min()}-{pd.to_datetime(test_df['tourney_date'], errors='coerce').dt.year.max()}&quot;)&#10;print(f&quot;   total partidos analizados: {len(train_df) + len(test_df):,}&quot;)&#10;print(f&quot;   features engineered: {len(features_list)}&quot;)&#10;&#10;print(f&quot;\nrendimiento del modelo:&quot;)&#10;print(f&quot;   mejor modelo: XGBoost optimizado&quot;)&#10;print(f&quot;   accuracy: {acc_optimized:.4f} ({acc_optimized:.1%})&quot;)&#10;print(f&quot;   AUC: {auc_optimized:.4f}&quot;)&#10;print(f&quot;   ensemble accuracy: {acc_ensemble:.4f} ({(acc_ensemble-acc_optimized)*100:+.2f}% mejora)&quot;)&#10;&#10;print(f&quot;\nfeatures más importantes:&quot;)&#10;if 'feature_importance_df' in locals():&#10;    top_5_features = feature_importance_df.head(5)&#10;    for idx, row in top_5_features.iterrows():&#10;        print(f&quot;   {idx+1}. {row['Feature']}: {row['Importance']:.3f} ({row['Importance']:.1%})&quot;)&#10;else:&#10;    print(&quot;   (No se encontró feature_importance_df)&quot;)&#10;&#10;print(f&quot;\ninsights clave:&quot;)&#10;print(f&quot;   las features categóricas (elo_advantage, tier_diff) son más predictivas&quot;)&#10;print(f&quot;   el ranking ATP es más informativo que el ELO calculado&quot;)&#10;print(f&quot;   el H2H tiene impacto mínimo en predicciones generales&quot;)&#10;print(f&quot;   los Big 3 muestran patrones únicos de dominancia por superficie&quot;)&#10;print(f&quot;   el modelo es altamente preciso (~99%) para datos históricos&quot;)&#10;&#10;print(f&quot;\nrecomendaciones:&quot;)&#10;print(f&quot;   usar XGBoost optimizado para predicciones en producción&quot;)&#10;print(f&quot;   enfocar feature engineering en rankings y diferencias de nivel&quot;)&#10;print(f&quot;   considerar factores temporales para predicciones futuras&quot;)&#10;print(f&quot;   validar con datos de torneos 2025 cuando estén disponibles&quot;)&#10;&#10;print(f&quot;\naplicaciones:&quot;)&#10;print(f&quot;   sistema de predicción en tiempo real&quot;)&#10;print(f&quot;   análisis para casas de apuestas&quot;)&#10;print(f&quot;   comentarios deportivos automatizados&quot;)&#10;print(f&quot;   análisis estratégico para jugadores/entrenadores&quot;)&#10;&#10;print(&quot;=&quot; * 80)&#10;print(&quot;¡proyecto completado exitosamente!&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;#%%&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/regenerate_features.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/regenerate_features.py" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;# Regenerar features con H2H balanceado&#10;&#10;import sys&#10;import os&#10;sys.path.append('C:\\Users\\pepeg\\PycharmProjects\\PythonProject\\src')&#10;&#10;from data_loader import load_train_data, load_test_data, BASE_DIR&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;# Regenerar features de entrenamiento&#10;print(&quot; Regenerando features de entrenamiento...&quot;)&#10;df_train = load_train_data()&#10;df_train = clean_data(df_train)&#10;df_train = add_all_features(df_train)&#10;&#10;output_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;)&#10;os.makedirs(output_path, exist_ok=True)&#10;df_train.to_csv(os.path.join(output_path, &quot;features_train.csv&quot;), index=False)&#10;print(&quot;✅ Features de entrenamiento guardadas&quot;)&#10;&#10;# Regenerar features de test&#10;print(&quot; Regenerando features de test...&quot;)&#10;df_test = load_test_data()&#10;df_test = clean_data(df_test)&#10;df_test = add_all_features(df_test)&#10;df_test.to_csv(os.path.join(output_path, &quot;features_test.csv&quot;), index=False)&#10;print(&quot;✅ Features de test guardadas&quot;)&#10;&#10;print(&quot; Regeneración completa!&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/requirements_backend.txt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/requirements_backend.txt" />
              <option name="updatedContent" value="Flask==2.3.3&#10;Flask-CORS==4.0.0&#10;pandas==2.1.4&#10;numpy==1.24.3&#10;scikit-learn==1.3.0&#10;xgboost==2.0.3&#10;statsmodels==0.14.0&#10;gunicorn==21.2.0&#10;python-dotenv==1.0.0&#10;Werkzeug==2.3.7" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/api.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/api.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;FastAPI Backend para Predicción de Partidos de Tenis&#10;Sistema completo de predicción usando XGBoost optimizado&#10;&quot;&quot;&quot;&#10;from fastapi import FastAPI, HTTPException, Query&#10;from fastapi.middleware.cors import CORSMiddleware&#10;from fastapi.responses import JSONResponse&#10;from typing import Optional&#10;import uvicorn&#10;from datetime import datetime&#10;import logging&#10;&#10;from src.models import (&#10;    PredictRequest, PredictResponse, PlayerResponse, PlayersListResponse,&#10;    ModelInfo, HealthResponse&#10;)&#10;from src.model_service import model_service&#10;&#10;# Configurar logging&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;# Crear aplicación FastAPI&#10;app = FastAPI(&#10;    title=&quot; Tennis Match Prediction API&quot;,&#10;    description=&quot;API REST para predicción de partidos de tenis usando ML avanzado&quot;,&#10;    version=&quot;1.0.0&quot;,&#10;    docs_url=&quot;/docs&quot;,&#10;    redoc_url=&quot;/redoc&quot;&#10;)&#10;&#10;# Configurar CORS para permitir requests desde el frontend&#10;app.add_middleware(&#10;    CORSMiddleware,&#10;    allow_origins=[&quot;*&quot;],  # En producción, especificar dominios exactos&#10;    allow_credentials=True,&#10;    allow_methods=[&quot;*&quot;],&#10;    allow_headers=[&quot;*&quot;],&#10;)&#10;&#10;@app.on_event(&quot;startup&quot;)&#10;async def startup_event():&#10;    &quot;&quot;&quot;Cargar modelo al iniciar la aplicación&quot;&quot;&quot;&#10;    logger.info(&quot; Iniciando Tennis Prediction API...&quot;)&#10;&#10;    success = model_service.load_model_artifacts()&#10;    if not success:&#10;        logger.error(&quot;❌ Error cargando el modelo!&quot;)&#10;        raise RuntimeError(&quot;No se pudo cargar el modelo&quot;)&#10;&#10;    logger.info(&quot;✅ API lista para predicciones!&quot;)&#10;&#10;@app.get(&quot;/&quot;, response_model=dict)&#10;async def root():&#10;    &quot;&quot;&quot;Endpoint raíz con información básica&quot;&quot;&quot;&#10;    return {&#10;        &quot;service&quot;: &quot;Tennis Match Prediction API&quot;,&#10;        &quot;version&quot;: &quot;1.0.0&quot;,&#10;        &quot;status&quot;: &quot;active&quot;,&#10;        &quot;endpoints&quot;: {&#10;            &quot;predict&quot;: &quot;/predict&quot;,&#10;            &quot;players&quot;: &quot;/players&quot;,&#10;            &quot;player_info&quot;: &quot;/player/{name}&quot;,&#10;            &quot;model_info&quot;: &quot;/model/info&quot;,&#10;            &quot;health&quot;: &quot;/health&quot;&#10;        },&#10;        &quot;documentation&quot;: &quot;/docs&quot;&#10;    }&#10;&#10;@app.get(&quot;/health&quot;, response_model=HealthResponse)&#10;async def health_check():&#10;    &quot;&quot;&quot;Health check del servicio&quot;&quot;&quot;&#10;    return HealthResponse(&#10;        status=&quot;healthy&quot; if model_service.is_loaded else &quot;unhealthy&quot;,&#10;        model_loaded=model_service.is_loaded,&#10;        timestamp=datetime.now().isoformat(),&#10;        version=&quot;1.0.0&quot;&#10;    )&#10;&#10;@app.post(&quot;/predict&quot;, response_model=PredictResponse)&#10;async def predict_match(request: PredictRequest):&#10;    &quot;&quot;&quot;&#10;    Predecir el resultado de un partido de tenis&#10;&#10;    - **player1**: Nombre del primer jugador&#10;    - **player2**: Nombre del segundo jugador&#10;    - **surface**: Superficie (Hard, Clay, Grass, Carpet)&#10;    - **tournament_level**: Nivel del torneo (opcional)&#10;    - **round**: Ronda del torneo (opcional, default: F)&#10;    - **best_of**: Mejor de 3 o 5 sets (opcional, default: 3)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Verificar que los jugadores existan en la base de datos&#10;        if not model_service.is_player_known(request.player1):&#10;            suggestions = model_service.get_player_suggestions(request.player1)&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Jugador '{request.player1}' no encontrado&quot;,&#10;                    &quot;suggestions&quot;: suggestions[:5]&#10;                }&#10;            )&#10;&#10;        if not model_service.is_player_known(request.player2):&#10;            suggestions = model_service.get_player_suggestions(request.player2)&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Jugador '{request.player2}' no encontrado&quot;,&#10;                    &quot;suggestions&quot;: suggestions[:5]&#10;                }&#10;            )&#10;&#10;        # Realizar predicción&#10;        prediction = model_service.predict_match(&#10;            player1=request.player1,&#10;            player2=request.player2,&#10;            surface=request.surface.value,&#10;            tournament_level=request.tournament_level.value if request.tournament_level else None,&#10;            round=request.round,&#10;            best_of=request.best_of&#10;        )&#10;&#10;        logger.info(f&quot;Predicción realizada: {request.player1} vs {request.player2} -&gt; {prediction.prediction}&quot;)&#10;        return prediction&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        logger.error(f&quot;Error en predicción: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;prediction_error&quot;,&#10;                &quot;message&quot;: &quot;Error interno al realizar la predicción&quot;,&#10;                &quot;details&quot;: str(e)&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/players&quot;, response_model=PlayersListResponse)&#10;async def get_players(&#10;    search: Optional[str] = Query(None, description=&quot;Buscar jugadores por nombre&quot;),&#10;    limit: int = Query(100, ge=1, le=1000, description=&quot;Límite de resultados&quot;)&#10;):&#10;    &quot;&quot;&quot;&#10;    Obtener lista de jugadores disponibles&#10;&#10;    - **search**: Filtro opcional por nombre&#10;    - **limit**: Número máximo de jugadores a retornar&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if search:&#10;            players = model_service.get_player_suggestions(search, limit)&#10;        else:&#10;            players = model_service.players_list[:limit] if model_service.players_list else []&#10;&#10;        return PlayersListResponse(&#10;            total_players=len(model_service.players_list) if model_service.players_list else 0,&#10;            players=players,&#10;            last_updated=datetime.now().isoformat()&#10;        )&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo jugadores: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;players_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo lista de jugadores&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/player/{player_name}&quot;, response_model=PlayerResponse)&#10;async def get_player_info(player_name: str):&#10;    &quot;&quot;&quot;&#10;    Obtener información detallada de un jugador específico&#10;&#10;    - **player_name**: Nombre del jugador&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Buscar jugador exacto o sugerencias&#10;        if not model_service.is_player_known(player_name):&#10;            suggestions = model_service.get_player_suggestions(player_name)&#10;            if not suggestions:&#10;                raise HTTPException(&#10;                    status_code=404,&#10;                    detail={&#10;                        &quot;error&quot;: &quot;player_not_found&quot;,&#10;                        &quot;message&quot;: f&quot;Jugador '{player_name}' no encontrado&quot;,&#10;                        &quot;suggestions&quot;: []&#10;                    }&#10;                )&#10;&#10;            # Si hay coincidencia exacta en las sugerencias, usarla&#10;            exact_match = next((s for s in suggestions if s.lower() == player_name.lower()), None)&#10;            if exact_match:&#10;                player_name = exact_match&#10;            else:&#10;                raise HTTPException(&#10;                    status_code=404,&#10;                    detail={&#10;                        &quot;error&quot;: &quot;player_not_found&quot;,&#10;                        &quot;message&quot;: f&quot;Jugador '{player_name}' no encontrado&quot;,&#10;                        &quot;suggestions&quot;: suggestions[:5]&#10;                    }&#10;                )&#10;&#10;        # Obtener estadísticas del jugador&#10;        player_stats = model_service.get_player_stats(player_name)&#10;        if not player_stats:&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_stats_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Estadísticas no disponibles para '{player_name}'&quot;&#10;                }&#10;            )&#10;&#10;        return PlayerResponse(&#10;            player=player_stats,&#10;            h2h_records={},  # TODO: Implementar H2H records&#10;            career_highlights=[]  # TODO: Implementar highlights&#10;        )&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo info del jugador: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;player_info_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo información del jugador&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/model/info&quot;, response_model=ModelInfo)&#10;async def get_model_info():&#10;    &quot;&quot;&quot;&#10;    Obtener información del modelo de ML&#10;&#10;    Incluye métricas de performance, features importantes y metadatos&#10;    &quot;&quot;&quot;&#10;    try:&#10;        model_info = model_service.get_model_info()&#10;        return model_info&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo info del modelo: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;model_info_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo información del modelo&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/model/features&quot;, response_model=dict)&#10;async def get_model_features():&#10;    &quot;&quot;&quot;Obtener lista completa de features del modelo&quot;&quot;&quot;&#10;    try:&#10;        if model_service.feature_importance is None:&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;features_not_found&quot;,&#10;                    &quot;message&quot;: &quot;Información de features no disponible&quot;&#10;                }&#10;            )&#10;&#10;        features_data = model_service.feature_importance.to_dict('records')&#10;        return {&#10;            &quot;total_features&quot;: len(features_data),&#10;            &quot;features&quot;: features_data,&#10;            &quot;top_10&quot;: features_data[:10]&#10;        }&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo features: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;features_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo features del modelo&quot;&#10;            }&#10;        )&#10;&#10;@app.exception_handler(HTTPException)&#10;async def http_exception_handler(request, exc):&#10;    &quot;&quot;&quot;Manejador personalizado de excepciones HTTP&quot;&quot;&quot;&#10;    return JSONResponse(&#10;        status_code=exc.status_code,&#10;        content=exc.detail&#10;    )&#10;&#10;@app.exception_handler(Exception)&#10;async def general_exception_handler(request, exc):&#10;    &quot;&quot;&quot;Manejador general de excepciones&quot;&quot;&quot;&#10;    logger.error(f&quot;Error no manejado: {str(exc)}&quot;)&#10;    return JSONResponse(&#10;        status_code=500,&#10;        content={&#10;            &quot;error&quot;: &quot;internal_error&quot;,&#10;            &quot;message&quot;: &quot;Error interno del servidor&quot;&#10;        }&#10;    )&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Ejecutar servidor en desarrollo&#10;    uvicorn.run(&#10;        &quot;src.api:app&quot;,&#10;        host=&quot;0.0.0.0&quot;,&#10;        port=8000,&#10;        reload=True,&#10;        log_level=&quot;info&quot;&#10;    )&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;FastAPI Backend para Predicción de Partidos de Tenis&#10;Sistema completo de predicción usando XGBoost optimizado&#10;&quot;&quot;&quot;&#10;from fastapi import FastAPI, HTTPException, Query&#10;from fastapi.middleware.cors import CORSMiddleware&#10;from fastapi.responses import JSONResponse&#10;from typing import Optional&#10;import uvicorn&#10;from datetime import datetime&#10;import logging&#10;import traceback&#10;&#10;from src.models import (&#10;    PredictRequest, PredictResponse, PlayerResponse, PlayersListResponse,&#10;    ModelInfo, HealthResponse&#10;)&#10;from src.model_service import model_service&#10;&#10;# Configurar logging&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;# Crear aplicación FastAPI&#10;app = FastAPI(&#10;    title=&quot; Tennis Match Prediction API&quot;,&#10;    description=&quot;API REST para predicción de partidos de tenis usando ML avanzado&quot;,&#10;    version=&quot;1.0.0&quot;,&#10;    docs_url=&quot;/docs&quot;,&#10;    redoc_url=&quot;/redoc&quot;&#10;)&#10;&#10;# Configurar CORS para permitir requests desde el frontend&#10;app.add_middleware(&#10;    CORSMiddleware,&#10;    allow_origins=[&quot;*&quot;],  # En producción, especificar dominios exactos&#10;    allow_credentials=True,&#10;    allow_methods=[&quot;*&quot;],&#10;    allow_headers=[&quot;*&quot;],&#10;)&#10;&#10;@app.on_event(&quot;startup&quot;)&#10;async def startup_event():&#10;    &quot;&quot;&quot;Cargar modelo al iniciar la aplicación&quot;&quot;&quot;&#10;    logger.info(&quot; Iniciando Tennis Prediction API...&quot;)&#10;&#10;    success = model_service.load_model_artifacts()&#10;    if not success:&#10;        logger.error(&quot;❌ Error cargando el modelo!&quot;)&#10;        raise RuntimeError(&quot;No se pudo cargar el modelo&quot;)&#10;&#10;    logger.info(&quot;✅ API lista para predicciones!&quot;)&#10;&#10;@app.get(&quot;/&quot;, response_model=dict)&#10;async def root():&#10;    &quot;&quot;&quot;Endpoint raíz con información básica&quot;&quot;&quot;&#10;    return {&#10;        &quot;service&quot;: &quot;Tennis Match Prediction API&quot;,&#10;        &quot;version&quot;: &quot;1.0.0&quot;,&#10;        &quot;status&quot;: &quot;active&quot;,&#10;        &quot;endpoints&quot;: {&#10;            &quot;predict&quot;: &quot;/predict&quot;,&#10;            &quot;players&quot;: &quot;/players&quot;,&#10;            &quot;player_info&quot;: &quot;/player/{name}&quot;,&#10;            &quot;model_info&quot;: &quot;/model/info&quot;,&#10;            &quot;health&quot;: &quot;/health&quot;&#10;        },&#10;        &quot;documentation&quot;: &quot;/docs&quot;&#10;    }&#10;&#10;@app.get(&quot;/health&quot;, response_model=HealthResponse)&#10;async def health_check():&#10;    &quot;&quot;&quot;Health check del servicio&quot;&quot;&quot;&#10;    return HealthResponse(&#10;        status=&quot;healthy&quot; if model_service.is_loaded else &quot;unhealthy&quot;,&#10;        model_loaded=model_service.is_loaded,&#10;        timestamp=datetime.now().isoformat(),&#10;        version=&quot;1.0.0&quot;&#10;    )&#10;&#10;@app.post(&quot;/predict&quot;, response_model=PredictResponse)&#10;async def predict_match(request: PredictRequest):&#10;    &quot;&quot;&quot;&#10;    Predecir el resultado de un partido de tenis&#10;&#10;    - **player1**: Nombre del primer jugador&#10;    - **player2**: Nombre del segundo jugador&#10;    - **surface**: Superficie (Hard, Clay, Grass, Carpet)&#10;    - **tournament_level**: Nivel del torneo (opcional)&#10;    - **round**: Ronda del torneo (opcional, default: F)&#10;    - **best_of**: Mejor de 3 o 5 sets (opcional, default: 3)&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Verificar que los jugadores existan en la base de datos&#10;        if not model_service.is_player_known(request.player1):&#10;            suggestions = model_service.get_player_suggestions(request.player1)&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Jugador '{request.player1}' no encontrado&quot;,&#10;                    &quot;suggestions&quot;: suggestions[:5]&#10;                }&#10;            )&#10;&#10;        if not model_service.is_player_known(request.player2):&#10;            suggestions = model_service.get_player_suggestions(request.player2)&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Jugador '{request.player2}' no encontrado&quot;,&#10;                    &quot;suggestions&quot;: suggestions[:5]&#10;                }&#10;            )&#10;&#10;        # Realizar predicción&#10;        prediction = model_service.predict_match(&#10;            player1=request.player1,&#10;            player2=request.player2,&#10;            surface=request.surface.value,&#10;            tournament_level=request.tournament_level.value if request.tournament_level else None,&#10;            round=request.round,&#10;            best_of=request.best_of&#10;        )&#10;&#10;        logger.info(f&quot;Predicción realizada: {request.player1} vs {request.player2} -&gt; {prediction.prediction}&quot;)&#10;        return prediction&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        # Registrar y devolver diagnóstico detallado en 'details'&#10;        logger.error(f&quot;Error en predicción: {str(e)}&quot;)&#10;        tb = traceback.format_exc()&#10;        detail_obj = {&#10;            &quot;error&quot;: &quot;prediction_error&quot;,&#10;            &quot;message&quot;: &quot;Error interno al realizar la predicción&quot;,&#10;            &quot;exception_type&quot;: type(e).__name__,&#10;            &quot;exception_str&quot;: str(e),&#10;            &quot;traceback&quot;: tb&#10;        }&#10;        # Si la excepción incluye un dict diagnóstico como primer argumento, anexarlo&#10;        try:&#10;            if e.args and isinstance(e.args[0], dict):&#10;                detail_obj[&quot;diagnostic&quot;] = e.args[0]&#10;        except Exception:&#10;            pass&#10;&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail=detail_obj&#10;        )&#10;&#10;@app.get(&quot;/players&quot;, response_model=PlayersListResponse)&#10;async def get_players(&#10;    search: Optional[str] = Query(None, description=&quot;Buscar jugadores por nombre&quot;),&#10;    limit: int = Query(100, ge=1, le=1000, description=&quot;Límite de resultados&quot;)&#10;):&#10;    &quot;&quot;&quot;&#10;    Obtener lista de jugadores disponibles&#10;&#10;    - **search**: Filtro opcional por nombre&#10;    - **limit**: Número máximo de jugadores a retornar&#10;    &quot;&quot;&quot;&#10;    try:&#10;        if search:&#10;            players = model_service.get_player_suggestions(search, limit)&#10;        else:&#10;            players = model_service.players_list[:limit] if model_service.players_list else []&#10;&#10;        return PlayersListResponse(&#10;            total_players=len(model_service.players_list) if model_service.players_list else 0,&#10;            players=players,&#10;            last_updated=datetime.now().isoformat()&#10;        )&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo jugadores: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;players_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo lista de jugadores&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/player/{player_name}&quot;, response_model=PlayerResponse)&#10;async def get_player_info(player_name: str):&#10;    &quot;&quot;&quot;&#10;    Obtener información detallada de un jugador específico&#10;&#10;    - **player_name**: Nombre del jugador&#10;    &quot;&quot;&quot;&#10;    try:&#10;        # Buscar jugador exacto o sugerencias&#10;        if not model_service.is_player_known(player_name):&#10;            suggestions = model_service.get_player_suggestions(player_name)&#10;            if not suggestions:&#10;                raise HTTPException(&#10;                    status_code=404,&#10;                    detail={&#10;                        &quot;error&quot;: &quot;player_not_found&quot;,&#10;                        &quot;message&quot;: f&quot;Jugador '{player_name}' no encontrado&quot;,&#10;                        &quot;suggestions&quot;: []&#10;                    }&#10;                )&#10;&#10;            # Si hay coincidencia exacta en las sugerencias, usarla&#10;            exact_match = next((s for s in suggestions if s.lower() == player_name.lower()), None)&#10;            if exact_match:&#10;                player_name = exact_match&#10;            else:&#10;                raise HTTPException(&#10;                    status_code=404,&#10;                    detail={&#10;                        &quot;error&quot;: &quot;player_not_found&quot;,&#10;                        &quot;message&quot;: f&quot;Jugador '{player_name}' no encontrado&quot;,&#10;                        &quot;suggestions&quot;: suggestions[:5]&#10;                    }&#10;                )&#10;&#10;        # Obtener estadísticas del jugador&#10;        player_stats = model_service.get_player_stats(player_name)&#10;        if not player_stats:&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;player_stats_not_found&quot;,&#10;                    &quot;message&quot;: f&quot;Estadísticas no disponibles para '{player_name}'&quot;&#10;                }&#10;            )&#10;&#10;        return PlayerResponse(&#10;            player=player_stats,&#10;            h2h_records={},  # TODO: Implementar H2H records&#10;            career_highlights=[]  # TODO: Implementar highlights&#10;        )&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo info del jugador: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;player_info_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo información del jugador&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/model/info&quot;, response_model=ModelInfo)&#10;async def get_model_info():&#10;    &quot;&quot;&quot;&#10;    Obtener información del modelo de ML&#10;&#10;    Incluye métricas de performance, features importantes y metadatos&#10;    &quot;&quot;&quot;&#10;    try:&#10;        model_info = model_service.get_model_info()&#10;        return model_info&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo info del modelo: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;model_info_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo información del modelo&quot;&#10;            }&#10;        )&#10;&#10;@app.get(&quot;/model/features&quot;, response_model=dict)&#10;async def get_model_features():&#10;    &quot;&quot;&quot;Obtener lista completa de features del modelo&quot;&quot;&quot;&#10;    try:&#10;        if model_service.feature_importance is None:&#10;            raise HTTPException(&#10;                status_code=404,&#10;                detail={&#10;                    &quot;error&quot;: &quot;features_not_found&quot;,&#10;                    &quot;message&quot;: &quot;Información de features no disponible&quot;&#10;                }&#10;            )&#10;&#10;        features_data = model_service.feature_importance.to_dict('records')&#10;        return {&#10;            &quot;total_features&quot;: len(features_data),&#10;            &quot;features&quot;: features_data,&#10;            &quot;top_10&quot;: features_data[:10]&#10;        }&#10;&#10;    except HTTPException:&#10;        raise&#10;    except Exception as e:&#10;        logger.error(f&quot;Error obteniendo features: {str(e)}&quot;)&#10;        raise HTTPException(&#10;            status_code=500,&#10;            detail={&#10;                &quot;error&quot;: &quot;features_error&quot;,&#10;                &quot;message&quot;: &quot;Error obteniendo features del modelo&quot;&#10;            }&#10;        )&#10;&#10;@app.exception_handler(HTTPException)&#10;async def http_exception_handler(request, exc):&#10;    &quot;&quot;&quot;Manejador personalizado de excepciones HTTP&quot;&quot;&quot;&#10;    return JSONResponse(&#10;        status_code=exc.status_code,&#10;        content=exc.detail&#10;    )&#10;&#10;@app.exception_handler(Exception)&#10;async def general_exception_handler(request, exc):&#10;    &quot;&quot;&quot;Manejador general de excepciones&quot;&quot;&quot;&#10;    logger.error(f&quot;Error no manejado: {str(exc)}&quot;)&#10;    return JSONResponse(&#10;        status_code=500,&#10;        content={&#10;            &quot;error&quot;: &quot;internal_error&quot;,&#10;            &quot;message&quot;: &quot;Error interno del servidor&quot;&#10;        }&#10;    )&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Ejecutar servidor en desarrollo&#10;    uvicorn.run(&#10;        &quot;src.api:app&quot;,&#10;        host=&quot;0.0.0.0&quot;,&#10;        port=8000,&#10;        reload=True,&#10;        log_level=&quot;info&quot;&#10;    )" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/australian_open_2025_simulator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/australian_open_2025_simulator.py" />
              <option name="originalContent" value="# src/australian_open_2025_simulator.py&#10;&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;from data_loader import BASE_DIR, load_train_data&#10;from preprocess import clean_data&#10;from features import add_all_features, compute_elo_ratings, compute_surface_elo, compute_h2h&#10;from utils import make_dual_rows, fillna_features&#10;from model import train_model&#10;import pickle&#10;from collections import defaultdict&#10;&#10;# simulador completo del australian open 2025 que usa datos históricos&#10;&#10;def extract_historical_elos_and_h2h():&#10;    &quot;&quot;&quot;extrae los elos finales y historial h2h de todos los datos de entrenamiento&quot;&quot;&quot;&#10;    print(&quot;extrayendo elos y h2h históricos...&quot;)&#10;&#10;    # cargar todos los datos históricos&#10;    df_historical = load_train_data()&#10;    df_historical = clean_data(df_historical)&#10;&#10;    # calcular elos progresivamente en todo el dataset histórico&#10;    df_with_features = add_all_features(df_historical)&#10;&#10;    # extraer elos finales de cada jugador&#10;    final_elos = {}&#10;    final_surface_elos = {}&#10;&#10;    # obtener el último elo de cada jugador&#10;    for _, row in df_with_features.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;&#10;        final_elos[winner] = row[&quot;elo_winner&quot;]&#10;        final_elos[loser] = row[&quot;elo_loser&quot;]&#10;&#10;        # elos de superficie&#10;        surface = row.get(&quot;surface&quot;, &quot;Hard&quot;)&#10;        final_surface_elos[f&quot;{winner}_{surface}&quot;] = row[&quot;surface_elo_winner&quot;]&#10;        final_surface_elos[f&quot;{loser}_{surface}&quot;] = row[&quot;surface_elo_loser&quot;]&#10;&#10;    # extraer historial h2h completo&#10;    h2h_history = defaultdict(lambda: {&quot;count&quot;: 0, &quot;winner_wins&quot;: 0})&#10;&#10;    for _, row in df_historical.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;        pair = tuple(sorted([winner, loser]))&#10;&#10;        h2h_history[pair][&quot;count&quot;] += 1&#10;        # contar victorias del ganador&#10;        if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;            h2h_history[pair][&quot;winner_wins&quot;] += 1&#10;&#10;    print(f&quot;elos extraídos: {len(final_elos)} jugadores&quot;)&#10;    print(f&quot;h2h extraído: {len(h2h_history)} pares&quot;)&#10;&#10;    return final_elos, final_surface_elos, h2h_history&#10;&#10;def create_ao_2025_r32():&#10;    &quot;&quot;&quot;crea el dataframe base con los partidos de R32 del australian open 2025&quot;&quot;&quot;&#10;&#10;    # emparejamientos reales de la R32 (puedes actualizar con los datos reales)&#10;    r32_matches = [&#10;        # cuarto superior&#10;        {&quot;player1&quot;: &quot;Jannik Sinner&quot;, &quot;player2&quot;: &quot;Nicolas Jarry&quot;},&#10;        {&quot;player1&quot;: &quot;Daniil Medvedev&quot;, &quot;player2&quot;: &quot;Learner Tien&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Zverev&quot;, &quot;player2&quot;: &quot;Ugo Humbert&quot;},&#10;        {&quot;player1&quot;: &quot;Carlos Alcaraz&quot;, &quot;player2&quot;: &quot;Jack Draper&quot;},&#10;        {&quot;player1&quot;: &quot;Tommy Paul&quot;, &quot;player2&quot;: &quot;Alejandro Davidovich Fokina&quot;},&#10;        {&quot;player1&quot;: &quot;Ben Shelton&quot;, &quot;player2&quot;: &quot;Lorenzo Musetti&quot;},&#10;        {&quot;player1&quot;: &quot;Novak Djokovic&quot;, &quot;player2&quot;: &quot;Jiri Lehecka&quot;},&#10;        {&quot;player1&quot;: &quot;Taylor Fritz&quot;, &quot;player2&quot;: &quot;Gael Monfils&quot;},&#10;&#10;        # cuarto medio-superior&#10;        {&quot;player1&quot;: &quot;Casper Ruud&quot;, &quot;player2&quot;: &quot;Jenson Brooksby&quot;},&#10;        {&quot;player1&quot;: &quot;Alex de Minaur&quot;, &quot;player2&quot;: &quot;Alex Michelsen&quot;},&#10;        {&quot;player1&quot;: &quot;Stefanos Tsitsipas&quot;, &quot;player2&quot;: &quot;Thanasi Kokkinakis&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Korda&quot;, &quot;player2&quot;: &quot;Corentin Moutet&quot;},&#10;        {&quot;player1&quot;: &quot;Hubert Hurkacz&quot;, &quot;player2&quot;: &quot;Arthur Fils&quot;},&#10;        {&quot;player1&quot;: &quot;Frances Tiafoe&quot;, &quot;player2&quot;: &quot;Fabian Marozsan&quot;},&#10;        {&quot;player1&quot;: &quot;Grigor Dimitrov&quot;, &quot;player2&quot;: &quot;Rinky Hijikata&quot;},&#10;        {&quot;player1&quot;: &quot;Andrey Rublev&quot;, &quot;player2&quot;: &quot;Jakub Mensik&quot;},&#10;&#10;        # cuarto medio-inferior&#10;        {&quot;player1&quot;: &quot;Holger Rune&quot;, &quot;player2&quot;: &quot;Matteo Berrettini&quot;},&#10;        {&quot;player1&quot;: &quot;Lorenzo Sonego&quot;, &quot;player2&quot;: &quot;Facundo Diaz Acosta&quot;},&#10;        {&quot;player1&quot;: &quot;Felix Auger-Aliassime&quot;, &quot;player2&quot;: &quot;Botic van de Zandschulp&quot;},&#10;        {&quot;player1&quot;: &quot;Karen Khachanov&quot;, &quot;player2&quot;: &quot;Giovanni Mpetshi Perricard&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Baez&quot;, &quot;player2&quot;: &quot;Pavel Kotov&quot;},&#10;        {&quot;player1&quot;: &quot;Jordan Thompson&quot;, &quot;player2&quot;: &quot;Adrian Mannarino&quot;},&#10;        {&quot;player1&quot;: &quot;Francisco Cerundolo&quot;, &quot;player2&quot;: &quot;Tomas Martin Etcheverry&quot;},&#10;        {&quot;player1&quot;: &quot;Flavio Cobolli&quot;, &quot;player2&quot;: &quot;James Duckworth&quot;},&#10;&#10;        # cuarto inferior&#10;        {&quot;player1&quot;: &quot;Alexei Popyrin&quot;, &quot;player2&quot;: &quot;Marcos Giron&quot;},&#10;        {&quot;player1&quot;: &quot;Matteo Arnaldi&quot;, &quot;player2&quot;: &quot;Zhang Yifan&quot;},&#10;        {&quot;player1&quot;: &quot;Cameron Norrie&quot;, &quot;player2&quot;: &quot;Yoshihito Nishioka&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Bublik&quot;, &quot;player2&quot;: &quot;Brandon Nakashima&quot;},&#10;        {&quot;player1&quot;: &quot;Arthur Cazaux&quot;, &quot;player2&quot;: &quot;Nuno Borges&quot;},&#10;        {&quot;player1&quot;: &quot;Daniel Evans&quot;, &quot;player2&quot;: &quot;Quentin Halys&quot;},&#10;        {&quot;player1&quot;: &quot;Roman Safiullin&quot;, &quot;player2&quot;: &quot;Roberto Carballes Baena&quot;},&#10;        {&quot;player1&quot;: &quot;Mariano Navone&quot;, &quot;player2&quot;: &quot;Christopher O'Connell&quot;}&#10;    ]&#10;&#10;    # crear dataframe base&#10;    matches = []&#10;    for i, match in enumerate(r32_matches):&#10;        # crear fila base para cada partido&#10;        row = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,  # fecha estimada&#10;            &quot;match_num&quot;: i + 1,&#10;            &quot;winner_name&quot;: match[&quot;player1&quot;],  # placeholder, se determinará por predicción&#10;            &quot;loser_name&quot;: match[&quot;player2&quot;],   # placeholder&#10;            &quot;round&quot;: &quot;R32&quot;,&#10;            &quot;best_of&quot;: 5,&#10;            &quot;score&quot;: None,&#10;            &quot;minutes&quot;: None&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;]:&#10;            row[col] = None&#10;&#10;        matches.append(row)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def load_trained_model():&#10;    &quot;&quot;&quot;carga el modelo entrenado o entrena uno nuevo&quot;&quot;&quot;&#10;    model_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;trained_model.pkl&quot;)&#10;&#10;    if os.path.exists(model_path):&#10;        print(&quot;cargando modelo preentrenado...&quot;)&#10;        with open(model_path, 'rb') as f:&#10;            model = pickle.load(f)&#10;&#10;        # obtener las features exactas que usa el modelo&#10;        if hasattr(model, 'feature_names_in_'):&#10;            model_features = list(model.feature_names_in_)&#10;            print(f&quot;modelo entrenado con features: {model_features}&quot;)&#10;            return model, model_features&#10;        else:&#10;            # fallback a features por defecto&#10;            default_features = [&#10;                &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;                &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;                &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;                &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;                &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;                &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;                &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;            ]&#10;            return model, default_features&#10;    else:&#10;        print(&quot;entrenando nuevo modelo...&quot;)&#10;        # cargar datos de entrenamiento&#10;        features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;        df_train = pd.read_csv(features_train_path)&#10;        df_train = make_dual_rows(df_train)&#10;&#10;        feature_cols = [&#10;            &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;            &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;            &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;            &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,&#10;            &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;            &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;            &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;            &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;        ]&#10;&#10;        # filtrar features disponibles&#10;        available_features = [col for col in feature_cols if col in df_train.columns]&#10;        df_train = fillna_features(df_train, available_features)&#10;&#10;        X_train = df_train[available_features]&#10;        y_train = df_train[&quot;target&quot;]&#10;&#10;        model, _ = train_model(X_train, y_train)&#10;&#10;        # guardar modelo&#10;        os.makedirs(os.path.dirname(model_path), exist_ok=True)&#10;        with open(model_path, 'wb') as f:&#10;            pickle.dump(model, f)&#10;&#10;        return model, available_features&#10;&#10;def predict_match_winner(df_match, model, feature_cols):&#10;    &quot;&quot;&quot;predice el ganador de un partido específico&quot;&quot;&quot;&#10;&#10;    # generar features&#10;    df_processed = clean_data(df_match.copy())&#10;    df_features = add_all_features(df_processed)&#10;&#10;    # crear ambas versiones del partido (A vs B y B vs A)&#10;    df_balanced = make_dual_rows(df_features)&#10;    df_balanced = fillna_features(df_balanced, feature_cols)&#10;&#10;    # solo usar la primera fila (player1 como ganador)&#10;    X = df_balanced.iloc[[0]][feature_cols]&#10;&#10;    # predecir probabilidad&#10;    prob = model.predict_proba(X)[0][1]  # probabilidad de que player1 gane&#10;&#10;    # determinar ganador&#10;    if prob &gt; 0.5:&#10;        winner = df_match.iloc[0][&quot;winner_name&quot;]&#10;        loser = df_match.iloc[0][&quot;loser_name&quot;]&#10;        confidence = prob&#10;    else:&#10;        winner = df_match.iloc[0][&quot;loser_name&quot;]&#10;        loser = df_match.iloc[0][&quot;winner_name&quot;]&#10;        confidence = 1 - prob&#10;&#10;    return winner, loser, confidence&#10;&#10;def predict_match_winner_with_history(df_match, model, feature_cols,&#10;                                    current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;predice el ganador usando elos y h2h históricos actualizados&quot;&quot;&quot;&#10;&#10;    # obtener nombres de jugadores&#10;    player1 = df_match.iloc[0][&quot;winner_name&quot;]&#10;    player2 = df_match.iloc[0][&quot;loser_name&quot;]&#10;    surface = df_match.iloc[0][&quot;surface&quot;]&#10;&#10;    # obtener elos actuales (o por defecto si es jugador nuevo)&#10;    elo1 = current_elos.get(player1, 1500)&#10;    elo2 = current_elos.get(player2, 1500)&#10;&#10;    surface_elo1 = current_surface_elos.get(f&quot;{player1}_{surface}&quot;, 1500)&#10;    surface_elo2 = current_surface_elos.get(f&quot;{player2}_{surface}&quot;, 1500)&#10;&#10;    # obtener h2h actual&#10;    pair = tuple(sorted([player1, player2]))&#10;    h2h_data = current_h2h[pair]&#10;&#10;    # probar ambas configuraciones: player1 como ganador Y player2 como ganador&#10;    # y elegir la que tenga mayor probabilidad&#10;&#10;    configs = [&#10;        {&#10;            &quot;winner&quot;: player1, &quot;loser&quot;: player2,&#10;            &quot;elo_winner&quot;: elo1, &quot;elo_loser&quot;: elo2,&#10;            &quot;surface_elo_winner&quot;: surface_elo1, &quot;surface_elo_loser&quot;: surface_elo2&#10;        },&#10;        {&#10;            &quot;winner&quot;: player2, &quot;loser&quot;: player1,&#10;            &quot;elo_winner&quot;: elo2, &quot;elo_loser&quot;: elo1,&#10;            &quot;surface_elo_winner&quot;: surface_elo2, &quot;surface_elo_loser&quot;: surface_elo1&#10;        }&#10;    ]&#10;&#10;    best_prob = 0&#10;    best_winner = None&#10;    best_loser = None&#10;&#10;    for config in configs:&#10;        # calcular features para esta configuración&#10;        features_dict = {&#10;            &quot;elo_winner&quot;: config[&quot;elo_winner&quot;],&#10;            &quot;elo_loser&quot;: config[&quot;elo_loser&quot;],&#10;            &quot;elo_diff&quot;: config[&quot;elo_winner&quot;] - config[&quot;elo_loser&quot;],&#10;            &quot;surface_elo_winner&quot;: config[&quot;surface_elo_winner&quot;],&#10;            &quot;surface_elo_loser&quot;: config[&quot;surface_elo_loser&quot;],&#10;            &quot;surface_elo_diff&quot;: config[&quot;surface_elo_winner&quot;] - config[&quot;surface_elo_loser&quot;],&#10;        }&#10;&#10;        # features categóricas&#10;        elo_diff = config[&quot;elo_winner&quot;] - config[&quot;elo_loser&quot;]&#10;        features_dict[&quot;elo_advantage&quot;] = (2 if elo_diff &gt; 200 else&#10;                                        (1 if elo_diff &gt; 50 else&#10;                                        (-1 if elo_diff &lt; -50 else&#10;                                        (-2 if elo_diff &lt; -200 else 0))))&#10;&#10;        surface_elo_diff = config[&quot;surface_elo_winner&quot;] - config[&quot;surface_elo_loser&quot;]&#10;        features_dict[&quot;surface_elo_advantage&quot;] = (2 if surface_elo_diff &gt; 200 else&#10;                                                (1 if surface_elo_diff &gt; 50 else&#10;                                                (-1 if surface_elo_diff &lt; -50 else&#10;                                                (-2 if surface_elo_diff &lt; -200 else 0))))&#10;&#10;        # features de interacción&#10;        features_dict[&quot;elo_surface_interaction&quot;] = elo_diff * surface_elo_diff / 10000&#10;        features_dict[&quot;elo_consistency&quot;] = abs(elo_diff - surface_elo_diff)&#10;&#10;        # features de ranking (usar valores por defecto)&#10;        features_dict.update({&#10;            &quot;rank_diff&quot;: 0,&#10;            &quot;rank_advantage&quot;: 0,&#10;            &quot;rank_ratio&quot;: 1,&#10;            &quot;elo_rank_mismatch&quot;: 0&#10;        })&#10;&#10;        # features de tiers&#10;        def get_tier(elo):&#10;            if elo &lt; 1400: return 0&#10;            elif elo &lt; 1600: return 1&#10;            elif elo &lt; 1800: return 2&#10;            elif elo &lt; 2000: return 3&#10;            else: return 4&#10;&#10;        tier_winner = get_tier(config[&quot;elo_winner&quot;])&#10;        tier_loser = get_tier(config[&quot;elo_loser&quot;])&#10;        features_dict.update({&#10;            &quot;elo_tier_winner&quot;: tier_winner,&#10;            &quot;elo_tier_loser&quot;: tier_loser,&#10;            &quot;tier_diff&quot;: tier_winner - tier_loser&#10;        })&#10;&#10;        # features de competitividad&#10;        features_dict[&quot;match_competitiveness&quot;] = 1 / (1 + abs(elo_diff) / 100)&#10;        features_dict[&quot;is_upset_potential&quot;] = int(abs(elo_diff) &gt; 150)&#10;&#10;        # features h2h logarítmicas&#10;        h2h_count = h2h_data[&quot;count&quot;]&#10;        features_dict[&quot;h2h_count&quot;] = np.log1p(h2h_count)&#10;&#10;        if h2h_count == 0:&#10;            features_dict[&quot;h2h_balance&quot;] = 0&#10;        else:&#10;            winner_wins = h2h_data[&quot;winner_wins&quot;]&#10;            loser_wins = h2h_count - winner_wins&#10;&#10;            # determinar quién es quién en el historial&#10;            if config[&quot;winner&quot;] == min(pair):  # winner es el primero alfabéticamente&#10;                w_wins = winner_wins&#10;                l_wins = loser_wins&#10;            else:&#10;                w_wins = loser_wins&#10;                l_wins = winner_wins&#10;&#10;            features_dict[&quot;h2h_balance&quot;] = np.log1p(w_wins) - np.log1p(l_wins)&#10;&#10;        # crear dataframe con las features&#10;        feature_values = [features_dict.get(col, 0) for col in feature_cols]&#10;        X = pd.DataFrame([feature_values], columns=feature_cols)&#10;&#10;        # predecir probabilidad&#10;        prob = model.predict_proba(X)[0][1]&#10;&#10;        # si esta configuración es mejor, guardarla&#10;        if prob &gt; best_prob:&#10;            best_prob = prob&#10;            best_winner = config[&quot;winner&quot;]&#10;            best_loser = config[&quot;loser&quot;]&#10;&#10;    return best_winner, best_loser, best_prob&#10;&#10;def simulate_tournament_round(matches_df, model, feature_cols, round_name):&#10;    &quot;&quot;&quot;simula una ronda completa del torneo&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # predecir ganador&#10;        winner, loser, confidence = predict_match_winner(match_df, model, feature_cols)&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{match['winner_name']} vs {match['loser_name']}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence&#10;        }&#10;        results.append(result)&#10;&#10;        print(f&quot;  {match['winner_name']} vs {match['loser_name']} → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def simulate_tournament_round_with_history(matches_df, model, feature_cols, round_name,&#10;                                         current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;simula una ronda completa usando historial actualizado&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # obtener elos actuales para mostrar&#10;        player1 = match['winner_name']&#10;        player2 = match['loser_name']&#10;        elo1 = current_elos.get(player1, 1500)&#10;        elo2 = current_elos.get(player2, 1500)&#10;&#10;        # predecir ganador usando historial&#10;        winner, loser, confidence = predict_match_winner_with_history(&#10;            match_df, model, feature_cols, current_elos, current_surface_elos, current_h2h&#10;        )&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{player1} vs {player2}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence,&#10;            &quot;elo_player1&quot;: elo1,&#10;            &quot;elo_player2&quot;: elo2&#10;        }&#10;        results.append(result)&#10;&#10;        # actualizar elos y h2h después del partido&#10;        surface = match[&quot;surface&quot;]&#10;        update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos)&#10;        update_h2h_after_match(winner, loser, current_h2h)&#10;&#10;        print(f&quot;  {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f}) → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def create_next_round_matches(winners, round_name):&#10;    &quot;&quot;&quot;crea los emparejamientos de la siguiente ronda&quot;&quot;&quot;&#10;&#10;    if len(winners) % 2 != 0:&#10;        raise ValueError(f&quot;número impar de ganadores: {len(winners)}&quot;)&#10;&#10;    matches = []&#10;    for i in range(0, len(winners), 2):&#10;        match = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,&#10;            &quot;match_num&quot;: i//2 + 1,&#10;            &quot;winner_name&quot;: winners[i],&#10;            &quot;loser_name&quot;: winners[i+1],&#10;            &quot;round&quot;: round_name,&#10;            &quot;best_of&quot;: 5&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;, &quot;score&quot;, &quot;minutes&quot;]:&#10;            match[col] = None&#10;&#10;        matches.append(match)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos, k=32):&#10;    &quot;&quot;&quot;actualiza los elos después de un partido&quot;&quot;&quot;&#10;&#10;    # elos actuales&#10;    elo_w = current_elos.get(winner, 1500)&#10;    elo_l = current_elos.get(loser, 1500)&#10;&#10;    surface_elo_w = current_surface_elos.get(f&quot;{winner}_{surface}&quot;, 1500)&#10;    surface_elo_l = current_surface_elos.get(f&quot;{loser}_{surface}&quot;, 1500)&#10;&#10;    # actualizar elo global&#10;    expected_w = 1 / (1 + 10 ** ((elo_l - elo_w) / 400))&#10;    current_elos[winner] = elo_w + k * (1 - expected_w)&#10;    current_elos[loser] = elo_l + k * (0 - (1 - expected_w))&#10;&#10;    # actualizar elo de superficie&#10;    surface_expected_w = 1 / (1 + 10 ** ((surface_elo_l - surface_elo_w) / 400))&#10;    current_surface_elos[f&quot;{winner}_{surface}&quot;] = surface_elo_w + k * (1 - surface_expected_w)&#10;    current_surface_elos[f&quot;{loser}_{surface}&quot;] = surface_elo_l + k * (0 - (1 - surface_expected_w))&#10;&#10;def update_h2h_after_match(winner, loser, current_h2h):&#10;    &quot;&quot;&quot;actualiza el historial h2h después de un partido&quot;&quot;&quot;&#10;    pair = tuple(sorted([winner, loser]))&#10;    current_h2h[pair][&quot;count&quot;] += 1&#10;&#10;    # incrementar victorias del ganador&#10;    if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;        current_h2h[pair][&quot;winner_wins&quot;] += 1&#10;&#10;def simulate_australian_open_2025():&#10;    &quot;&quot;&quot;simula el torneo completo del australian open 2025 usando datos históricos&quot;&quot;&quot;&#10;&#10;    print(&quot;=== simulador australian open 2025 con datos históricos ===&quot;)&#10;&#10;    # extraer elos y h2h históricos del dataset de entrenamiento&#10;    current_elos, current_surface_elos, current_h2h = extract_historical_elos_and_h2h()&#10;&#10;    # cargar modelo entrenado y obtener sus features exactas&#10;    model, feature_cols = load_trained_model()&#10;&#10;    print(f&quot;usando features del modelo: {feature_cols}&quot;)&#10;&#10;    # generar R32&#10;    r32_df = create_ao_2025_r32()&#10;&#10;    # simular cada ronda con historial actualizado&#10;    all_results = []&#10;&#10;    # R32 (32 → 16)&#10;    r16_winners, r32_results = simulate_tournament_round_with_history(&#10;        r32_df, model, feature_cols, &quot;R32&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r32_results)&#10;&#10;    # R16 (16 → 8)&#10;    r16_df = create_next_round_matches(r16_winners, &quot;R16&quot;)&#10;    qf_winners, r16_results = simulate_tournament_round_with_history(&#10;        r16_df, model, feature_cols, &quot;R16&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r16_results)&#10;&#10;    # cuartos de final (8 → 4)&#10;    qf_df = create_next_round_matches(qf_winners, &quot;QF&quot;)&#10;    sf_winners, qf_results = simulate_tournament_round_with_history(&#10;        qf_df, model, feature_cols, &quot;QF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(qf_results)&#10;&#10;    # semifinales (4 → 2)&#10;    sf_df = create_next_round_matches(sf_winners, &quot;SF&quot;)&#10;    f_winners, sf_results = simulate_tournament_round_with_history(&#10;        sf_df, model, feature_cols, &quot;SF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(sf_results)&#10;&#10;    # final (2 → 1)&#10;    f_df = create_next_round_matches(f_winners, &quot;F&quot;)&#10;    champion, f_results = simulate_tournament_round_with_history(&#10;        f_df, model, feature_cols, &quot;F&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(f_results)&#10;&#10;    # resultados finales&#10;    print(f&quot;\ncampeón australian open 2025: {champion[0]}&quot;)&#10;    print(f&quot;finalista: {f_results[0]['loser']}&quot;)&#10;    print(f&quot;semifinalistas: {', '.join([r['loser'] for r in sf_results])}&quot;)&#10;&#10;    # mostrar algunos elos finales de jugadores top&#10;    top_players = [&quot;Jannik Sinner&quot;, &quot;Novak Djokovic&quot;, &quot;Carlos Alcaraz&quot;, &quot;Daniil Medvedev&quot;]&#10;    print(f&quot;\nelos finales después del torneo:&quot;)&#10;    for player in top_players:&#10;        if player in current_elos:&#10;            print(f&quot;  {player}: {current_elos[player]:.0f}&quot;)&#10;&#10;    # guardar resultados&#10;    results_df = pd.DataFrame(all_results)&#10;    output_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;australian_open_2025_results.csv&quot;)&#10;    os.makedirs(os.path.dirname(output_path), exist_ok=True)&#10;    results_df.to_csv(output_path, index=False)&#10;&#10;    print(f&quot;\nresultados guardados en: {output_path}&quot;)&#10;&#10;    return results_df, champion[0]&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    results, champion = simulate_australian_open_2025()&#10;    print(f&quot;\n simulación completada - campeón: {champion}&quot;)&#10;" />
              <option name="updatedContent" value="# src/australian_open_2025_simulator.py&#10;&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;from data_loader import BASE_DIR, load_train_data&#10;from preprocess import clean_data&#10;from features import add_all_features, compute_elo_ratings, compute_surface_elo, compute_h2h&#10;from utils import make_dual_rows, fillna_features&#10;from model import train_model&#10;import pickle&#10;from collections import defaultdict&#10;&#10;# simulador completo del australian open 2025 que usa datos históricos&#10;&#10;def extract_historical_elos_and_h2h():&#10;    &quot;&quot;&quot;extrae los elos finales y historial h2h de todos los datos de entrenamiento&quot;&quot;&quot;&#10;    print(&quot;extrayendo elos y h2h históricos...&quot;)&#10;&#10;    # cargar todos los datos históricos&#10;    df_historical = load_train_data()&#10;    df_historical = clean_data(df_historical)&#10;&#10;    # calcular elos progresivamente en todo el dataset histórico&#10;    df_with_features = add_all_features(df_historical)&#10;&#10;    # extraer elos finales de cada jugador&#10;    final_elos = {}&#10;    final_surface_elos = {}&#10;&#10;    # obtener el último elo de cada jugador&#10;    for _, row in df_with_features.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;&#10;        final_elos[winner] = row[&quot;elo_winner&quot;]&#10;        final_elos[loser] = row[&quot;elo_loser&quot;]&#10;&#10;        # elos de superficie&#10;        surface = row.get(&quot;surface&quot;, &quot;Hard&quot;)&#10;        final_surface_elos[f&quot;{winner}_{surface}&quot;] = row[&quot;surface_elo_winner&quot;]&#10;        final_surface_elos[f&quot;{loser}_{surface}&quot;] = row[&quot;surface_elo_loser&quot;]&#10;&#10;    # extraer historial h2h completo&#10;    h2h_history = defaultdict(lambda: {&quot;count&quot;: 0, &quot;winner_wins&quot;: 0})&#10;&#10;    for _, row in df_historical.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;        pair = tuple(sorted([winner, loser]))&#10;&#10;        h2h_history[pair][&quot;count&quot;] += 1&#10;        # contar victorias del ganador&#10;        if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;            h2h_history[pair][&quot;winner_wins&quot;] += 1&#10;&#10;    print(f&quot;elos extraídos: {len(final_elos)} jugadores&quot;)&#10;    print(f&quot;h2h extraído: {len(h2h_history)} pares&quot;)&#10;&#10;    return final_elos, final_surface_elos, h2h_history&#10;&#10;def create_ao_2025_r32():&#10;    &quot;&quot;&quot;crea el dataframe base con los partidos de R32 del australian open 2025&quot;&quot;&quot;&#10;&#10;    # emparejamientos reales de la R32 (puedes actualizar con los datos reales)&#10;    r32_matches = [&#10;        # cuarto superior&#10;        {&quot;player1&quot;: &quot;Jannik Sinner&quot;, &quot;player2&quot;: &quot;Nicolas Jarry&quot;},&#10;        {&quot;player1&quot;: &quot;Daniil Medvedev&quot;, &quot;player2&quot;: &quot;Learner Tien&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Zverev&quot;, &quot;player2&quot;: &quot;Ugo Humbert&quot;},&#10;        {&quot;player1&quot;: &quot;Carlos Alcaraz&quot;, &quot;player2&quot;: &quot;Jack Draper&quot;},&#10;        {&quot;player1&quot;: &quot;Tommy Paul&quot;, &quot;player2&quot;: &quot;Alejandro Davidovich Fokina&quot;},&#10;        {&quot;player1&quot;: &quot;Ben Shelton&quot;, &quot;player2&quot;: &quot;Lorenzo Musetti&quot;},&#10;        {&quot;player1&quot;: &quot;Novak Djokovic&quot;, &quot;player2&quot;: &quot;Jiri Lehecka&quot;},&#10;        {&quot;player1&quot;: &quot;Taylor Fritz&quot;, &quot;player2&quot;: &quot;Gael Monfils&quot;},&#10;&#10;        # cuarto medio-superior&#10;        {&quot;player1&quot;: &quot;Casper Ruud&quot;, &quot;player2&quot;: &quot;Jenson Brooksby&quot;},&#10;        {&quot;player1&quot;: &quot;Alex de Minaur&quot;, &quot;player2&quot;: &quot;Alex Michelsen&quot;},&#10;        {&quot;player1&quot;: &quot;Stefanos Tsitsipas&quot;, &quot;player2&quot;: &quot;Thanasi Kokkinakis&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Korda&quot;, &quot;player2&quot;: &quot;Corentin Moutet&quot;},&#10;        {&quot;player1&quot;: &quot;Hubert Hurkacz&quot;, &quot;player2&quot;: &quot;Arthur Fils&quot;},&#10;        {&quot;player1&quot;: &quot;Frances Tiafoe&quot;, &quot;player2&quot;: &quot;Fabian Marozsan&quot;},&#10;        {&quot;player1&quot;: &quot;Grigor Dimitrov&quot;, &quot;player2&quot;: &quot;Rinky Hijikata&quot;},&#10;        {&quot;player1&quot;: &quot;Andrey Rublev&quot;, &quot;player2&quot;: &quot;Jakub Mensik&quot;},&#10;&#10;        # cuarto medio-inferior&#10;        {&quot;player1&quot;: &quot;Holger Rune&quot;, &quot;player2&quot;: &quot;Matteo Berrettini&quot;},&#10;        {&quot;player1&quot;: &quot;Lorenzo Sonego&quot;, &quot;player2&quot;: &quot;Facundo Diaz Acosta&quot;},&#10;        {&quot;player1&quot;: &quot;Felix Auger-Aliassime&quot;, &quot;player2&quot;: &quot;Botic van de Zandschulp&quot;},&#10;        {&quot;player1&quot;: &quot;Karen Khachanov&quot;, &quot;player2&quot;: &quot;Giovanni Mpetshi Perricard&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Baez&quot;, &quot;player2&quot;: &quot;Pavel Kotov&quot;},&#10;        {&quot;player1&quot;: &quot;Jordan Thompson&quot;, &quot;player2&quot;: &quot;Adrian Mannarino&quot;},&#10;        {&quot;player1&quot;: &quot;Francisco Cerundolo&quot;, &quot;player2&quot;: &quot;Tomas Martin Etcheverry&quot;},&#10;        {&quot;player1&quot;: &quot;Flavio Cobolli&quot;, &quot;player2&quot;: &quot;James Duckworth&quot;},&#10;&#10;        # cuarto inferior&#10;        {&quot;player1&quot;: &quot;Alexei Popyrin&quot;, &quot;player2&quot;: &quot;Marcos Giron&quot;},&#10;        {&quot;player1&quot;: &quot;Matteo Arnaldi&quot;, &quot;player2&quot;: &quot;Zhang Yifan&quot;},&#10;        {&quot;player1&quot;: &quot;Cameron Norrie&quot;, &quot;player2&quot;: &quot;Yoshihito Nishioka&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Bublik&quot;, &quot;player2&quot;: &quot;Brandon Nakashima&quot;},&#10;        {&quot;player1&quot;: &quot;Arthur Cazaux&quot;, &quot;player2&quot;: &quot;Nuno Borges&quot;},&#10;        {&quot;player1&quot;: &quot;Daniel Evans&quot;, &quot;player2&quot;: &quot;Quentin Halys&quot;},&#10;        {&quot;player1&quot;: &quot;Roman Safiullin&quot;, &quot;player2&quot;: &quot;Roberto Carballes Baena&quot;},&#10;        {&quot;player1&quot;: &quot;Mariano Navone&quot;, &quot;player2&quot;: &quot;Christopher O'Connell&quot;}&#10;    ]&#10;&#10;    # crear dataframe base&#10;    matches = []&#10;    for i, match in enumerate(r32_matches):&#10;        # crear fila base para cada partido&#10;        row = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,  # fecha estimada&#10;            &quot;match_num&quot;: i + 1,&#10;            &quot;winner_name&quot;: match[&quot;player1&quot;],  # placeholder, se determinará por predicción&#10;            &quot;loser_name&quot;: match[&quot;player2&quot;],   # placeholder&#10;            &quot;round&quot;: &quot;R32&quot;,&#10;            &quot;best_of&quot;: 5,&#10;            &quot;score&quot;: None,&#10;            &quot;minutes&quot;: None&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;]:&#10;            row[col] = None&#10;&#10;        matches.append(row)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def load_trained_model():&#10;    &quot;&quot;&quot;carga el modelo entrenado o entrena uno nuevo&quot;&quot;&quot;&#10;    model_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;trained_model.pkl&quot;)&#10;&#10;    if os.path.exists(model_path):&#10;        print(&quot;cargando modelo preentrenado...&quot;)&#10;        with open(model_path, 'rb') as f:&#10;            model = pickle.load(f)&#10;&#10;        # obtener las features exactas que usa el modelo&#10;        if hasattr(model, 'feature_names_in_'):&#10;            model_features = list(model.feature_names_in_)&#10;            print(f&quot;modelo entrenado con features: {model_features}&quot;)&#10;            return model, model_features&#10;        else:&#10;            # fallback a features por defecto&#10;            default_features = [&#10;                &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;                &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;                &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;                &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;                &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;                &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;                &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;            ]&#10;            return model, default_features&#10;    else:&#10;        print(&quot;entrenando nuevo modelo...&quot;)&#10;        # cargar datos de entrenamiento&#10;        features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;        df_train = pd.read_csv(features_train_path)&#10;        df_train = make_dual_rows(df_train)&#10;&#10;        feature_cols = [&#10;            &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;            &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;            &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;            &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,&#10;            &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;            &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;            &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;            &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;        ]&#10;&#10;        # filtrar features disponibles&#10;        available_features = [col for col in feature_cols if col in df_train.columns]&#10;        df_train = fillna_features(df_train, available_features)&#10;&#10;        X_train = df_train[available_features]&#10;        y_train = df_train[&quot;target&quot;]&#10;&#10;        model, _ = train_model(X_train, y_train)&#10;&#10;        # guardar modelo&#10;        os.makedirs(os.path.dirname(model_path), exist_ok=True)&#10;        with open(model_path, 'wb') as f:&#10;            pickle.dump(model, f)&#10;&#10;        return model, available_features&#10;&#10;def predict_match_winner(df_match, model, feature_cols):&#10;    &quot;&quot;&quot;predice el ganador de un partido específico&quot;&quot;&quot;&#10;&#10;    # generar features&#10;    df_processed = clean_data(df_match.copy())&#10;    df_features = add_all_features(df_processed)&#10;&#10;    # crear ambas versiones del partido (A vs B y B vs A)&#10;    df_balanced = make_dual_rows(df_features)&#10;    df_balanced = fillna_features(df_balanced, feature_cols)&#10;&#10;    # solo usar la primera fila (player1 como ganador)&#10;    X = df_balanced.iloc[[0]][feature_cols]&#10;&#10;    # predecir probabilidad&#10;    prob = model.predict_proba(X)[0][1]  # probabilidad de que player1 gane&#10;&#10;    # determinar ganador&#10;    if prob &gt; 0.5:&#10;        winner = df_match.iloc[0][&quot;winner_name&quot;]&#10;        loser = df_match.iloc[0][&quot;loser_name&quot;]&#10;        confidence = prob&#10;    else:&#10;        winner = df_match.iloc[0][&quot;loser_name&quot;]&#10;        loser = df_match.iloc[0][&quot;winner_name&quot;]&#10;        confidence = 1 - prob&#10;&#10;    return winner, loser, confidence&#10;&#10;def predict_match_winner_with_history(df_match, model, feature_cols,&#10;                                    current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;predice el ganador usando elos y h2h históricos actualizados&quot;&quot;&quot;&#10;&#10;    # obtener nombres de jugadores&#10;    player1 = df_match.iloc[0][&quot;winner_name&quot;]&#10;    player2 = df_match.iloc[0][&quot;loser_name&quot;]&#10;    surface = df_match.iloc[0][&quot;surface&quot;]&#10;&#10;    # obtener elos actuales (o por defecto si es jugador nuevo)&#10;    elo1 = current_elos.get(player1, 1500)&#10;    elo2 = current_elos.get(player2, 1500)&#10;&#10;    surface_elo1 = current_surface_elos.get(f&quot;{player1}_{surface}&quot;, 1500)&#10;    surface_elo2 = current_surface_elos.get(f&quot;{player2}_{surface}&quot;, 1500)&#10;&#10;    # obtener h2h actual&#10;    pair = tuple(sorted([player1, player2]))&#10;    h2h_data = current_h2h[pair]&#10;&#10;    # calcular features manualmente para player1 como ganador&#10;    features_dict = {&#10;        &quot;elo_winner&quot;: elo1,&#10;        &quot;elo_loser&quot;: elo2,&#10;        &quot;elo_diff&quot;: elo1 - elo2,&#10;        &quot;surface_elo_winner&quot;: surface_elo1,&#10;        &quot;surface_elo_loser&quot;: surface_elo2,&#10;        &quot;surface_elo_diff&quot;: surface_elo1 - surface_elo2,&#10;    }&#10;&#10;    # features categóricas&#10;    elo_diff = elo1 - elo2&#10;    features_dict[&quot;elo_advantage&quot;] = (2 if elo_diff &gt; 200 else&#10;                                    (1 if elo_diff &gt; 50 else&#10;                                    (-1 if elo_diff &lt; -50 else&#10;                                    (-2 if elo_diff &lt; -200 else 0))))&#10;&#10;    surface_elo_diff = surface_elo1 - surface_elo2&#10;    features_dict[&quot;surface_elo_advantage&quot;] = (2 if surface_elo_diff &gt; 200 else&#10;                                            (1 if surface_elo_diff &gt; 50 else&#10;                                            (-1 if surface_elo_diff &lt; -50 else&#10;                                            (-2 if surface_elo_diff &lt; -200 else 0))))&#10;&#10;    # features de interacción&#10;    features_dict[&quot;elo_surface_interaction&quot;] = elo_diff * surface_elo_diff / 10000&#10;    features_dict[&quot;elo_consistency&quot;] = abs(elo_diff - surface_elo_diff)&#10;&#10;    # features de ranking (usar valores por defecto)&#10;    features_dict.update({&#10;        &quot;rank_diff&quot;: 0,&#10;        &quot;rank_advantage&quot;: 0,&#10;        &quot;rank_ratio&quot;: 1,&#10;        &quot;elo_rank_mismatch&quot;: 0&#10;    })&#10;&#10;    # features de tiers&#10;    def get_tier(elo):&#10;        if elo &lt; 1400: return 0&#10;        elif elo &lt; 1600: return 1&#10;        elif elo &lt; 1800: return 2&#10;        elif elo &lt; 2000: return 3&#10;        else: return 4&#10;&#10;    tier1 = get_tier(elo1)&#10;    tier2 = get_tier(elo2)&#10;    features_dict.update({&#10;        &quot;elo_tier_winner&quot;: tier1,&#10;        &quot;elo_tier_loser&quot;: tier2,&#10;        &quot;tier_diff&quot;: tier1 - tier2&#10;    })&#10;&#10;    # features de competitividad&#10;    features_dict[&quot;match_competitiveness&quot;] = 1 / (1 + abs(elo_diff) / 100)&#10;    features_dict[&quot;is_upset_potential&quot;] = int(abs(elo_diff) &gt; 150)&#10;&#10;    # features h2h logarítmicas&#10;    h2h_count = h2h_data[&quot;count&quot;]&#10;    features_dict[&quot;h2h_count&quot;] = np.log1p(h2h_count)&#10;&#10;    if h2h_count == 0:&#10;        features_dict[&quot;h2h_balance&quot;] = 0&#10;    else:&#10;        winner_wins = h2h_data[&quot;winner_wins&quot;]&#10;        loser_wins = h2h_count - winner_wins&#10;&#10;        # determinar quién es quién en el historial&#10;        if player1 == min(pair):  # player1 es el primero alfabéticamente&#10;            p1_wins = winner_wins&#10;            p2_wins = loser_wins&#10;        else:&#10;            p1_wins = loser_wins&#10;            p2_wins = winner_wins&#10;&#10;        features_dict[&quot;h2h_balance&quot;] = np.log1p(p1_wins) - np.log1p(p2_wins)&#10;&#10;    # crear dataframe con las features y predecir&#10;    feature_values = [features_dict.get(col, 0) for col in feature_cols]&#10;    X = pd.DataFrame([feature_values], columns=feature_cols)&#10;&#10;    # predecir probabilidad de que player1 gane&#10;    prob_player1_wins = model.predict_proba(X)[0][1]&#10;    &#10;    # debug: imprimir información solo para algunos casos extremos&#10;    if prob_player1_wins &gt; 0.99 or prob_player1_wins &lt; 0.01:&#10;        print(f&quot;    DEBUG - {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f})&quot;)&#10;        print(f&quot;    ELO diff: {elo_diff:.0f}, Surface ELO diff: {surface_elo_diff:.0f}&quot;)&#10;        print(f&quot;    ELO advantage: {features_dict['elo_advantage']}, Tier diff: {features_dict['tier_diff']}&quot;)&#10;        print(f&quot;    H2H count: {h2h_count}, H2H balance: {features_dict['h2h_balance']:.3f}&quot;)&#10;        print(f&quot;    Raw probability: {prob_player1_wins:.6f}&quot;)&#10;&#10;    # determinar ganador basado en probabilidad&#10;    if prob_player1_wins &gt; 0.5:&#10;        return player1, player2, prob_player1_wins&#10;    else:&#10;        return player2, player1, 1 - prob_player1_wins&#10;&#10;def simulate_tournament_round(matches_df, model, feature_cols, round_name):&#10;    &quot;&quot;&quot;simula una ronda completa del torneo&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # predecir ganador&#10;        winner, loser, confidence = predict_match_winner(match_df, model, feature_cols)&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{match['winner_name']} vs {match['loser_name']}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence&#10;        }&#10;        results.append(result)&#10;&#10;        print(f&quot;  {match['winner_name']} vs {match['loser_name']} → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def simulate_tournament_round_with_history(matches_df, model, feature_cols, round_name,&#10;                                         current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;simula una ronda completa usando historial actualizado&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # obtener elos actuales para mostrar&#10;        player1 = match['winner_name']&#10;        player2 = match['loser_name']&#10;        elo1 = current_elos.get(player1, 1500)&#10;        elo2 = current_elos.get(player2, 1500)&#10;&#10;        # predecir ganador usando historial&#10;        winner, loser, confidence = predict_match_winner_with_history(&#10;            match_df, model, feature_cols, current_elos, current_surface_elos, current_h2h&#10;        )&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{player1} vs {player2}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence,&#10;            &quot;elo_player1&quot;: elo1,&#10;            &quot;elo_player2&quot;: elo2&#10;        }&#10;        results.append(result)&#10;&#10;        # actualizar elos y h2h después del partido&#10;        surface = match[&quot;surface&quot;]&#10;        update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos)&#10;        update_h2h_after_match(winner, loser, current_h2h)&#10;&#10;        print(f&quot;  {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f}) → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def create_next_round_matches(winners, round_name):&#10;    &quot;&quot;&quot;crea los emparejamientos de la siguiente ronda&quot;&quot;&quot;&#10;&#10;    if len(winners) % 2 != 0:&#10;        raise ValueError(f&quot;número impar de ganadores: {len(winners)}&quot;)&#10;&#10;    matches = []&#10;    for i in range(0, len(winners), 2):&#10;        match = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,&#10;            &quot;match_num&quot;: i//2 + 1,&#10;            &quot;winner_name&quot;: winners[i],&#10;            &quot;loser_name&quot;: winners[i+1],&#10;            &quot;round&quot;: round_name,&#10;            &quot;best_of&quot;: 5&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;, &quot;score&quot;, &quot;minutes&quot;]:&#10;            match[col] = None&#10;&#10;        matches.append(match)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos, k=32):&#10;    &quot;&quot;&quot;actualiza los elos después de un partido&quot;&quot;&quot;&#10;&#10;    # elos actuales&#10;    elo_w = current_elos.get(winner, 1500)&#10;    elo_l = current_elos.get(loser, 1500)&#10;&#10;    surface_elo_w = current_surface_elos.get(f&quot;{winner}_{surface}&quot;, 1500)&#10;    surface_elo_l = current_surface_elos.get(f&quot;{loser}_{surface}&quot;, 1500)&#10;&#10;    # actualizar elo global&#10;    expected_w = 1 / (1 + 10 ** ((elo_l - elo_w) / 400))&#10;    current_elos[winner] = elo_w + k * (1 - expected_w)&#10;    current_elos[loser] = elo_l + k * (0 - (1 - expected_w))&#10;&#10;    # actualizar elo de superficie&#10;    surface_expected_w = 1 / (1 + 10 ** ((surface_elo_l - surface_elo_w) / 400))&#10;    current_surface_elos[f&quot;{winner}_{surface}&quot;] = surface_elo_w + k * (1 - surface_expected_w)&#10;    current_surface_elos[f&quot;{loser}_{surface}&quot;] = surface_elo_l + k * (0 - (1 - surface_expected_w))&#10;&#10;def update_h2h_after_match(winner, loser, current_h2h):&#10;    &quot;&quot;&quot;actualiza el historial h2h después de un partido&quot;&quot;&quot;&#10;    pair = tuple(sorted([winner, loser]))&#10;    current_h2h[pair][&quot;count&quot;] += 1&#10;&#10;    # incrementar victorias del ganador&#10;    if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;        current_h2h[pair][&quot;winner_wins&quot;] += 1&#10;&#10;def simulate_australian_open_2025():&#10;    &quot;&quot;&quot;simula el torneo completo del australian open 2025 usando datos históricos&quot;&quot;&quot;&#10;&#10;    print(&quot;=== simulador australian open 2025 con datos históricos ===&quot;)&#10;&#10;    # extraer elos y h2h históricos del dataset de entrenamiento&#10;    current_elos, current_surface_elos, current_h2h = extract_historical_elos_and_h2h()&#10;&#10;    # cargar modelo entrenado y obtener sus features exactas&#10;    model, feature_cols = load_trained_model()&#10;&#10;    print(f&quot;usando features del modelo: {feature_cols}&quot;)&#10;&#10;    # generar R32&#10;    r32_df = create_ao_2025_r32()&#10;&#10;    # simular cada ronda con historial actualizado&#10;    all_results = []&#10;&#10;    # R32 (32 → 16)&#10;    r16_winners, r32_results = simulate_tournament_round_with_history(&#10;        r32_df, model, feature_cols, &quot;R32&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r32_results)&#10;&#10;    # R16 (16 → 8)&#10;    r16_df = create_next_round_matches(r16_winners, &quot;R16&quot;)&#10;    qf_winners, r16_results = simulate_tournament_round_with_history(&#10;        r16_df, model, feature_cols, &quot;R16&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r16_results)&#10;&#10;    # cuartos de final (8 → 4)&#10;    qf_df = create_next_round_matches(qf_winners, &quot;QF&quot;)&#10;    sf_winners, qf_results = simulate_tournament_round_with_history(&#10;        qf_df, model, feature_cols, &quot;QF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(qf_results)&#10;&#10;    # semifinales (4 → 2)&#10;    sf_df = create_next_round_matches(sf_winners, &quot;SF&quot;)&#10;    f_winners, sf_results = simulate_tournament_round_with_history(&#10;        sf_df, model, feature_cols, &quot;SF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(sf_results)&#10;&#10;    # final (2 → 1)&#10;    f_df = create_next_round_matches(f_winners, &quot;F&quot;)&#10;    champion, f_results = simulate_tournament_round_with_history(&#10;        f_df, model, feature_cols, &quot;F&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(f_results)&#10;&#10;    # resultados finales&#10;    print(f&quot;\ncampeón australian open 2025: {champion[0]}&quot;)&#10;    print(f&quot;finalista: {f_results[0]['loser']}&quot;)&#10;    print(f&quot;semifinalistas: {', '.join([r['loser'] for r in sf_results])}&quot;)&#10;&#10;    # mostrar algunos elos finales de jugadores top&#10;    top_players = [&quot;Jannik Sinner&quot;, &quot;Novak Djokovic&quot;, &quot;Carlos Alcaraz&quot;, &quot;Daniil Medvedev&quot;]&#10;    print(f&quot;\nelos finales después del torneo:&quot;)&#10;    for player in top_players:&#10;        if player in current_elos:&#10;            print(f&quot;  {player}: {current_elos[player]:.0f}&quot;)&#10;&#10;    # guardar resultados&#10;    results_df = pd.DataFrame(all_results)&#10;    output_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;australian_open_2025_results.csv&quot;)&#10;    os.makedirs(os.path.dirname(output_path), exist_ok=True)&#10;    results_df.to_csv(output_path, index=False)&#10;&#10;    print(f&quot;\nresultados guardados en: {output_path}&quot;)&#10;&#10;    return results_df, champion[0]&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    results, champion = simulate_australian_open_2025()&#10;    print(f&quot;\n simulación completada - campeón: {champion}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/model_service.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/model_service.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;model_service.py&#10;Servicio principal para manejar modelos y predicciones de tenis&#10;&quot;&quot;&quot;&#10;import pickle&#10;import json&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;from datetime import datetime&#10;from typing import Dict, List, Optional&#10;import logging&#10;from sklearn.impute import SimpleImputer&#10;&#10;# Import local modules - arreglando imports para funcionar en diferentes contextos&#10;try:&#10;    from .models import PredictResponse, PlayerStats, ModelInfo&#10;    from .features import create_features_for_prediction, get_curated_features&#10;except ImportError:&#10;    try:&#10;        from src.models import PredictResponse, PlayerStats, ModelInfo&#10;        from src.features import create_features_for_prediction, get_curated_features&#10;    except ImportError:&#10;        from models import PredictResponse, PlayerStats, ModelInfo&#10;        from features import create_features_for_prediction, get_curated_features&#10;&#10;# Configurar logging&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;class TennisModelService:&#10;    &quot;&quot;&quot;Servicio para manejar el modelo de predicción de tenis&quot;&quot;&quot;&#10;&#10;    def __init__(self, base_path: str = None):&#10;        self.base_path = Path(base_path) if base_path else Path(__file__).parent.parent&#10;        self.outputs_path = self.base_path / &quot;outputs&quot;&#10;        self.data_path = self.base_path / &quot;data&quot;&#10;&#10;        # Artefactos del modelo&#10;        self.model = None&#10;        self.imputer = None&#10;        self.players_list = None&#10;        self.feature_importance = None&#10;        self.model_summary = None&#10;        self.training_states = None&#10;&#10;        # Datos de entrenamiento para features históricas&#10;        self.train_data = None&#10;        self.test_data = None&#10;&#10;        self.is_loaded = False&#10;&#10;    def load_model_artifacts(self) -&gt; bool:&#10;        &quot;&quot;&quot;Cargar todos los artefactos del modelo&quot;&quot;&quot;&#10;        try:&#10;            logger.info(&quot;Cargando artefactos del modelo...&quot;)&#10;&#10;            # Cargar modelo principal&#10;            model_path = self.outputs_path / &quot;best_xgb_model.pkl&quot;&#10;            if model_path.exists():&#10;                with open(model_path, 'rb') as f:&#10;                    self.model = pickle.load(f)&#10;                logger.info(&quot;✓ Modelo XGBoost cargado&quot;)&#10;            else:&#10;                logger.error(f&quot;Modelo no encontrado en {model_path}&quot;)&#10;                return False&#10;&#10;            # Cargar imputer&#10;            imputer_path = self.outputs_path / &quot;imputer.pkl&quot;&#10;            if imputer_path.exists():&#10;                with open(imputer_path, 'rb') as f:&#10;                    self.imputer = pickle.load(f)&#10;                # Log adicional para diagnóstico&#10;                try:&#10;                    if hasattr(self.imputer, 'feature_names_in_'):&#10;                        names = list(self.imputer.feature_names_in_)&#10;                        logger.info(f&quot;✓ Imputer cargado (feature_names_in_ len={len(names)}) sample={names[:10]}&quot;)&#10;                    else:&#10;                        logger.info(&quot;✓ Imputer cargado (sin feature_names_in_)&quot;)&#10;                except Exception as e:&#10;                    logger.warning(f&quot;Imputer cargado pero no se pudo leer feature_names_in_: {e}&quot;)&#10;            else:&#10;                logger.warning(&quot;Imputer no encontrado, creando uno nuevo&quot;)&#10;                self.imputer = SimpleImputer(strategy='median')&#10;&#10;            # Cargar lista de jugadores - forzar regeneración si contiene nombres inválidos&#10;            players_path = self.outputs_path / &quot;players_list.pkl&quot;&#10;            should_regenerate = False&#10;&#10;            if players_path.exists():&#10;                with open(players_path, 'rb') as f:&#10;                    temp_players_list = pickle.load(f)&#10;&#10;                # Verificar si la lista tiene nombres con espacios al inicio&#10;                invalid_names = [p for p in temp_players_list[:10] if p.startswith(' ')]&#10;                if invalid_names:&#10;                    logger.info(&quot;Lista de jugadores contiene nombres inválidos, regenerando...&quot;)&#10;                    should_regenerate = True&#10;                    # Eliminar archivo corrupto&#10;                    try:&#10;                        players_path.unlink()&#10;                        logger.info(&quot;✓ Archivo players_list.pkl eliminado&quot;)&#10;                    except:&#10;                        pass&#10;                else:&#10;                    self.players_list = temp_players_list&#10;                    logger.info(f&quot;✓ Lista de {len(self.players_list)} jugadores cargada desde pickle&quot;)&#10;            else:&#10;                should_regenerate = True&#10;&#10;            if should_regenerate:&#10;                logger.info(&quot;Generando nueva lista de jugadores...&quot;)&#10;                self.players_list = self._extract_players_from_data()&#10;&#10;            # Cargar importancia de features&#10;            importance_path = self.outputs_path / &quot;feature_importance.csv&quot;&#10;            if importance_path.exists():&#10;                self.feature_importance = pd.read_csv(importance_path)&#10;                logger.info(&quot;✓ Importancia de features cargada&quot;)&#10;            else:&#10;                logger.warning(&quot;Importancia de features no encontrada&quot;)&#10;&#10;            # Cargar resumen del modelo&#10;            summary_path = self.outputs_path / &quot;model_summary.json&quot;&#10;            if summary_path.exists():&#10;                with open(summary_path, 'r') as f:&#10;                    self.model_summary = json.load(f)&#10;                logger.info(&quot;✓ Resumen del modelo cargado&quot;)&#10;            else:&#10;                logger.warning(&quot;Resumen del modelo no encontrado&quot;)&#10;&#10;            # Cargar estados de entrenamiento&#10;            states_path = self.outputs_path / &quot;training_states.pkl&quot;&#10;            if states_path.exists():&#10;                with open(states_path, 'rb') as f:&#10;                    self.training_states = pickle.load(f)&#10;                logger.info(&quot;✓ Estados de entrenamiento cargados&quot;)&#10;                # Log breve de feature_columns si existen&#10;                try:&#10;                    fc = self.training_states.get('feature_columns')&#10;                    if fc is not None:&#10;                        logger.info(f&quot;  - training_states.feature_columns len={len(fc)} sample={fc[:10]}&quot;)&#10;                    else:&#10;                        logger.info(&quot;  - training_states.feature_columns no presente&quot;)&#10;                except Exception as e:&#10;                    logger.warning(f&quot;No se pudo leer feature_columns de training_states: {e}&quot;)&#10;&#10;            # --- VALIDAR Y RECONSTRUIR IMPUTER SI ES NECESARIO ---&#10;            try:&#10;                # Determinar columnas esperadas (training_states &gt; feature_importance)&#10;                expected_cols = None&#10;                if self.training_states and isinstance(self.training_states, dict):&#10;                    expected_cols = self.training_states.get('feature_columns')&#10;                if expected_cols is None and self.feature_importance is not None:&#10;                    try:&#10;                        expected_cols = self.feature_importance['Feature'].tolist()&#10;                    except Exception:&#10;                        expected_cols = None&#10;&#10;                if expected_cols is not None and self.imputer is not None:&#10;                    bad_imputer = False&#10;                    try:&#10;                        imputer_names = list(getattr(self.imputer, 'feature_names_in_', []))&#10;                        # Si no hay nombres, no los consideramos malos aquí&#10;                        if imputer_names:&#10;                            # Detectar nombres genéricos problemáticos&#10;                            if any(n == 'feature' or n.startswith('feature_') or n.startswith('Unnamed') for n in imputer_names):&#10;                                bad_imputer = True&#10;                            # Detectar mismatch de longitud&#10;                            elif len(imputer_names) != len(expected_cols):&#10;                                bad_imputer = True&#10;                            else:&#10;                                # Detectar nombres que no aparecen en expected_cols&#10;                                if any(n not in expected_cols for n in imputer_names):&#10;                                    bad_imputer = True&#10;                    except Exception:&#10;                        bad_imputer = True&#10;&#10;                    if bad_imputer:&#10;                        logger.warning(&quot;Imputer con feature_names_in_ inválidos detectado — reconstruyendo basado en columnas esperadas&quot;)&#10;                        # Guardar backup del imputer original&#10;                        try:&#10;                            backup_path = self.outputs_path / &quot;imputer_backup.pkl&quot;&#10;                            with open(backup_path, 'wb') as f:&#10;                                pickle.dump(self.imputer, f)&#10;                            logger.info(f&quot;✓ Backup del imputer original guardado en {backup_path}&quot;)&#10;                        except Exception as e:&#10;                            logger.warning(f&quot;No se pudo guardar backup del imputer original: {e}&quot;)&#10;&#10;                        # Reconstruir un nuevo imputer y ajustarlo sobre una fila dummy con las columnas esperadas&#10;                        try:&#10;                            new_imputer = SimpleImputer(strategy='median')&#10;                            dummy = pd.DataFrame([[0.0] * len(expected_cols)], columns=expected_cols)&#10;                            new_imputer.fit(dummy)&#10;                            self.imputer = new_imputer&#10;                            # Guardar imputer reconstruido&#10;                            try:&#10;                                with open(self.outputs_path / &quot;imputer.pkl&quot;, 'wb') as f:&#10;                                    pickle.dump(self.imputer, f)&#10;                                logger.info(&quot;✓ Nuevo imputer guardado en outputs/imputer.pkl&quot;)&#10;                            except Exception as e:&#10;                                logger.warning(f&quot;No se pudo guardar el nuevo imputer: {e}&quot;)&#10;                        except Exception as e:&#10;                            logger.error(f&quot;Error reconstruyendo el imputer: {e}&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo validar/reconstruir imputer: {e}&quot;)&#10;&#10;            # Cargar datos de entrenamiento para features&#10;            self._load_training_data()&#10;&#10;            # Log feature_importance sample&#10;            try:&#10;                if self.feature_importance is not None:&#10;                    sample_feats = self.feature_importance['Feature'].tolist()[:10]&#10;                    logger.info(f&quot;✓ feature_importance sample: {sample_feats}&quot;)&#10;            except Exception:&#10;                pass&#10;&#10;            self.is_loaded = True&#10;            logger.info(&quot; Todos los artefactos cargados exitosamente!&quot;)&#10;            return True&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error cargando artefactos: {str(e)}&quot;)&#10;            return False&#10;&#10;    def _extract_players_from_data(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;Extraer lista de jugadores únicos desde los datos de entrenamiento&quot;&quot;&quot;&#10;        players_set = set()&#10;&#10;        try:&#10;            # Cargar datos de entrenamiento&#10;            train_path = self.data_path / &quot;processed&quot; / &quot;train_full.csv&quot;&#10;            test_path = self.data_path / &quot;processed&quot; / &quot;test_full.csv&quot;&#10;&#10;            # Leer en chunks para manejar archivos grandes&#10;            for file_path, file_name in [(train_path, &quot;train_full.csv&quot;), (test_path, &quot;test_full.csv&quot;)]:&#10;                if file_path.exists():&#10;                    logger.info(f&quot;Extrayendo jugadores de {file_name}...&quot;)&#10;                    for chunk in pd.read_csv(file_path, chunksize=10000):&#10;                        # Buscar en todas las posibles columnas de jugadores (igual que en el notebook)&#10;                        player_columns = []&#10;&#10;                        # Columnas estándar&#10;                        if 'winner_name' in chunk.columns:&#10;                            player_columns.append('winner_name')&#10;                        if 'loser_name' in chunk.columns:&#10;                            player_columns.append('loser_name')&#10;&#10;                        # Columnas alternativas (como en el notebook)&#10;                        if 'player_1' in chunk.columns:&#10;                            player_columns.append('player_1')&#10;                        if 'player_2' in chunk.columns:&#10;                            player_columns.append('player_2')&#10;&#10;                        # Extraer jugadores de todas las columnas encontradas&#10;                        for col in player_columns:&#10;                            clean_players = chunk[col].dropna().astype(str).str.strip()&#10;                            players_set.update(clean_players.unique())&#10;&#10;            # Convertir a lista ordenada y filtrar nombres válidos (igual que antes)&#10;            players_list = []&#10;            for p in players_set:&#10;                if isinstance(p, str):&#10;                    clean_name = p.strip()&#10;                    if (len(clean_name) &gt; 2 and&#10;                        not clean_name.startswith(' ') and&#10;                        not clean_name.lower().startswith('bye') and&#10;                        not clean_name.lower() == 'nan' and&#10;                        ' ' in clean_name and  # Nombres deben tener al menos nombre y apellido&#10;                        clean_name.replace(' ', '').replace('.', '').replace('-', '').isalpha()):  # Solo letras, espacios, puntos y guiones&#10;                        players_list.append(clean_name)&#10;&#10;            players_list = sorted(list(set(players_list)))  # Eliminar duplicados y ordenar&#10;            logger.info(f&quot;✓ {len(players_list)} jugadores únicos extraídos de los datos&quot;)&#10;&#10;            # Guardar la lista para futuros usos&#10;            try:&#10;                with open(self.outputs_path / &quot;players_list.pkl&quot;, 'wb') as f:&#10;                    pickle.dump(players_list, f)&#10;                logger.info(&quot;✓ Lista de jugadores guardada en players_list.pkl&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo guardar la lista de jugadores: {e}&quot;)&#10;&#10;            return players_list&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error extrayendo jugadores: {str(e)}&quot;)&#10;            # Fallback a lista de muestra&#10;            return self._create_sample_players_list()&#10;&#10;    def _create_sample_players_list(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;Crear lista de jugadores de ejemplo si no existe&#10;        Se desactiva el fallback con jugadores hardcodeados: devolver lista vacía para forzar error si no hay datos.&#10;        &quot;&quot;&quot;&#10;        # Devolver lista vacía para evitar dependencias y falsos positivos&#10;        return []&#10;&#10;    def _load_training_data(self):&#10;        &quot;&quot;&quot;Cargar datos de entrenamiento para generar features&quot;&quot;&quot;&#10;        try:&#10;            train_path = self.data_path / &quot;processed&quot; / &quot;train_final.csv&quot;&#10;            test_path = self.data_path / &quot;processed&quot; / &quot;test_final.csv&quot;&#10;&#10;            if train_path.exists():&#10;                # Cargar una muestra de datos para features estadísticas&#10;                self.train_data = pd.read_csv(train_path, nrows=10000)&#10;                logger.info(f&quot;✓ Datos de entrenamiento cargados: {len(self.train_data)} registros (muestra)&quot;)&#10;&#10;            if test_path.exists():&#10;                # Cargar una muestra de datos de test&#10;                self.test_data = pd.read_csv(test_path, nrows=5000)&#10;                logger.info(f&quot;✓ Datos de test cargados: {len(self.test_data)} registros (muestra)&quot;)&#10;&#10;        except Exception as e:&#10;            logger.warning(f&quot;No se pudieron cargar los datos de entrenamiento: {str(e)}&quot;)&#10;&#10;    def is_player_known(self, player_name: str) -&gt; bool:&#10;        &quot;&quot;&quot;Verificar si un jugador está en la base de datos&quot;&quot;&quot;&#10;        if not self.players_list:&#10;            return False&#10;        return player_name in self.players_list&#10;&#10;    def get_player_suggestions(self, query: str, limit: int = 10) -&gt; List[str]:&#10;        &quot;&quot;&quot;Obtener sugerencias de jugadores basadas en una consulta&quot;&quot;&quot;&#10;        if not self.players_list:&#10;            return []&#10;&#10;        query = query.lower()&#10;        suggestions = [&#10;            player for player in self.players_list&#10;            if query in player.lower()&#10;        ]&#10;        return suggestions[:limit]&#10;&#10;    def predict_match(self, player1: str, player2: str, surface: str,&#10;                     tournament_level: str = None, round: str = &quot;F&quot;,&#10;                     best_of: int = 3) -&gt; PredictResponse:&#10;        &quot;&quot;&quot;Realizar predicción simplificada - solo necesita nombres y superficie&quot;&quot;&quot;&#10;        if not self.is_loaded:&#10;            raise RuntimeError(&quot;Modelo no está cargado&quot;)&#10;&#10;        try:&#10;            # Primero intentar crear features completas reutilizando estados de entrenamiento&#10;            features_df = None&#10;            try:&#10;                features_full = create_features_for_prediction(&#10;                    player1, player2, surface=surface,&#10;                    tournament_level=tournament_level or &quot;ATP Tour&quot;,&#10;                    round_name=round, best_of=best_of,&#10;                    training_states=self.training_states or {}&#10;                )&#10;                # Obtener columnas que espera el modelo&#10;                expected_cols = None&#10;                if self.training_states and isinstance(self.training_states, dict):&#10;                    expected_cols = self.training_states.get('feature_columns')&#10;                if expected_cols is None and self.feature_importance is not None:&#10;                    expected_cols = self.feature_importance['Feature'].tolist()&#10;                # Si el imputer incluye feature_names_in_ usarlo&#10;                try:&#10;                    if hasattr(self.imputer, 'feature_names_in_'):&#10;                        expected_cols = list(self.imputer.feature_names_in_)&#10;                except Exception:&#10;                    pass&#10;&#10;                if expected_cols is not None:&#10;                    for c in expected_cols:&#10;                        if c not in features_full.columns:&#10;                            features_full[c] = 0.0&#10;                    features_df = features_full.reindex(columns=expected_cols)&#10;                else:&#10;                    features_df = features_full.copy()&#10;            except Exception as e:&#10;                logger.debug(f&quot;No se pudo crear features completas: {e}. Usando features mínimas.&quot;)&#10;                features_df = self._create_minimal_features(player1, player2, surface)&#10;&#10;            # Asegurar columnas y tipos numéricos&#10;            features_df = features_df.fillna(0.0)&#10;            for col in features_df.columns:&#10;                try:&#10;                    features_df[col] = features_df[col].astype(float)&#10;                except Exception:&#10;                    # dejar como está si no convertible&#10;                    pass&#10;&#10;            # FORZAR reindexado según lo que el imputer/model espera (si está disponible)&#10;            try:&#10;                if hasattr(self.imputer, 'feature_names_in_'):&#10;                    expected_imputer = list(self.imputer.feature_names_in_)&#10;                    # Añadir columnas faltantes con ceros&#10;                    for c in expected_imputer:&#10;                        if c not in features_df.columns:&#10;                            features_df[c] = 0.0&#10;                    # Reindexar en el orden esperado&#10;                    features_df = features_df.reindex(columns=expected_imputer)&#10;                    logger.debug(f&quot;Reindexado features según imputer.feature_names_in_ (len={len(expected_imputer)})&quot;)&#10;                else:&#10;                    # Si no hay feature_names_in_, intentar usar training_states.feature_columns&#10;                    if self.training_states and isinstance(self.training_states, dict):&#10;                        fc = self.training_states.get('feature_columns')&#10;                        if isinstance(fc, (list, tuple)):&#10;                            for c in fc:&#10;                                if c not in features_df.columns:&#10;                                    features_df[c] = 0.0&#10;                            features_df = features_df.reindex(columns=fc)&#10;                            logger.debug(f&quot;Reindexado features según training_states.feature_columns (len={len(fc)})&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo reindexar según imputer/training_states: {e}&quot;)&#10;&#10;            # Aplicar imputación&#10;            try:&#10;                # Intentar usar el DataFrame (mantiene nombres de columnas)&#10;                try:&#10;                    X = self.imputer.transform(features_df)&#10;                except KeyError as e_df:&#10;                    logger.warning(f&quot;Imputer transform KeyError on DataFrame: {e_df}. Intentando transformar como ndarray.&quot;)&#10;                    # Intentar transformar como ndarray para evitar problemas con feature_names_in_&#10;                    try:&#10;                        X = self.imputer.transform(features_df.to_numpy())&#10;                    except Exception as e_arr:&#10;                        logger.warning(f&quot;Imputer transform falló en ndarray: {e_arr}. Intentando fallback con fila de ceros según imputador.&quot;)&#10;                        # Si el imputador conoce los nombres de las features, crear fila de ceros con esas columnas&#10;                        if hasattr(self.imputer, 'feature_names_in_'):&#10;                            try:&#10;                                expected = list(self.imputer.feature_names_in_)&#10;                                zeros = {c: 0.0 for c in expected}&#10;                                fallback_df = pd.DataFrame([zeros])&#10;                                logger.info(f&quot;Usando fallback: fila de ceros para {len(expected)} features del imputador&quot;)&#10;                                X = self.imputer.transform(fallback_df)&#10;                            except Exception as e2:&#10;                                logger.error(f&quot;Fallback imputer failed: {e2}&quot;)&#10;                                raise RuntimeError(f&quot;KeyError en imputador/columns: {e_df} / {e_arr} / {e2}&quot;)&#10;                        else:&#10;                            raise RuntimeError(f&quot;KeyError en imputador/columns y no hay feature_names_in_ para fallback: {e_df} / {e_arr}&quot;)&#10;            except Exception as e:&#10;                # Mensaje diagnóstico más robusto&#10;                expected_sample = None&#10;                try:&#10;                    expected_sample = list(getattr(self.imputer, 'feature_names_in_', []))[:50]&#10;                except Exception:&#10;                    expected_sample = None&#10;                diag = {&#10;                    'error': str(e),&#10;                    'expected_cols_sample': expected_sample,&#10;                    'provided_columns_sample': list(features_df.columns)[:200],&#10;                    'training_states_keys': list(self.training_states.keys()) if self.training_states else None&#10;                }&#10;                logger.error(f&quot;Imputer error diagnóstico: {diag}&quot;)&#10;                # Lanzar la excepción con el dict diagnóstico como primer argumento&#10;                raise RuntimeError(diag)&#10;&#10;            # Realizar predicción con diagnóstico adicional en caso de fallo&#10;            try:&#10;                proba = self.model.predict_proba(X)[0]&#10;            except Exception as e:&#10;                logger.error(f&quot;Error en model.predict_proba: {e}&quot;)&#10;                # Agregar información adicional&#10;                raise RuntimeError(f&quot;model.predict_proba failed: {e} - input_shape={getattr(X, 'shape', None)}&quot;)&#10;&#10;            prediction_proba = proba[1]  # Probabilidad de que gane player1&#10;&#10;            # Determinar ganador y confianza&#10;            winner = player1 if prediction_proba &gt; 0.5 else player2&#10;            confidence = max(prediction_proba, 1 - prediction_proba)&#10;&#10;            # No devolver heurísticas adicionales ni key features: lista vacía&#10;            key_features = []&#10;&#10;            # Información básica del partido&#10;            match_info = {&#10;                &quot;surface&quot;: surface,&#10;                &quot;tournament_level&quot;: tournament_level or &quot;Standard&quot;,&#10;                &quot;round&quot;: round,&#10;                &quot;best_of&quot;: best_of,&#10;                &quot;match_competitiveness&quot;: self._calculate_competitiveness(prediction_proba)&#10;            }&#10;&#10;            return PredictResponse(&#10;                player1=player1,&#10;                player2=player2,&#10;                player1_win_probability=float(prediction_proba),&#10;                player2_win_probability=float(1 - prediction_proba),&#10;                prediction=winner,&#10;                confidence=float(confidence),&#10;                match_info=match_info,&#10;                key_features=key_features,&#10;                model_version=self.model_summary.get(&quot;training_date&quot;, &quot;2025-09-05&quot;) if self.model_summary else &quot;2025-09-05&quot;&#10;            )&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error en predicción: {e}&quot;)&#10;            raise&#10;&#10;    def _create_minimal_features(self, player1: str, player2: str, surface: str) -&gt; pd.DataFrame:&#10;        &quot;&quot;&quot;Crear features mínimas para predicción - solo nombres y superficie&quot;&quot;&quot;&#10;&#10;        # Obtener las features que espera el modelo&#10;        expected_features = []&#10;        if self.feature_importance is not None:&#10;            expected_features = self.feature_importance['Feature'].tolist()&#10;        else:&#10;            # Si no hay feature_importance, usar features básicas&#10;            expected_features = [f'feature_{i}' for i in range(36)]  # 36 features según model_summary&#10;&#10;        # Inicializar todas las features con valores neutros&#10;        features_dict = {feature: [0.0] for feature in expected_features}&#10;&#10;        # Llenar solo las features que podemos calcular con los datos disponibles&#10;        basic_features = {&#10;            # Features de superficie&#10;            'surface_Hard': 1.0 if surface == 'Hard' else 0.0,&#10;            'surface_Clay': 1.0 if surface == 'Clay' else 0.0,&#10;            'surface_Grass': 1.0 if surface == 'Grass' else 0.0,&#10;            'surface_Carpet': 1.0 if surface == 'Carpet' else 0.0,&#10;&#10;            # Features de formato (valores por defecto)&#10;            'best_of': 3.0,&#10;            'match_competitiveness': 0.5,&#10;        }&#10;&#10;        # Estadísticas básicas de jugadores si están disponibles&#10;        if self.train_data is not None:&#10;            try:&#10;                player_stats = self._get_simple_player_stats(player1, player2)&#10;                basic_features.update(player_stats)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudieron calcular estadísticas de jugadores: {e}&quot;)&#10;&#10;        # Actualizar solo las features que existen en el modelo&#10;        for feature, value in basic_features.items():&#10;            if feature in features_dict:&#10;                features_dict[feature] = [value]&#10;&#10;        return pd.DataFrame(features_dict)&#10;&#10;    def _get_simple_player_stats(self, player1: str, player2: str) -&gt; Dict[str, float]:&#10;        &quot;&quot;&quot;Estadísticas simplificadas de jugadores&quot;&quot;&quot;&#10;        stats = {}&#10;&#10;        if self.train_data is not None:&#10;            try:&#10;                # Buscar jugadores en diferentes columnas posibles&#10;                p1_data = pd.DataFrame()&#10;                p2_data = pd.DataFrame()&#10;&#10;                # Intentar diferentes nombres de columnas&#10;                possible_winner_cols = ['winner_name', 'player_1']&#10;                possible_loser_cols = ['loser_name', 'player_2']&#10;&#10;                for winner_col in possible_winner_cols:&#10;                    if winner_col in self.train_data.columns:&#10;                        p1_wins = self.train_data[self.train_data[winner_col] == player1]&#10;                        p2_wins = self.train_data[self.train_data[winner_col] == player2]&#10;                        break&#10;&#10;                for loser_col in possible_loser_cols:&#10;                    if loser_col in self.train_data.columns:&#10;                        p1_losses = self.train_data[self.train_data[loser_col] == player1]&#10;                        p2_losses = self.train_data[self.train_data[loser_col] == player2]&#10;                        break&#10;&#10;                # Calcular estadísticas básicas si encontramos datos&#10;                if 'p1_wins' in locals() and 'p1_losses' in locals():&#10;                    p1_total = len(p1_wins) + len(p1_losses)&#10;                    p2_total = len(p2_wins) + len(p2_losses)&#10;&#10;                    if p1_total &gt; 0 and p2_total &gt; 0:&#10;                        p1_win_rate = len(p1_wins) / p1_total&#10;                        p2_win_rate = len(p2_wins) / p2_total&#10;&#10;                        stats.update({&#10;                            'player_advantage': p1_win_rate - p2_win_rate,&#10;                            'experience_factor': min((p1_total + p2_total) / 200, 1.0)&#10;                        })&#10;&#10;            except Exception as e:&#10;                logger.debug(f&quot;Error calculando estadísticas: {e}&quot;)&#10;&#10;        return stats&#10;&#10;    def _calculate_competitiveness(self, prob: float) -&gt; str:&#10;        &quot;&quot;&quot;Calcular nivel de competitividad del partido&quot;&quot;&quot;&#10;        diff = abs(prob - 0.5)&#10;        if diff &lt; 0.1:&#10;            return &quot;Muy competitivo&quot;&#10;        elif diff &lt; 0.2:&#10;            return &quot;Competitivo&quot;&#10;        elif diff &lt; 0.3:&#10;            return &quot;Favorito claro&quot;&#10;        else:&#10;            return &quot;Muy desigual&quot;&#10;&#10;    def get_player_stats(self, player_name: str) -&gt; Optional[PlayerStats]:&#10;        &quot;&quot;&quot;Obtener estadísticas de un jugador&quot;&quot;&quot;&#10;        if not self.is_player_known(player_name):&#10;            return None&#10;&#10;        # Aquí deberías calcular las estadísticas reales del jugador&#10;        # usando los datos de entrenamiento&#10;        return PlayerStats(&#10;            name=player_name,&#10;            current_ranking=None,  # Calcular del dataset&#10;            elo_rating=1500.0,     # Calcular del dataset&#10;            matches_played=0,      # Calcular del dataset&#10;            wins=0,               # Calcular del dataset&#10;            losses=0,             # Calcular del dataset&#10;            win_percentage=0.0,   # Calcular del dataset&#10;            surface_stats={},     # Calcular del dataset&#10;            recent_form=[],       # Calcular del dataset&#10;            last_match_date=None  # Calcular del dataset&#10;        )&#10;&#10;    def get_model_info(self) -&gt; ModelInfo:&#10;        &quot;&quot;&quot;Obtener información del modelo&quot;&quot;&quot;&#10;        if not self.model_summary:&#10;            raise RuntimeError(&quot;Información del modelo no disponible&quot;)&#10;&#10;        return ModelInfo(&#10;            model_type=self.model_summary.get(&quot;model_type&quot;, &quot;Unknown&quot;),&#10;            training_date=self.model_summary.get(&quot;training_date&quot;, &quot;Unknown&quot;),&#10;            performance=self.model_summary.get(&quot;performance&quot;, {}),&#10;            data_info=self.model_summary.get(&quot;data_info&quot;, {}),&#10;            top_features=self.model_summary.get(&quot;top_features&quot;, []),&#10;            hyperparameters=self.model_summary.get(&quot;best_hyperparameters&quot;, {})&#10;        )&#10;&#10;# Instancia global del servicio&#10;model_service = TennisModelService()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;model_service.py&#10;Servicio principal para manejar modelos y predicciones de tenis&#10;&quot;&quot;&quot;&#10;import pickle&#10;import json&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;from datetime import datetime&#10;from typing import Dict, List, Optional&#10;import logging&#10;from sklearn.impute import SimpleImputer&#10;import traceback&#10;&#10;# Import local modules - arreglando imports para funcionar en diferentes contextos&#10;try:&#10;    from .models import PredictResponse, PlayerStats, ModelInfo&#10;    from .features import create_features_for_prediction, get_curated_features&#10;except ImportError:&#10;    try:&#10;        from src.models import PredictResponse, PlayerStats, ModelInfo&#10;        from src.features import create_features_for_prediction, get_curated_features&#10;    except ImportError:&#10;        from models import PredictResponse, PlayerStats, ModelInfo&#10;        from features import create_features_for_prediction, get_curated_features&#10;&#10;# Configurar logging&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;class TennisModelService:&#10;    &quot;&quot;&quot;Servicio para manejar el modelo de predicción de tenis&quot;&quot;&quot;&#10;&#10;    def __init__(self, base_path: str = None):&#10;        self.base_path = Path(base_path) if base_path else Path(__file__).parent.parent&#10;        self.outputs_path = self.base_path / &quot;outputs&quot;&#10;        self.data_path = self.base_path / &quot;data&quot;&#10;&#10;        # Artefactos del modelo&#10;        self.model = None&#10;        self.imputer = None&#10;        self.players_list = None&#10;        self.feature_importance = None&#10;        self.model_summary = None&#10;        self.training_states = None&#10;&#10;        # Datos de entrenamiento para features históricas&#10;        self.train_data = None&#10;        self.test_data = None&#10;&#10;        self.is_loaded = False&#10;&#10;    def load_model_artifacts(self) -&gt; bool:&#10;        &quot;&quot;&quot;Cargar todos los artefactos del modelo&quot;&quot;&quot;&#10;        try:&#10;            logger.info(&quot;Cargando artefactos del modelo...&quot;)&#10;&#10;            # Cargar modelo principal&#10;            model_path = self.outputs_path / &quot;best_xgb_model.pkl&quot;&#10;            if model_path.exists():&#10;                with open(model_path, 'rb') as f:&#10;                    self.model = pickle.load(f)&#10;                logger.info(&quot;✓ Modelo XGBoost cargado&quot;)&#10;            else:&#10;                logger.error(f&quot;Modelo no encontrado en {model_path}&quot;)&#10;                return False&#10;&#10;            # Cargar imputer&#10;            imputer_path = self.outputs_path / &quot;imputer.pkl&quot;&#10;            if imputer_path.exists():&#10;                with open(imputer_path, 'rb') as f:&#10;                    self.imputer = pickle.load(f)&#10;                # Log adicional para diagnóstico&#10;                try:&#10;                    if hasattr(self.imputer, 'feature_names_in_'):&#10;                        names = list(self.imputer.feature_names_in_)&#10;                        logger.info(f&quot;✓ Imputer cargado (feature_names_in_ len={len(names)}) sample={names[:10]}&quot;)&#10;                    else:&#10;                        logger.info(&quot;✓ Imputer cargado (sin feature_names_in_)&quot;)&#10;                except Exception as e:&#10;                    logger.warning(f&quot;Imputer cargado pero no se pudo leer feature_names_in_: {e}&quot;)&#10;            else:&#10;                logger.warning(&quot;Imputer no encontrado, creando uno nuevo&quot;)&#10;                self.imputer = SimpleImputer(strategy='median')&#10;&#10;            # Cargar lista de jugadores - forzar regeneración si contiene nombres inválidos&#10;            players_path = self.outputs_path / &quot;players_list.pkl&quot;&#10;            should_regenerate = False&#10;&#10;            if players_path.exists():&#10;                with open(players_path, 'rb') as f:&#10;                    temp_players_list = pickle.load(f)&#10;&#10;                # Verificar si la lista tiene nombres con espacios al inicio&#10;                invalid_names = [p for p in temp_players_list[:10] if p.startswith(' ')]&#10;                if invalid_names:&#10;                    logger.info(&quot;Lista de jugadores contiene nombres inválidos, regenerando...&quot;)&#10;                    should_regenerate = True&#10;                    # Eliminar archivo corrupto&#10;                    try:&#10;                        players_path.unlink()&#10;                        logger.info(&quot;✓ Archivo players_list.pkl eliminado&quot;)&#10;                    except:&#10;                        pass&#10;                else:&#10;                    self.players_list = temp_players_list&#10;                    logger.info(f&quot;✓ Lista de {len(self.players_list)} jugadores cargada desde pickle&quot;)&#10;            else:&#10;                should_regenerate = True&#10;&#10;            if should_regenerate:&#10;                logger.info(&quot;Generando nueva lista de jugadores...&quot;)&#10;                self.players_list = self._extract_players_from_data()&#10;&#10;            # Cargar importancia de features&#10;            importance_path = self.outputs_path / &quot;feature_importance.csv&quot;&#10;            if importance_path.exists():&#10;                self.feature_importance = pd.read_csv(importance_path)&#10;                logger.info(&quot;✓ Importancia de features cargada&quot;)&#10;            else:&#10;                logger.warning(&quot;Importancia de features no encontrada&quot;)&#10;&#10;            # Cargar resumen del modelo&#10;            summary_path = self.outputs_path / &quot;model_summary.json&quot;&#10;            if summary_path.exists():&#10;                with open(summary_path, 'r') as f:&#10;                    self.model_summary = json.load(f)&#10;                logger.info(&quot;✓ Resumen del modelo cargado&quot;)&#10;            else:&#10;                logger.warning(&quot;Resumen del modelo no encontrado&quot;)&#10;&#10;            # Cargar estados de entrenamiento&#10;            states_path = self.outputs_path / &quot;training_states.pkl&quot;&#10;            if states_path.exists():&#10;                with open(states_path, 'rb') as f:&#10;                    self.training_states = pickle.load(f)&#10;                logger.info(&quot;✓ Estados de entrenamiento cargados&quot;)&#10;                # Log breve de feature_columns si existen&#10;                try:&#10;                    fc = self.training_states.get('feature_columns')&#10;                    if fc is not None:&#10;                        logger.info(f&quot;  - training_states.feature_columns len={len(fc)} sample={fc[:10]}&quot;)&#10;                    else:&#10;                        logger.info(&quot;  - training_states.feature_columns no presente&quot;)&#10;                except Exception as e:&#10;                    logger.warning(f&quot;No se pudo leer feature_columns de training_states: {e}&quot;)&#10;&#10;            # --- VALIDAR Y RECONSTRUIR IMPUTER SI ES NECESARIO ---&#10;            try:&#10;                # Determinar columnas esperadas (training_states &gt; feature_importance)&#10;                expected_cols = None&#10;                if self.training_states and isinstance(self.training_states, dict):&#10;                    expected_cols = self.training_states.get('feature_columns')&#10;                if expected_cols is None and self.feature_importance is not None:&#10;                    try:&#10;                        expected_cols = self.feature_importance['Feature'].tolist()&#10;                    except Exception:&#10;                        expected_cols = None&#10;&#10;                if expected_cols is not None and self.imputer is not None:&#10;                    bad_imputer = False&#10;                    try:&#10;                        imputer_names = list(getattr(self.imputer, 'feature_names_in_', []))&#10;                        # Si no hay nombres, no los consideramos malos aquí&#10;                        if imputer_names:&#10;                            # Detectar nombres genéricos problemáticos&#10;                            if any(n == 'feature' or n.startswith('feature_') or n.startswith('Unnamed') for n in imputer_names):&#10;                                bad_imputer = True&#10;                            # Detectar mismatch de longitud&#10;                            elif len(imputer_names) != len(expected_cols):&#10;                                bad_imputer = True&#10;                            else:&#10;                                # Detectar nombres que no aparecen en expected_cols&#10;                                if any(n not in expected_cols for n in imputer_names):&#10;                                    bad_imputer = True&#10;                    except Exception:&#10;                        bad_imputer = True&#10;&#10;                    if bad_imputer:&#10;                        logger.warning(&quot;Imputer con feature_names_in_ inválidos detectado — reconstruyendo basado en columnas esperadas&quot;)&#10;                        # Guardar backup del imputer original&#10;                        try:&#10;                            backup_path = self.outputs_path / &quot;imputer_backup.pkl&quot;&#10;                            with open(backup_path, 'wb') as f:&#10;                                pickle.dump(self.imputer, f)&#10;                            logger.info(f&quot;✓ Backup del imputer original guardado en {backup_path}&quot;)&#10;                        except Exception as e:&#10;                            logger.warning(f&quot;No se pudo guardar backup del imputer original: {e}&quot;)&#10;&#10;                        # Reconstruir un nuevo imputer y ajustarlo sobre una fila dummy con las columnas esperadas&#10;                        try:&#10;                            new_imputer = SimpleImputer(strategy='median')&#10;                            dummy = pd.DataFrame([[0.0] * len(expected_cols)], columns=expected_cols)&#10;                            new_imputer.fit(dummy)&#10;                            self.imputer = new_imputer&#10;                            # Guardar imputer reconstruido&#10;                            try:&#10;                                with open(self.outputs_path / &quot;imputer.pkl&quot;, 'wb') as f:&#10;                                    pickle.dump(self.imputer, f)&#10;                                logger.info(&quot;✓ Nuevo imputer guardado en outputs/imputer.pkl&quot;)&#10;                            except Exception as e:&#10;                                logger.warning(f&quot;No se pudo guardar el nuevo imputer: {e}&quot;)&#10;                        except Exception as e:&#10;                            logger.error(f&quot;Error reconstruyendo el imputer: {e}&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo validar/reconstruir imputer: {e}&quot;)&#10;&#10;            # Cargar datos de entrenamiento para features&#10;            self._load_training_data()&#10;&#10;            # Log feature_importance sample&#10;            try:&#10;                if self.feature_importance is not None:&#10;                    sample_feats = self.feature_importance['Feature'].tolist()[:10]&#10;                    logger.info(f&quot;✓ feature_importance sample: {sample_feats}&quot;)&#10;            except Exception:&#10;                pass&#10;&#10;            self.is_loaded = True&#10;            logger.info(&quot; Todos los artefactos cargados exitosamente!&quot;)&#10;            return True&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error cargando artefactos: {str(e)}&quot;)&#10;            return False&#10;&#10;    def _extract_players_from_data(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;Extraer lista de jugadores únicos desde los datos de entrenamiento&quot;&quot;&quot;&#10;        players_set = set()&#10;&#10;        try:&#10;            # Cargar datos de entrenamiento&#10;            train_path = self.data_path / &quot;processed&quot; / &quot;train_full.csv&quot;&#10;            test_path = self.data_path / &quot;processed&quot; / &quot;test_full.csv&quot;&#10;&#10;            # Leer en chunks para manejar archivos grandes&#10;            for file_path, file_name in [(train_path, &quot;train_full.csv&quot;), (test_path, &quot;test_full.csv&quot;)]:&#10;                if file_path.exists():&#10;                    logger.info(f&quot;Extrayendo jugadores de {file_name}...&quot;)&#10;                    for chunk in pd.read_csv(file_path, chunksize=10000):&#10;                        # Buscar en todas las posibles columnas de jugadores (igual que en el notebook)&#10;                        player_columns = []&#10;&#10;                        # Columnas estándar&#10;                        if 'winner_name' in chunk.columns:&#10;                            player_columns.append('winner_name')&#10;                        if 'loser_name' in chunk.columns:&#10;                            player_columns.append('loser_name')&#10;&#10;                        # Columnas alternativas (como en el notebook)&#10;                        if 'player_1' in chunk.columns:&#10;                            player_columns.append('player_1')&#10;                        if 'player_2' in chunk.columns:&#10;                            player_columns.append('player_2')&#10;&#10;                        # Extraer jugadores de todas las columnas encontradas&#10;                        for col in player_columns:&#10;                            clean_players = chunk[col].dropna().astype(str).str.strip()&#10;                            players_set.update(clean_players.unique())&#10;&#10;            # Convertir a lista ordenada y filtrar nombres válidos (igual que antes)&#10;            players_list = []&#10;            for p in players_set:&#10;                if isinstance(p, str):&#10;                    clean_name = p.strip()&#10;                    if (len(clean_name) &gt; 2 and&#10;                        not clean_name.startswith(' ') and&#10;                        not clean_name.lower().startswith('bye') and&#10;                        not clean_name.lower() == 'nan' and&#10;                        ' ' in clean_name and  # Nombres deben tener al menos nombre y apellido&#10;                        clean_name.replace(' ', '').replace('.', '').replace('-', '').isalpha()):  # Solo letras, espacios, puntos y guiones&#10;                        players_list.append(clean_name)&#10;&#10;            players_list = sorted(list(set(players_list)))  # Eliminar duplicados y ordenar&#10;            logger.info(f&quot;✓ {len(players_list)} jugadores únicos extraídos de los datos&quot;)&#10;&#10;            # Guardar la lista para futuros usos&#10;            try:&#10;                with open(self.outputs_path / &quot;players_list.pkl&quot;, 'wb') as f:&#10;                    pickle.dump(players_list, f)&#10;                logger.info(&quot;✓ Lista de jugadores guardada en players_list.pkl&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo guardar la lista de jugadores: {e}&quot;)&#10;&#10;            return players_list&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error extrayendo jugadores: {str(e)}&quot;)&#10;            # Fallback a lista de muestra&#10;            return self._create_sample_players_list()&#10;&#10;    def _create_sample_players_list(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;Crear lista de jugadores de ejemplo si no existe&#10;        Se desactiva el fallback con jugadores hardcodeados: devolver lista vacía para forzar error si no hay datos.&#10;        &quot;&quot;&quot;&#10;        # Devolver lista vacía para evitar dependencias y falsos positivos&#10;        return []&#10;&#10;    def _load_training_data(self):&#10;        &quot;&quot;&quot;Cargar datos de entrenamiento para generar features&quot;&quot;&quot;&#10;        try:&#10;            train_path = self.data_path / &quot;processed&quot; / &quot;train_final.csv&quot;&#10;            test_path = self.data_path / &quot;processed&quot; / &quot;test_final.csv&quot;&#10;&#10;            if train_path.exists():&#10;                # Cargar una muestra de datos para features estadísticas&#10;                self.train_data = pd.read_csv(train_path, nrows=10000)&#10;                logger.info(f&quot;✓ Datos de entrenamiento cargados: {len(self.train_data)} registros (muestra)&quot;)&#10;&#10;            if test_path.exists():&#10;                # Cargar una muestra de datos de test&#10;                self.test_data = pd.read_csv(test_path, nrows=5000)&#10;                logger.info(f&quot;✓ Datos de test cargados: {len(self.test_data)} registros (muestra)&quot;)&#10;&#10;        except Exception as e:&#10;            logger.warning(f&quot;No se pudieron cargar los datos de entrenamiento: {str(e)}&quot;)&#10;&#10;    def is_player_known(self, player_name: str) -&gt; bool:&#10;        &quot;&quot;&quot;Verificar si un jugador está en la base de datos&quot;&quot;&quot;&#10;        if not self.players_list:&#10;            return False&#10;        return player_name in self.players_list&#10;&#10;    def get_player_suggestions(self, query: str, limit: int = 10) -&gt; List[str]:&#10;        &quot;&quot;&quot;Obtener sugerencias de jugadores basadas en una consulta&quot;&quot;&quot;&#10;        if not self.players_list:&#10;            return []&#10;&#10;        query = query.lower()&#10;        suggestions = [&#10;            player for player in self.players_list&#10;            if query in player.lower()&#10;        ]&#10;        return suggestions[:limit]&#10;&#10;    def predict_match(self, player1: str, player2: str, surface: str,&#10;                     tournament_level: str = None, round: str = &quot;F&quot;,&#10;                     best_of: int = 3) -&gt; PredictResponse:&#10;        &quot;&quot;&quot;Realizar predicción simplificada - solo necesita nombres y superficie&quot;&quot;&quot;&#10;        if not self.is_loaded:&#10;            raise RuntimeError(&quot;Modelo no está cargado&quot;)&#10;&#10;        try:&#10;            # Primero intentar crear features completas reutilizando estados de entrenamiento&#10;            features_df = None&#10;            try:&#10;                features_full = create_features_for_prediction(&#10;                    player1, player2, surface=surface,&#10;                    tournament_level=tournament_level or &quot;ATP Tour&quot;,&#10;                    round_name=round, best_of=best_of,&#10;                    training_states=self.training_states or {}&#10;                )&#10;                # Obtener columnas que espera el modelo&#10;                expected_cols = None&#10;                if self.training_states and isinstance(self.training_states, dict):&#10;                    expected_cols = self.training_states.get('feature_columns')&#10;                if expected_cols is None and self.feature_importance is not None:&#10;                    expected_cols = self.feature_importance['Feature'].tolist()&#10;                # Si el imputer incluye feature_names_in_ usarlo&#10;                try:&#10;                    if hasattr(self.imputer, 'feature_names_in_'):&#10;                        expected_cols = list(self.imputer.feature_names_in_)&#10;                except Exception:&#10;                    pass&#10;&#10;                if expected_cols is not None:&#10;                    for c in expected_cols:&#10;                        if c not in features_full.columns:&#10;                            features_full[c] = 0.0&#10;                    features_df = features_full.reindex(columns=expected_cols)&#10;                else:&#10;                    features_df = features_full.copy()&#10;            except Exception as e:&#10;                logger.debug(f&quot;No se pudo crear features completas: {e}. Usando features mínimas.&quot;)&#10;                features_df = self._create_minimal_features(player1, player2, surface)&#10;&#10;            # Asegurar columnas y tipos numéricos&#10;            features_df = features_df.fillna(0.0)&#10;            for col in features_df.columns:&#10;                try:&#10;                    features_df[col] = features_df[col].astype(float)&#10;                except Exception:&#10;                    # dejar como está si no convertible&#10;                    pass&#10;&#10;            # FORZAR reindexado según lo que el imputer/model espera (si está disponible)&#10;            try:&#10;                if hasattr(self.imputer, 'feature_names_in_'):&#10;                    expected_imputer = list(self.imputer.feature_names_in_)&#10;                    # Añadir columnas faltantes con ceros&#10;                    for c in expected_imputer:&#10;                        if c not in features_df.columns:&#10;                            features_df[c] = 0.0&#10;                    # Reindexar en el orden esperado&#10;                    features_df = features_df.reindex(columns=expected_imputer)&#10;                    logger.debug(f&quot;Reindexado features según imputer.feature_names_in_ (len={len(expected_imputer)})&quot;)&#10;                else:&#10;                    # Si no hay feature_names_in_, intentar usar training_states.feature_columns&#10;                    if self.training_states and isinstance(self.training_states, dict):&#10;                        fc = self.training_states.get('feature_columns')&#10;                        if isinstance(fc, (list, tuple)):&#10;                            for c in fc:&#10;                                if c not in features_df.columns:&#10;                                    features_df[c] = 0.0&#10;                            features_df = features_df.reindex(columns=fc)&#10;                            logger.debug(f&quot;Reindexado features según training_states.feature_columns (len={len(fc)})&quot;)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudo reindexar según imputer/training_states: {e}&quot;)&#10;&#10;            # Aplicar imputación&#10;            try:&#10;                # Intentar usar el DataFrame (mantiene nombres de columnas)&#10;                try:&#10;                    X = self.imputer.transform(features_df)&#10;                except KeyError as e_df:&#10;                    logger.warning(f&quot;Imputer transform KeyError on DataFrame: {e_df}. Intentando transformar como ndarray.&quot;)&#10;                    # Intentar transformar como ndarray para evitar problemas con feature_names_in_&#10;                    try:&#10;                        X = self.imputer.transform(features_df.to_numpy())&#10;                    except Exception as e_arr:&#10;                        logger.warning(f&quot;Imputer transform falló en ndarray: {e_arr}. Intentando fallback con fila de ceros según imputador.&quot;)&#10;                        # Si el imputador conoce los nombres de las features, crear fila de ceros con esas columnas&#10;                        if hasattr(self.imputer, 'feature_names_in_'):&#10;                            try:&#10;                                expected = list(self.imputer.feature_names_in_)&#10;                                zeros = {c: 0.0 for c in expected}&#10;                                fallback_df = pd.DataFrame([zeros])&#10;                                logger.info(f&quot;Usando fallback: fila de ceros para {len(expected)} features del imputador&quot;)&#10;                                X = self.imputer.transform(fallback_df)&#10;                            except Exception as e2:&#10;                                logger.error(f&quot;Fallback imputer failed: {e2}&quot;)&#10;                                raise RuntimeError(f&quot;KeyError en imputador/columns: {e_df} / {e_arr} / {e2}&quot;)&#10;                        else:&#10;                            raise RuntimeError(f&quot;KeyError en imputador/columns y no hay feature_names_in_ para fallback: {e_df} / {e_arr}&quot;)&#10;            except Exception as e:&#10;                # Mensaje diagnóstico más robusto&#10;                expected_sample = None&#10;                try:&#10;                    expected_sample = list(getattr(self.imputer, 'feature_names_in_', []))[:50]&#10;                except Exception:&#10;                    expected_sample = None&#10;                diag = {&#10;                    'error': str(e),&#10;                    'expected_cols_sample': expected_sample,&#10;                    'provided_columns_sample': list(features_df.columns)[:200],&#10;                    'training_states_keys': list(self.training_states.keys()) if self.training_states else None&#10;                }&#10;                logger.error(f&quot;Imputer error diagnóstico: {diag}&quot;)&#10;                # Lanzar la excepción con el dict diagnóstico como primer argumento&#10;                raise RuntimeError(diag)&#10;&#10;            # Realizar predicción con diagnóstico adicional en caso de fallo&#10;            try:&#10;                proba = self.model.predict_proba(X)[0]&#10;            except Exception as e:&#10;                logger.error(f&quot;Error en model.predict_proba: {e}&quot;)&#10;                # Agregar información adicional&#10;                raise RuntimeError(f&quot;model.predict_proba failed: {e} - input_shape={getattr(X, 'shape', None)}&quot;)&#10;&#10;            prediction_proba = proba[1]  # Probabilidad de que gane player1&#10;&#10;            # Determinar ganador y confianza&#10;            winner = player1 if prediction_proba &gt; 0.5 else player2&#10;            confidence = max(prediction_proba, 1 - prediction_proba)&#10;&#10;            # No devolver heurísticas adicionales ni key features: lista vacía&#10;            key_features = []&#10;&#10;            # Información básica del partido&#10;            match_info = {&#10;                &quot;surface&quot;: surface,&#10;                &quot;tournament_level&quot;: tournament_level or &quot;Standard&quot;,&#10;                &quot;round&quot;: round,&#10;                &quot;best_of&quot;: best_of,&#10;                &quot;match_competitiveness&quot;: self._calculate_competitiveness(prediction_proba)&#10;            }&#10;&#10;            return PredictResponse(&#10;                player1=player1,&#10;                player2=player2,&#10;                player1_win_probability=float(prediction_proba),&#10;                player2_win_probability=float(1 - prediction_proba),&#10;                prediction=winner,&#10;                confidence=float(confidence),&#10;                match_info=match_info,&#10;                key_features=key_features,&#10;                model_version=self.model_summary.get(&quot;training_date&quot;, &quot;2025-09-05&quot;) if self.model_summary else &quot;2025-09-05&quot;&#10;            )&#10;&#10;        except Exception as e:&#10;            # Construir diagnóstico completo y lanzar como RuntimeError con dict&#10;            logger.error(f&quot;Error en predicción: {e}&quot;)&#10;            tb = traceback.format_exc()&#10;            diag = {&#10;                'exception_type': type(e).__name__,&#10;                'exception_str': str(e),&#10;                'traceback': tb,&#10;                'provided_columns_sample': list(features_df.columns)[:200] if 'features_df' in locals() and features_df is not None else None,&#10;                'imputer_feature_names_sample': list(getattr(self.imputer, 'feature_names_in_', []))[:200] if self.imputer is not None else None&#10;            }&#10;            # Si la excepción ya tenía un dict diagnóstico como primer argumento, anexarlo&#10;            try:&#10;                if e.args and isinstance(e.args[0], dict):&#10;                    diag['inner_diagnostic'] = e.args[0]&#10;            except Exception:&#10;                pass&#10;&#10;            raise RuntimeError(diag)&#10;&#10;    def _create_minimal_features(self, player1: str, player2: str, surface: str) -&gt; pd.DataFrame:&#10;        &quot;&quot;&quot;Crear features mínimas para predicción - solo nombres y superficie&quot;&quot;&quot;&#10;&#10;        # Obtener las features que espera el modelo&#10;        expected_features = []&#10;        if self.feature_importance is not None:&#10;            expected_features = self.feature_importance['Feature'].tolist()&#10;        else:&#10;            # Si no hay feature_importance, usar features básicas&#10;            expected_features = [f'feature_{i}' for i in range(36)]  # 36 features según model_summary&#10;&#10;        # Inicializar todas las features con valores neutros&#10;        features_dict = {feature: [0.0] for feature in expected_features}&#10;&#10;        # Llenar solo las features que podemos calcular con los datos disponibles&#10;        basic_features = {&#10;            # Features de superficie&#10;            'surface_Hard': 1.0 if surface == 'Hard' else 0.0,&#10;            'surface_Clay': 1.0 if surface == 'Clay' else 0.0,&#10;            'surface_Grass': 1.0 if surface == 'Grass' else 0.0,&#10;            'surface_Carpet': 1.0 if surface == 'Carpet' else 0.0,&#10;&#10;            # Features de formato (valores por defecto)&#10;            'best_of': 3.0,&#10;            'match_competitiveness': 0.5,&#10;        }&#10;&#10;        # Estadísticas básicas de jugadores si están disponibles&#10;        if self.train_data is not None:&#10;            try:&#10;                player_stats = self._get_simple_player_stats(player1, player2)&#10;                basic_features.update(player_stats)&#10;            except Exception as e:&#10;                logger.warning(f&quot;No se pudieron calcular estadísticas de jugadores: {e}&quot;)&#10;&#10;        # Actualizar solo las features que existen en el modelo&#10;        for feature, value in basic_features.items():&#10;            if feature in features_dict:&#10;                features_dict[feature] = [value]&#10;&#10;        return pd.DataFrame(features_dict)&#10;&#10;    def _get_simple_player_stats(self, player1: str, player2: str) -&gt; Dict[str, float]:&#10;        &quot;&quot;&quot;Estadísticas simplificadas de jugadores&quot;&quot;&quot;&#10;        stats = {}&#10;&#10;        if self.train_data is not None:&#10;            try:&#10;                # Buscar jugadores en diferentes columnas posibles&#10;                p1_data = pd.DataFrame()&#10;                p2_data = pd.DataFrame()&#10;&#10;                # Intentar diferentes nombres de columnas&#10;                possible_winner_cols = ['winner_name', 'player_1']&#10;                possible_loser_cols = ['loser_name', 'player_2']&#10;&#10;                for winner_col in possible_winner_cols:&#10;                    if winner_col in self.train_data.columns:&#10;                        p1_wins = self.train_data[self.train_data[winner_col] == player1]&#10;                        p2_wins = self.train_data[self.train_data[winner_col] == player2]&#10;                        break&#10;&#10;                for loser_col in possible_loser_cols:&#10;                    if loser_col in self.train_data.columns:&#10;                        p1_losses = self.train_data[self.train_data[loser_col] == player1]&#10;                        p2_losses = self.train_data[self.train_data[loser_col] == player2]&#10;                        break&#10;&#10;                # Calcular estadísticas básicas si encontramos datos&#10;                if 'p1_wins' in locals() and 'p1_losses' in locals():&#10;                    p1_total = len(p1_wins) + len(p1_losses)&#10;                    p2_total = len(p2_wins) + len(p2_losses)&#10;&#10;                    if p1_total &gt; 0 and p2_total &gt; 0:&#10;                        p1_win_rate = len(p1_wins) / p1_total&#10;                        p2_win_rate = len(p2_wins) / p2_total&#10;&#10;                        stats.update({&#10;                            'player_advantage': p1_win_rate - p2_win_rate,&#10;                            'experience_factor': min((p1_total + p2_total) / 200, 1.0)&#10;                        })&#10;&#10;            except Exception as e:&#10;                logger.debug(f&quot;Error calculando estadísticas: {e}&quot;)&#10;&#10;        return stats&#10;&#10;    def _calculate_competitiveness(self, prob: float) -&gt; str:&#10;        &quot;&quot;&quot;Calcular nivel de competitividad del partido&quot;&quot;&quot;&#10;        diff = abs(prob - 0.5)&#10;        if diff &lt; 0.1:&#10;            return &quot;Muy competitivo&quot;&#10;        elif diff &lt; 0.2:&#10;            return &quot;Competitivo&quot;&#10;        elif diff &lt; 0.3:&#10;            return &quot;Favorito claro&quot;&#10;        else:&#10;            return &quot;Muy desigual&quot;&#10;&#10;    def get_player_stats(self, player_name: str) -&gt; Optional[PlayerStats]:&#10;        &quot;&quot;&quot;Obtener estadísticas de un jugador&quot;&quot;&quot;&#10;        if not self.is_player_known(player_name):&#10;            return None&#10;&#10;        # Aquí deberías calcular las estadísticas reales del jugador&#10;        # usando los datos de entrenamiento&#10;        return PlayerStats(&#10;            name=player_name,&#10;            current_ranking=None,  # Calcular del dataset&#10;            elo_rating=1500.0,     # Calcular del dataset&#10;            matches_played=0,      # Calcular del dataset&#10;            wins=0,               # Calcular del dataset&#10;            losses=0,             # Calcular del dataset&#10;            win_percentage=0.0,   # Calcular del dataset&#10;            surface_stats={},     # Calcular del dataset&#10;            recent_form=[],       # Calcular del dataset&#10;            last_match_date=None  # Calcular del dataset&#10;        )&#10;&#10;    def get_model_info(self) -&gt; ModelInfo:&#10;        &quot;&quot;&quot;Obtener información del modelo&quot;&quot;&quot;&#10;        if not self.model_summary:&#10;            raise RuntimeError(&quot;Información del modelo no disponible&quot;)&#10;&#10;        return ModelInfo(&#10;            model_type=self.model_summary.get(&quot;model_type&quot;, &quot;Unknown&quot;),&#10;            training_date=self.model_summary.get(&quot;training_date&quot;, &quot;Unknown&quot;),&#10;            performance=self.model_summary.get(&quot;performance&quot;, {}),&#10;            data_info=self.model_summary.get(&quot;data_info&quot;, {}),&#10;            top_features=self.model_summary.get(&quot;top_features&quot;, []),&#10;            hyperparameters=self.model_summary.get(&quot;best_hyperparameters&quot;, {})&#10;        )&#10;&#10;# Instancia global del servicio&#10;model_service = TennisModelService()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/test_without_h2h.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/test_without_h2h.py" />
              <option name="updatedContent" value="import pandas as pd&#10;import os&#10;from sklearn.metrics import accuracy_score&#10;from xgboost import XGBClassifier&#10;from data_loader import BASE_DIR&#10;&#10;# Cargar datos existentes&#10;features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;features_test_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_test.csv&quot;)&#10;&#10;def make_dual_rows(df):&#10;    df1 = df.copy()&#10;    df1[&quot;target&quot;] = 1&#10;&#10;    df2 = df.copy()&#10;    df2[&quot;target&quot;] = 0&#10;    for col in [&quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;]:&#10;        tmp = df2[col.replace(&quot;winner&quot;, &quot;loser&quot;)]&#10;        df2[col.replace(&quot;winner&quot;, &quot;loser&quot;)] = df2[col]&#10;        df2[col] = tmp&#10;    return pd.concat([df1, df2], ignore_index=True)&#10;&#10;# Cargar datos&#10;df_train = pd.read_csv(features_train_path)&#10;df_test = pd.read_csv(features_test_path)&#10;&#10;df_train = make_dual_rows(df_train)&#10;df_test[&quot;target&quot;] = 1&#10;&#10;# SOLO usar ELO ratings, sin H2H&#10;feature_cols = [&#10;    &quot;elo_winner&quot;, &quot;elo_loser&quot;,&#10;    &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;&#10;]&#10;&#10;print(&quot; Entrenando modelo SIN features H2H...&quot;)&#10;&#10;X_train = df_train[feature_cols]&#10;y_train = df_train[&quot;target&quot;]&#10;X_test = df_test[feature_cols]&#10;y_test = df_test[&quot;target&quot;]&#10;&#10;model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')&#10;model.fit(X_train, y_train)&#10;&#10;y_pred = model.predict(X_test)&#10;test_acc = accuracy_score(y_test, y_pred)&#10;print(f&quot; Accuracy en test (SOLO ELO): {test_acc:.4f}&quot;)&#10;&#10;# Mostrar importancia de features&#10;importances = model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': feature_cols,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;print(&quot;\n Importancia de features (solo ELO):&quot;)&#10;print(feature_importance_df)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/train_for_web.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/train_for_web.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Script para guardar el modelo entrenado y los estados necesarios para la aplicación web&#10;&quot;&quot;&quot;&#10;import pickle&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import sys&#10;import os&#10;&#10;&#10;# Ahora importar los módulos&#10;from features import add_all_features&#10;from data_loader import load_and_preprocess_data&#10;from sklearn.model_selection import train_test_split&#10;import xgboost as xgb&#10;&#10;def save_model_and_states():&#10;    &quot;&quot;&quot;&#10;    Entrena el modelo y guarda todos los estados necesarios para la aplicación web&#10;    &quot;&quot;&quot;&#10;    print(&quot; Cargando y procesando datos...&quot;)&#10;&#10;    # Cargar datos&#10;    df_train, df_test = load_and_preprocess_data()&#10;&#10;    # Procesar features de entrenamiento&#10;    print(&quot; Calculando features de entrenamiento...&quot;)&#10;    (df_train_final, df_train_full, final_global_elos,&#10;     final_surface_elos, final_h2h, final_stats, pca_state) = add_all_features(&#10;        df_train,&#10;        mode=&quot;train&quot;,&#10;        fast=False,&#10;        return_pca_state=True,&#10;        return_full=True&#10;    )&#10;&#10;    # Procesar features de test&#10;    print(&quot; Calculando features de test...&quot;)&#10;    (df_test_final, df_test_full, _, _, _, _) = add_all_features(&#10;        df_test,&#10;        initial_global_elos=final_global_elos,&#10;        initial_surface_elos=final_surface_elos,&#10;        initial_h2h=final_h2h,&#10;        initial_stats=final_stats,&#10;        mode=&quot;inference&quot;,&#10;        fast=False,&#10;        pca_state=pca_state,&#10;        randomize_players=False,&#10;        return_full=True&#10;    )&#10;&#10;    # Preparar datos para entrenamiento&#10;    feature_cols = [col for col in df_train_final.columns if col != 'target']&#10;    X_train = df_train_final[feature_cols].fillna(0)&#10;    y_train = df_train_final['target']&#10;    X_test = df_test_final[feature_cols].fillna(0)&#10;    y_test = df_test_final['target']&#10;&#10;    print(f&quot; Features seleccionadas: {len(feature_cols)}&quot;)&#10;    print(f&quot; Datos de entrenamiento: {X_train.shape}&quot;)&#10;    print(f&quot; Datos de test: {X_test.shape}&quot;)&#10;&#10;    # Entrenar modelo XGBoost optimizado&#10;    print(&quot; Entrenando modelo XGBoost...&quot;)&#10;&#10;    model = xgb.XGBClassifier(&#10;        objective='binary:logistic',&#10;        eval_metric='logloss',&#10;        colsample_bytree=0.7,&#10;        learning_rate=0.05,&#10;        max_depth=8,&#10;        n_estimators=200,&#10;        subsample=0.9,&#10;        random_state=42,&#10;        n_jobs=-1&#10;    )&#10;&#10;    model.fit(X_train, y_train)&#10;&#10;    # Evaluar modelo&#10;    from sklearn.metrics import accuracy_score, roc_auc_score, log_loss&#10;&#10;    y_pred_proba = model.predict_proba(X_test)[:, 1]&#10;    y_pred = model.predict(X_test)&#10;&#10;    accuracy = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_pred_proba)&#10;    logloss = log_loss(y_test, y_pred_proba)&#10;&#10;    print(f&quot;✅ Accuracy: {accuracy:.4f}&quot;)&#10;    print(f&quot;✅ AUC: {auc:.4f}&quot;)&#10;    print(f&quot;✅ LogLoss: {logloss:.4f}&quot;)&#10;&#10;    # Crear directorio outputs si no existe&#10;    Path('../outputs').mkdir(exist_ok=True)&#10;&#10;    # Guardar modelo&#10;    print(&quot; Guardando modelo...&quot;)&#10;    with open('outputs/best_model.pkl', 'wb') as f:&#10;        pickle.dump(model, f)&#10;&#10;    # Guardar estados para la aplicación&#10;    print(&quot; Guardando estados...&quot;)&#10;    training_states = {&#10;        'final_global_elos': final_global_elos,&#10;        'final_surface_elos': final_surface_elos,&#10;        'final_h2h': final_h2h,&#10;        'final_stats': final_stats,&#10;        'pca_state': pca_state,&#10;        'feature_columns': feature_cols,&#10;        'model_metrics': {&#10;            'accuracy': accuracy,&#10;            'auc': auc,&#10;            'logloss': logloss&#10;        }&#10;    }&#10;&#10;    with open('outputs/training_states.pkl', 'wb') as f:&#10;        pickle.dump(training_states, f)&#10;&#10;    # Guardar lista de jugadores únicos para la app&#10;    all_players = set()&#10;    for df in [df_train_full, df_test_full]:&#10;        if 'player_1' in df.columns:&#10;            all_players.update(df['player_1'].dropna())&#10;        if 'player_2' in df.columns:&#10;            all_players.update(df['player_2'].dropna())&#10;&#10;    players_list = sorted(list(all_players))&#10;&#10;    with open('outputs/players_list.pkl', 'wb') as f:&#10;        pickle.dump(players_list, f)&#10;&#10;    print(f&quot;✅ Modelo y estados guardados exitosamente!&quot;)&#10;    print(f&quot; {len(players_list)} jugadores únicos identificados&quot;)&#10;    print(f&quot; Archivos guardados en: outputs/&quot;)&#10;&#10;    return model, training_states&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    save_model_and_states()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Script para guardar el modelo entrenado y los estados necesarios para la aplicación web&#10;&quot;&quot;&quot;&#10;import pickle&#10;import pandas as pd&#10;import numpy as np&#10;from pathlib import Path&#10;import sys&#10;import os&#10;&#10;&#10;# Ahora importar los módulos&#10;from features import add_all_features&#10;from data_loader import load_and_preprocess_data&#10;from sklearn.model_selection import train_test_split&#10;import xgboost as xgb&#10;&#10;def save_model_and_states():&#10;    &quot;&quot;&quot;&#10;    Entrena el modelo y guarda todos los estados necesarios para la aplicación web&#10;    &quot;&quot;&quot;&#10;    print(&quot; Cargando y procesando datos...&quot;)&#10;&#10;    # Cargar datos&#10;    df_train, df_test = load_and_preprocess_data()&#10;&#10;    # Procesar features de entrenamiento&#10;    print(&quot; Calculando features de entrenamiento...&quot;)&#10;    (df_train_final, df_train_full, final_global_elos,&#10;     final_surface_elos, final_h2h, final_stats, pca_state) = add_all_features(&#10;        df_train,&#10;        mode=&quot;train&quot;,&#10;        fast=False,&#10;        return_pca_state=True,&#10;        return_full=True&#10;    )&#10;&#10;    # Procesar features de test&#10;    print(&quot; Calculando features de test...&quot;)&#10;    (df_test_final, df_test_full, _, _, _, _) = add_all_features(&#10;        df_test,&#10;        initial_global_elos=final_global_elos,&#10;        initial_surface_elos=final_surface_elos,&#10;        initial_h2h=final_h2h,&#10;        initial_stats=final_stats,&#10;        mode=&quot;inference&quot;,&#10;        fast=False,&#10;        pca_state=pca_state,&#10;        randomize_players=False,&#10;        return_full=True&#10;    )&#10;&#10;    # Preparar datos para entrenamiento - ARREGLADO para columnas consistentes&#10;    print(&quot; Alineando columnas entre train y test...&quot;)&#10;    &#10;    # Obtener columnas comunes (excluyendo target)&#10;    train_cols = set(df_train_final.columns) - {'target'}&#10;    test_cols = set(df_test_final.columns) - {'target'}&#10;    &#10;    # Encontrar columnas que faltan en cada conjunto&#10;    missing_in_test = train_cols - test_cols&#10;    missing_in_train = test_cols - train_cols&#10;    &#10;    if missing_in_test:&#10;        print(f&quot;⚠️  Columnas faltantes en test: {list(missing_in_test)[:10]}...&quot;)&#10;        # Agregar columnas faltantes con ceros&#10;        for col in missing_in_test:&#10;            df_test_final[col] = 0&#10;    &#10;    if missing_in_train:&#10;        print(f&quot;⚠️  Columnas faltantes en train: {list(missing_in_train)[:10]}...&quot;)&#10;        # Agregar columnas faltantes con ceros&#10;        for col in missing_in_train:&#10;            df_train_final[col] = 0&#10;    &#10;    # Usar solo las columnas comunes, ordenadas alfabéticamente para consistencia&#10;    common_cols = sorted(list(train_cols.intersection(test_cols)))&#10;    &#10;    # Si agregamos columnas, incluirlas también&#10;    if missing_in_test:&#10;        common_cols.extend(sorted(list(missing_in_test)))&#10;    if missing_in_train:&#10;        common_cols.extend(sorted(list(missing_in_train)))&#10;    &#10;    # Remover duplicados y ordenar&#10;    feature_cols = sorted(list(set(common_cols)))&#10;    &#10;    X_train = df_train_final[feature_cols].fillna(0)&#10;    y_train = df_train_final['target']&#10;    X_test = df_test_final[feature_cols].fillna(0)&#10;    y_test = df_test_final['target']&#10;&#10;    print(f&quot; Features seleccionadas: {len(feature_cols)}&quot;)&#10;    print(f&quot; Datos de entrenamiento: {X_train.shape}&quot;)&#10;    print(f&quot; Datos de test: {X_test.shape}&quot;)&#10;&#10;    # Entrenar modelo XGBoost optimizado&#10;    print(&quot; Entrenando modelo XGBoost...&quot;)&#10;&#10;    model = xgb.XGBClassifier(&#10;        objective='binary:logistic',&#10;        eval_metric='logloss',&#10;        colsample_bytree=0.7,&#10;        learning_rate=0.05,&#10;        max_depth=8,&#10;        n_estimators=200,&#10;        subsample=0.9,&#10;        random_state=42,&#10;        n_jobs=-1&#10;    )&#10;&#10;    model.fit(X_train, y_train)&#10;&#10;    # Evaluar modelo&#10;    from sklearn.metrics import accuracy_score, roc_auc_score, log_loss&#10;&#10;    y_pred_proba = model.predict_proba(X_test)[:, 1]&#10;    y_pred = model.predict(X_test)&#10;&#10;    accuracy = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_pred_proba)&#10;    logloss = log_loss(y_test, y_pred_proba)&#10;&#10;    print(f&quot;✅ Accuracy: {accuracy:.4f}&quot;)&#10;    print(f&quot;✅ AUC: {auc:.4f}&quot;)&#10;    print(f&quot;✅ LogLoss: {logloss:.4f}&quot;)&#10;&#10;    # Crear directorio outputs si no existe&#10;    Path('../outputs').mkdir(exist_ok=True)&#10;&#10;    # Guardar modelo&#10;    print(&quot; Guardando modelo...&quot;)&#10;    with open('outputs/best_model.pkl', 'wb') as f:&#10;        pickle.dump(model, f)&#10;&#10;    # Guardar estados para la aplicación&#10;    print(&quot; Guardando estados...&quot;)&#10;    training_states = {&#10;        'final_global_elos': final_global_elos,&#10;        'final_surface_elos': final_surface_elos,&#10;        'final_h2h': final_h2h,&#10;        'final_stats': final_stats,&#10;        'pca_state': pca_state,&#10;        'feature_columns': feature_cols,&#10;        'model_metrics': {&#10;            'accuracy': accuracy,&#10;            'auc': auc,&#10;            'logloss': logloss&#10;        }&#10;    }&#10;&#10;    with open('outputs/training_states.pkl', 'wb') as f:&#10;        pickle.dump(training_states, f)&#10;&#10;    # Guardar lista de jugadores únicos para la app&#10;    all_players = set()&#10;    for df in [df_train_full, df_test_full]:&#10;        if 'player_1' in df.columns:&#10;            all_players.update(df['player_1'].dropna())&#10;        if 'player_2' in df.columns:&#10;            all_players.update(df['player_2'].dropna())&#10;&#10;    players_list = sorted(list(all_players))&#10;&#10;    with open('outputs/players_list.pkl', 'wb') as f:&#10;        pickle.dump(players_list, f)&#10;&#10;    print(f&quot;✅ Modelo y estados guardados exitosamente!&quot;)&#10;    print(f&quot; {len(players_list)} jugadores únicos identificados&quot;)&#10;    print(f&quot; Archivos guardados en: outputs/&quot;)&#10;&#10;    return model, training_states&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    save_model_and_states()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/tennis_services.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/tennis_services.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Servicios de predicción y análisis de tenis&#10;NUEVO: Usa features pre-calculadas desde archivo&#10;&quot;&quot;&quot;&#10;import pandas as pd&#10;import numpy as np&#10;from datetime import datetime, timedelta&#10;from collections import defaultdict&#10;import logging&#10;import pickle&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;class TennisPredictor:&#10;    &quot;&quot;&quot;Servicio principal de predicción de tenis - Usa features pre-calculadas&quot;&quot;&quot;&#10;&#10;    def __init__(self, model_cache, data_cache):&#10;        self.model_cache = model_cache&#10;        self.data_cache = data_cache&#10;&#10;        # VALIDACIÓN ESTRICTA: todo debe estar presente&#10;        self.model = model_cache.get('xgb_model')&#10;        self.imputer = model_cache.get('imputer')&#10;        self.training_states = model_cache.get('training_states', {})&#10;        self.feature_columns = self.training_states.get('feature_columns', [])&#10;&#10;        # FALLO INMEDIATO si algo no está&#10;        if not self.model:&#10;            raise ValueError(&quot;MODELO XGBOOST NO ENCONTRADO - La aplicación no puede funcionar&quot;)&#10;        if not self.imputer:&#10;            raise ValueError(&quot;IMPUTER NO ENCONTRADO - La aplicación no puede funcionar&quot;)&#10;        if not self.feature_columns:&#10;            raise ValueError(&quot;FEATURE COLUMNS NO ENCONTRADAS - La aplicación no puede funcionar&quot;)&#10;&#10;        # NUEVO: Cargar features pre-calculadas de jugadores&#10;        self.player_features = self._load_player_features()&#10;&#10;        logger.info(f&quot;✅ TennisPredictor inicializado con {len(self.feature_columns)} features&quot;)&#10;        logger.info(f&quot; Features pre-calculadas para {len(self.player_features)} jugadores&quot;)&#10;&#10;    def _load_player_features(self):&#10;        &quot;&quot;&quot;Cargar features pre-calculadas de jugadores desde archivo&quot;&quot;&quot;&#10;        from pathlib import Path&#10;&#10;        try:&#10;            outputs_dir = Path(__file__).parent / 'outputs'&#10;            player_features_path = outputs_dir / 'player_features.pkl'&#10;&#10;            if not player_features_path.exists():&#10;                logger.warning(f&quot;❌ Archivo de features de jugadores no encontrado: {player_features_path}&quot;)&#10;                logger.warning(&quot; Ejecuta el notebook hasta la sección 15 para generarlo&quot;)&#10;                return {}&#10;&#10;            logger.info(f&quot; Cargando features de jugadores desde {player_features_path}&quot;)&#10;            with open(player_features_path, 'rb') as f:&#10;                player_features = pickle.load(f)&#10;&#10;            logger.info(f&quot;✅ Features cargadas para {len(player_features)} jugadores&quot;)&#10;            return player_features&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;❌ Error cargando features de jugadores: {e}&quot;)&#10;            return {}&#10;&#10;    def predict_match(self, player1, player2, surface='Hard', tournament_level='ATP500'):&#10;        &quot;&quot;&quot;&#10;        Predecir resultado usando features pre-calculadas&#10;        &quot;&quot;&quot;&#10;        try:&#10;            # Verificar que tengamos features para ambos jugadores&#10;            if not self.player_features:&#10;                raise ValueError(&quot;No hay features de jugadores cargadas. Ejecuta el notebook hasta la sección 15.&quot;)&#10;&#10;            # Buscar features de ambos jugadores&#10;            p1_features = self._get_player_features(player1)&#10;            p2_features = self._get_player_features(player2)&#10;&#10;            if p1_features is None:&#10;                logger.warning(f&quot;⚠️ Player1 '{player1}' no encontrado en features pre-calculadas&quot;)&#10;            if p2_features is None:&#10;                logger.warning(f&quot;⚠️ Player2 '{player2}' no encontrado en features pre-calculadas&quot;)&#10;&#10;            # Crear features para ambas direcciones del enfrentamiento&#10;            features_1 = self._create_match_features(p1_features, p2_features, surface, player1, player2)&#10;            features_2 = self._create_match_features(p2_features, p1_features, surface, player2, player1)&#10;&#10;            # Validar dimensiones&#10;            expected = len(self.feature_columns)&#10;            if len(features_1) != expected or len(features_2) != expected:&#10;                logger.error(f&quot;MISMATCH DE FEATURES: esperado {expected}, obtenido {len(features_1)}/{len(features_2)}&quot;)&#10;                # Ajustar features si hay diferencia&#10;                features_1 = self._adjust_features_length(features_1, expected)&#10;                features_2 = self._adjust_features_length(features_2, expected)&#10;&#10;            # Preparar arrays e imputar&#10;            arr1 = np.array([features_1])&#10;            arr2 = np.array([features_2])&#10;            arr1_imp = self.imputer.transform(arr1)&#10;            arr2_imp = self.imputer.transform(arr2)&#10;&#10;            # Predicciones del modelo&#10;            probs1 = self.model.predict_proba(arr1_imp)[0]&#10;            probs2 = self.model.predict_proba(arr2_imp)[0]&#10;&#10;            # Promediado simétrico para evitar bias&#10;            prob_p1_from_direct = float(probs1[1])&#10;            prob_p1_from_inverted = 1.0 - float(probs2[1])&#10;            prob_player1_wins = (prob_p1_from_direct + prob_p1_from_inverted) / 2.0&#10;            prob_player2_wins = 1.0 - prob_player1_wins&#10;&#10;            # Información de jugadores y H2D&#10;            player1_info = self._get_player_detailed_info(player1, surface)&#10;            player2_info = self._get_player_detailed_info(player2, surface)&#10;            h2h_info = self._get_h2h_info(player1, player2)&#10;&#10;            response = {&#10;                'player1': player1,&#10;                'player2': player2,&#10;                'surface': surface,&#10;                'predictions': {&#10;                    'player1_win_probability': round(prob_player1_wins, 3),&#10;                    'player2_win_probability': round(prob_player2_wins, 3),&#10;                    'predicted_winner': player1 if prob_player1_wins &gt; 0.5 else player2,&#10;                    'confidence': round(abs(prob_player1_wins - 0.5) * 2, 3)&#10;                },&#10;                'player1_info': player1_info,&#10;                'player2_info': player2_info,&#10;                'head_to_head': h2h_info,&#10;                'model_type': 'XGBoost con Features Pre-calculadas',&#10;                'features_used': expected,&#10;                'model_accuracy': self.model_cache.get('model_summary', {}).get('performance', {}).get('accuracy', 'N/A'),&#10;                'status': 'success'&#10;            }&#10;&#10;            # Diagnósticos&#10;            response['diagnostics'] = {&#10;                'player1_found_in_features': p1_features is not None,&#10;                'player2_found_in_features': p2_features is not None,&#10;                'features_1_non_zero': int((np.array(features_1) != 0).sum()),&#10;                'features_2_non_zero': int((np.array(features_2) != 0).sum()),&#10;                'total_players_in_db': len(self.player_features),&#10;                'method': 'pre_calculated_features'&#10;            }&#10;&#10;            return response&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;ERROR CRÍTICO EN PREDICCIÓN: {e}&quot;)&#10;            raise e&#10;&#10;    def _get_player_features(self, player_name):&#10;        &quot;&quot;&quot;&#10;        Buscar features de un jugador (con búsqueda flexible)&#10;        &quot;&quot;&quot;&#10;        # Búsqueda exacta&#10;        if player_name in self.player_features:&#10;            return self.player_features[player_name]['model_features']&#10;&#10;        # Búsqueda parcial por apellido&#10;        player_lower = player_name.lower()&#10;        name_parts = player_lower.split()&#10;&#10;        # Buscar por apellido (última parte del nombre)&#10;        if len(name_parts) &gt;= 2:&#10;            surname = name_parts[-1]&#10;            for stored_name in self.player_features.keys():&#10;                if surname in stored_name.lower():&#10;                    return self.player_features[stored_name]['model_features']&#10;&#10;        # Buscar por cualquier parte del nombre&#10;        for stored_name in self.player_features.keys():&#10;            stored_lower = stored_name.lower()&#10;            if any(part in stored_lower for part in name_parts):&#10;                return self.player_features[stored_name]['model_features']&#10;&#10;        return None  # No encontrado&#10;&#10;    def _create_match_features(self, p1_features, p2_features, surface, player1_name, player2_name):&#10;        &quot;&quot;&quot;&#10;        Crear vector de features para un enfrentamiento específico&#10;        &quot;&quot;&quot;&#10;        # Si no tenemos features de algún jugador, usar valores neutros&#10;        if p1_features is None:&#10;            p1_features = {col: 0.0 for col in self.feature_columns}&#10;        if p2_features is None:&#10;            p2_features = {col: 0.0 for col in self.feature_columns}&#10;&#10;        # Crear vector de features alineado con feature_columns del modelo&#10;        match_features = []&#10;&#10;        for col in self.feature_columns:&#10;            # Intentar obtener el valor de features del jugador&#10;            value = 0.0  # Valor por defecto&#10;&#10;            # Estrategia: usar features del jugador 1 como base,&#10;            # y complementar con diferencias/ratios respecto al jugador 2&#10;            if col in p1_features:&#10;                value = p1_features[col]&#10;            elif col in p2_features:&#10;                # Si es una feature de &quot;diferencia&quot; o &quot;ratio&quot;, usar p2 como referencia&#10;                if 'diff' in col.lower() or 'ratio' in col.lower():&#10;                    value = -p2_features[col]  # Invertir para perspectiva del jugador 1&#10;                else:&#10;                    value = p2_features[col]&#10;&#10;            # Para features específicas de superficie, ajustar según superficie actual&#10;            if surface.lower() in col.lower():&#10;                # Dar más peso a features de la superficie específica&#10;                value *= 1.1&#10;&#10;            # Asegurar que es un float válido&#10;            try:&#10;                value = float(value)&#10;                if not np.isfinite(value):&#10;                    value = 0.0&#10;            except (ValueError, TypeError):&#10;                value = 0.0&#10;&#10;            match_features.append(value)&#10;&#10;        return match_features&#10;&#10;    def _adjust_features_length(self, features, expected_length):&#10;        &quot;&quot;&quot;&#10;        Ajustar longitud de features si hay diferencia&#10;        &quot;&quot;&quot;&#10;        if len(features) &lt; expected_length:&#10;            # Rellenar con ceros&#10;            features.extend([0.0] * (expected_length - len(features)))&#10;        elif len(features) &gt; expected_length:&#10;            # Truncar&#10;            features = features[:expected_length]&#10;        return features&#10;&#10;    def _get_player_detailed_info(self, player_name, surface):&#10;        &quot;&quot;&quot;&#10;        Obtener información detallada de un jugador para la predicción&#10;        CORREGIDO: surface_elo_p1 ya corresponde a la superficie específica&#10;        &quot;&quot;&quot;&#10;        # Obtener estados del entrenamiento&#10;        global_elos = self.training_states.get('final_global_elos', {})&#10;        surface_elos = self.training_states.get('final_surface_elos', {})&#10;        stats_data = self.training_states.get('final_stats', {})&#10;&#10;        # ELO ratings&#10;        global_elo = global_elos.get(player_name, 1500)&#10;&#10;        # CORREGIDO: Los surface_elos en training_states contienen ELOs por superficie específica&#10;        # Buscar en surface_elos por superficie actual&#10;        surface_key = f&quot;{surface.lower()}_elos&quot;  # ej: &quot;clay_elos&quot;, &quot;hard_elos&quot;&#10;        surface_elos_dict = surface_elos.get(surface_key, {})&#10;        surface_elo = surface_elos_dict.get(player_name, global_elo)&#10;&#10;        # Si no encontramos en surface_elos, usar el global_elo como fallback&#10;        if surface_elo == global_elo and surface_elos:&#10;            # Intentar con nombres de superficie alternativos&#10;            alt_surface_names = {&#10;                'hard': ['hard', 'Hard'],&#10;                'clay': ['clay', 'Clay'],&#10;                'grass': ['grass', 'Grass'],&#10;                'carpet': ['carpet', 'Carpet']&#10;            }&#10;&#10;            for alt_name in alt_surface_names.get(surface.lower(), [surface]):&#10;                alt_key = f&quot;{alt_name}_elos&quot;&#10;                if alt_key in surface_elos:&#10;                    surface_elo = surface_elos[alt_key].get(player_name, global_elo)&#10;                    if surface_elo != global_elo:&#10;                        break&#10;&#10;        # Buscar estadísticas con nombres alternativos&#10;        player_stats = self._find_player_stats(player_name, stats_data)&#10;&#10;        # Información básica del jugador&#10;        player_info = {&#10;            'name': player_name,&#10;            'elo_ratings': {&#10;                'global_elo': int(global_elo),&#10;                'surface_elo': int(surface_elo),&#10;                'elo_difference': int(surface_elo - global_elo)&#10;            },&#10;            'career_stats': {&#10;                'total_matches': player_stats.get('total_matches', 0),&#10;                'wins': player_stats.get('wins', 0),&#10;                'losses': player_stats.get('losses', 0),&#10;                'win_rate': round(player_stats.get('win_rate', 0.5), 3)&#10;            },&#10;            'recent_form': self._get_recent_form_from_data(player_name),&#10;            'surface_performance': self._get_surface_performance(player_name, surface),&#10;            'last_match_info': self._get_last_match_info(player_name)&#10;        }&#10;&#10;        return player_info&#10;&#10;    def _find_player_stats(self, player_name, stats_data):&#10;        &quot;&quot;&quot;&#10;        Buscar estadísticas del jugador con nombres alternativos&#10;        &quot;&quot;&quot;&#10;        # Buscar exacto&#10;        if player_name in stats_data:&#10;            return stats_data[player_name]&#10;&#10;        # Buscar por partes del nombre&#10;        name_parts = player_name.lower().split()&#10;        for key, stats in stats_data.items():&#10;            key_lower = key.lower()&#10;            # Si contiene apellido y nombre, o viceversa&#10;            if len(name_parts) &gt;= 2:&#10;                if all(part in key_lower for part in name_parts[:2]):&#10;                    return stats&#10;&#10;        # Si no encuentra nada, calcular desde datos históricos&#10;        return self._calculate_career_stats_from_historical(player_name)&#10;&#10;    def _calculate_career_stats_from_historical(self, player_name):&#10;        &quot;&quot;&quot;&#10;        Calcular estadísticas de carrera desde datos históricos&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return {'total_matches': 0, 'wins': 0, 'losses': 0, 'win_rate': 0.5}&#10;&#10;        df = self.data_cache['historical_data']&#10;        total_wins = 0&#10;        total_losses = 0&#10;&#10;        # CORREGIDO: Usar las columnas que realmente existen (player_1, player_2)&#10;        if 'player_1' in df.columns and 'player_2' in df.columns:&#10;            # Contar partidos donde aparece como player_1 o player_2&#10;            # Para determinar quién ganó necesitaríamos la columna 'target' o similar&#10;&#10;            # Partidos como player_1&#10;            p1_matches = df[df['player_1'].str.contains(player_name, case=False, na=False)]&#10;&#10;            # Partidos como player_2&#10;            p2_matches = df[df['player_2'].str.contains(player_name, case=False, na=False)]&#10;&#10;            # Si hay columna target, usarla para determinar victorias&#10;            if 'target' in df.columns:&#10;                # target=1 significa que player_1 ganó&#10;                p1_wins = len(p1_matches[p1_matches['target'] == 1])&#10;                p1_losses = len(p1_matches[p1_matches['target'] == 0])&#10;&#10;                # Para player_2: target=0 significa que player_2 ganó&#10;                p2_wins = len(p2_matches[p2_matches['target'] == 0])&#10;                p2_losses = len(p2_matches[p2_matches['target'] == 1])&#10;&#10;                total_wins = p1_wins + p2_wins&#10;                total_losses = p1_losses + p2_losses&#10;            else:&#10;                # Fallback: asumir 50% win rate&#10;                total_matches = len(p1_matches) + len(p2_matches)&#10;                total_wins = total_matches // 2&#10;                total_losses = total_matches - total_wins&#10;&#10;        total_matches = total_wins + total_losses&#10;        win_rate = total_wins / total_matches if total_matches &gt; 0 else 0.5&#10;&#10;        return {&#10;            'total_matches': int(total_matches),&#10;            'wins': int(total_wins),&#10;            'losses': int(total_losses),&#10;            'win_rate': round(win_rate, 3)&#10;        }&#10;&#10;    def _get_recent_form_from_data(self, player_name):&#10;        &quot;&quot;&quot;&#10;        Obtener forma reciente del jugador (últimos partidos)&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return {&#10;                'recent_matches': 0,&#10;                'recent_wins': 0,&#10;                'recent_win_rate': 0.5,&#10;                'form_string': 'N/A',&#10;                'note': 'Datos históricos no disponibles'&#10;            }&#10;&#10;        df = self.data_cache['historical_data']&#10;        recent_matches = []&#10;&#10;        # CORREGIDO: Usar player_1, player_2 y target para determinar resultados&#10;        if 'player_1' in df.columns and 'player_2' in df.columns and 'target' in df.columns:&#10;            # Partidos como player_1&#10;            p1_matches = df[df['player_1'].str.contains(player_name, case=False, na=False)]&#10;            for _, match in p1_matches.tail(10).iterrows():&#10;                result = 'W' if match.get('target', 0) == 1 else 'L'&#10;                recent_matches.append({&#10;                    'result': result,&#10;                    'date': match.get('tourney_date', ''),&#10;                    'opponent': match.get('player_2', 'Unknown'),&#10;                    'tournament': match.get('tourney_name', 'Unknown')&#10;                })&#10;&#10;            # Partidos como player_2&#10;            p2_matches = df[df['player_2'].str.contains(player_name, case=False, na=False)]&#10;            for _, match in p2_matches.tail(10).iterrows():&#10;                result = 'W' if match.get('target', 0) == 0 else 'L'  # target=0 means player_2 won&#10;                recent_matches.append({&#10;                    'result': result,&#10;                    'date': match.get('tourney_date', ''),&#10;                    'opponent': match.get('player_1', 'Unknown'),&#10;                    'tournament': match.get('tourney_name', 'Unknown')&#10;                })&#10;&#10;        # Ordenar por fecha y tomar los últimos 10&#10;        if recent_matches:&#10;            recent_matches = sorted(recent_matches, key=lambda x: x['date'], reverse=True)[:10]&#10;            recent_wins = sum(1 for m in recent_matches if m['result'] == 'W')&#10;            form_string = ''.join(m['result'] for m in recent_matches[:8])&#10;        else:&#10;            recent_wins = 0&#10;            form_string = 'N/A'&#10;&#10;        return {&#10;            'recent_matches': len(recent_matches),&#10;            'recent_wins': recent_wins,&#10;            'recent_win_rate': round(recent_wins / len(recent_matches) if recent_matches else 0.5, 3),&#10;            'form_string': form_string,&#10;            'last_matches': recent_matches[:5]&#10;        }&#10;&#10;    def _get_surface_performance(self, player_name, surface):&#10;        &quot;&quot;&quot;&#10;        Obtener rendimiento específico en la superficie&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return {&#10;                'matches_on_surface': 0,&#10;                'wins_on_surface': 0,&#10;                'surface_win_rate': 0.5,&#10;                'note': 'Datos históricos no disponibles'&#10;            }&#10;&#10;        df = self.data_cache['historical_data']&#10;&#10;        # Filtrar partidos en la superficie específica&#10;        if 'surface' not in df.columns:&#10;            return {&#10;                'matches_on_surface': 0,&#10;                'wins_on_surface': 0,&#10;                'surface_win_rate': 0.5,&#10;                'note': 'Información de superficie no disponible'&#10;            }&#10;&#10;        surface_df = df[df['surface'].str.contains(surface, case=False, na=False)]&#10;&#10;        # CORREGIDO: Usar player_1, player_2 y target&#10;        wins_on_surface = 0&#10;        losses_on_surface = 0&#10;&#10;        if 'player_1' in surface_df.columns and 'player_2' in surface_df.columns and 'target' in surface_df.columns:&#10;            # Como player_1&#10;            p1_surface_matches = surface_df[surface_df['player_1'].str.contains(player_name, case=False, na=False)]&#10;            p1_wins = len(p1_surface_matches[p1_surface_matches['target'] == 1])&#10;            p1_losses = len(p1_surface_matches[p1_surface_matches['target'] == 0])&#10;&#10;            # Como player_2&#10;            p2_surface_matches = surface_df[surface_df['player_2'].str.contains(player_name, case=False, na=False)]&#10;            p2_wins = len(p2_surface_matches[p2_surface_matches['target'] == 0])  # target=0 means player_2 won&#10;            p2_losses = len(p2_surface_matches[p2_surface_matches['target'] == 1])&#10;&#10;            wins_on_surface = p1_wins + p2_wins&#10;            losses_on_surface = p1_losses + p2_losses&#10;&#10;        total_surface_matches = wins_on_surface + losses_on_surface&#10;        surface_win_rate = wins_on_surface / total_surface_matches if total_surface_matches &gt; 0 else 0.5&#10;&#10;        return {&#10;            'matches_on_surface': total_surface_matches,&#10;            'wins_on_surface': wins_on_surface,&#10;            'losses_on_surface': losses_on_surface,&#10;            'surface_win_rate': round(surface_win_rate, 3),&#10;            'surface_specialty': surface_win_rate &gt; 0.6&#10;        }&#10;&#10;    def _get_last_match_info(self, player_name):&#10;        &quot;&quot;&quot;&#10;        Obtener información del último partido jugado&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return {&#10;                'last_match': None,&#10;                'note': 'Datos históricos no disponibles'&#10;            }&#10;&#10;        df = self.data_cache['historical_data']&#10;        last_match = None&#10;        latest_date = None&#10;&#10;        # CORREGIDO: Usar player_1, player_2 y target&#10;        if 'player_1' in df.columns and 'player_2' in df.columns and 'tourney_date' in df.columns:&#10;            # Partidos como player_1&#10;            p1_matches = df[df['player_1'].str.contains(player_name, case=False, na=False)]&#10;            if not p1_matches.empty:&#10;                latest_p1 = p1_matches.loc[p1_matches['tourney_date'].idxmax()]&#10;                if latest_date is None or pd.to_datetime(latest_p1['tourney_date']) &gt; pd.to_datetime(latest_date if latest_date else '1900-01-01'):&#10;                    latest_date = latest_p1['tourney_date']&#10;                    result = 'Won' if latest_p1.get('target', 0) == 1 else 'Lost'&#10;                    last_match = {&#10;                        'date': latest_p1.get('tourney_date', ''),&#10;                        'tournament': latest_p1.get('tourney_name', 'Unknown'),&#10;                        'opponent': latest_p1.get('player_2', 'Unknown'),&#10;                        'result': result,&#10;                        'surface': latest_p1.get('surface', 'Unknown'),&#10;                        'score': latest_p1.get('score', ''),&#10;                        'round': latest_p1.get('round', '')&#10;                    }&#10;&#10;            # Partidos como player_2&#10;            p2_matches = df[df['player_2'].str.contains(player_name, case=False, na=False)]&#10;            if not p2_matches.empty:&#10;                latest_p2 = p2_matches.loc[p2_matches['tourney_date'].idxmax()]&#10;                if latest_date is None or pd.to_datetime(latest_p2['tourney_date']) &gt; pd.to_datetime(latest_date if latest_date else '1900-01-01'):&#10;                    latest_date = latest_p2['tourney_date']&#10;                    result = 'Won' if latest_p2.get('target', 0) == 0 else 'Lost'  # target=0 means player_2 won&#10;                    last_match = {&#10;                        'date': latest_p2.get('tourney_date', ''),&#10;                        'tournament': latest_p2.get('tourney_name', 'Unknown'),&#10;                        'opponent': latest_p2.get('player_1', 'Unknown'),&#10;                        'result': result,&#10;                        'surface': latest_p2.get('surface', 'Unknown'),&#10;                        'score': latest_p2.get('score', ''),&#10;                        'round': latest_p2.get('round', '')&#10;                    }&#10;&#10;        return {&#10;            'last_match': last_match,&#10;            'days_since_last_match': self._calculate_days_since(latest_date) if latest_date else None&#10;        }&#10;&#10;    def _get_h2h_info(self, player1, player2):&#10;        &quot;&quot;&quot;&#10;        Obtener información head-to-head entre los dos jugadores&#10;        &quot;&quot;&quot;&#10;        # CORREGIR: Buscar directamente en datos históricos si no hay en training_states&#10;        h2h_data = self.training_states.get('final_h2h', {})&#10;&#10;        # Buscar H2H en training_states primero&#10;        h2h_key1 = f&quot;{player1}_vs_{player2}&quot;&#10;        h2h_key2 = f&quot;{player2}_vs_{player1}&quot;&#10;&#10;        h2h_stats1 = h2h_data.get(h2h_key1, {})&#10;        h2h_stats2 = h2h_data.get(h2h_key2, {})&#10;&#10;        # Combinar estadísticas de training_states&#10;        player1_wins = h2h_stats1.get('wins', 0) + h2h_stats2.get('losses', 0)&#10;        player2_wins = h2h_stats1.get('losses', 0) + h2h_stats2.get('wins', 0)&#10;        total_matches = player1_wins + player2_wins&#10;&#10;        # Si no hay datos en training_states, buscar en datos históricos&#10;        if total_matches == 0:&#10;            h2h_from_historical = self._calculate_h2h_from_historical(player1, player2)&#10;            if h2h_from_historical['total_matches'] &gt; 0:&#10;                return h2h_from_historical&#10;&#10;        if total_matches == 0:&#10;            return {&#10;                'total_matches': 0,&#10;                'player1_wins': 0,&#10;                'player2_wins': 0,&#10;                'player1_h2h_rate': 0.5,&#10;                'note': 'No hay enfrentamientos previos registrados',&#10;                'recent_matches': []&#10;            }&#10;&#10;        return {&#10;            'total_matches': total_matches,&#10;            'player1_wins': player1_wins,&#10;            'player2_wins': player2_wins,&#10;            'player1_h2h_rate': round(player1_wins / total_matches, 3),&#10;            'player2_h2h_rate': round(player2_wins / total_matches, 3),&#10;            'head_to_head_advantage': player1 if player1_wins &gt; player2_wins else player2 if player2_wins &gt; player1_wins else 'Even',&#10;            'recent_matches': self._get_recent_h2h_matches(player1, player2)&#10;        }&#10;&#10;    def _calculate_h2h_from_historical(self, player1, player2):&#10;        &quot;&quot;&quot;&#10;        Calcular head-to-head directamente desde datos históricos&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return {'total_matches': 0, 'player1_wins': 0, 'player2_wins': 0}&#10;&#10;        df = self.data_cache['historical_data']&#10;        player1_wins = 0&#10;        player2_wins = 0&#10;&#10;        # CORREGIDO: Usar player_1, player_2 y target para enfrentamientos directos&#10;        if 'player_1' in df.columns and 'player_2' in df.columns and 'target' in df.columns:&#10;            # Usar búsqueda más flexible por apellidos&#10;            p1_parts = player1.lower().split()&#10;            p2_parts = player2.lower().split()&#10;&#10;            if len(p1_parts) &gt;= 2 and len(p2_parts) &gt;= 2:&#10;                p1_surname = p1_parts[-1]&#10;                p2_surname = p2_parts[-1]&#10;&#10;                # Enfrentamientos donde player1 es player_1 y player2 es player_2&#10;                matches1 = df[&#10;                    (df['player_1'].str.contains(p1_surname, case=False, na=False)) &amp;&#10;                    (df['player_2'].str.contains(p2_surname, case=False, na=False))&#10;                ]&#10;                # En estos partidos, player1 ganó cuando target=1&#10;                p1_wins_as_p1 = len(matches1[matches1['target'] == 1])&#10;                p2_wins_as_p2 = len(matches1[matches1['target'] == 0])&#10;&#10;                # Enfrentamientos donde player1 es player_2 y player2 es player_1&#10;                matches2 = df[&#10;                    (df['player_1'].str.contains(p2_surname, case=False, na=False)) &amp;&#10;                    (df['player_2'].str.contains(p1_surname, case=False, na=False))&#10;                ]&#10;                # En estos partidos, player1 ganó cuando target=0 (porque está como player_2)&#10;                p1_wins_as_p2 = len(matches2[matches2['target'] == 0])&#10;                p2_wins_as_p1 = len(matches2[matches2['target'] == 1])&#10;&#10;                player1_wins = p1_wins_as_p1 + p1_wins_as_p2&#10;                player2_wins = p2_wins_as_p2 + p2_wins_as_p1&#10;&#10;        total_matches = player1_wins + player2_wins&#10;&#10;        if total_matches &gt; 0:&#10;            return {&#10;                'total_matches': total_matches,&#10;                'player1_wins': player1_wins,&#10;                'player2_wins': player2_wins,&#10;                'player1_h2h_rate': round(player1_wins / total_matches, 3),&#10;                'player2_h2h_rate': round(player2_wins / total_matches, 3),&#10;                'head_to_head_advantage': player1 if player1_wins &gt; player2_wins else player2 if player2_wins &gt; player1_wins else 'Even',&#10;                'recent_matches': self._get_recent_h2h_matches(player1, player2)&#10;            }&#10;&#10;        return {'total_matches': 0, 'player1_wins': 0, 'player2_wins': 0}&#10;&#10;    def _get_recent_h2h_matches(self, player1, player2):&#10;        &quot;&quot;&quot;&#10;        Obtener últimos enfrentamientos entre los jugadores&#10;        CORREGIDO: Para usar las columnas reales&#10;        &quot;&quot;&quot;&#10;        if 'historical_data' not in self.data_cache:&#10;            return []&#10;&#10;        df = self.data_cache['historical_data']&#10;        h2h_matches = []&#10;&#10;        # CORREGIDO: Buscar enfrentamientos directos usando player_1, player_2&#10;        if 'player_1' in df.columns and 'player_2' in df.columns and 'target' in df.columns:&#10;            # Enfrentamientos donde player1 vs player2&#10;            matches1 = df[&#10;                (df['player_1'].str.contains(player1, case=False, na=False)) &amp;&#10;                (df['player_2'].str.contains(player2, case=False, na=False))&#10;            ]&#10;&#10;            for _, match in matches1.iterrows():&#10;                winner = player1 if match.get('target', 0) == 1 else player2&#10;                loser = player2 if match.get('target', 0) == 1 else player1&#10;                h2h_matches.append({&#10;                    'date': match.get('tourney_date', ''),&#10;                    'tournament': match.get('tourney_name', 'Unknown'),&#10;                    'winner': winner,&#10;                    'loser': loser,&#10;                    'surface': match.get('surface', 'Unknown'),&#10;                    'score': match.get('score', ''),&#10;                    'round': match.get('round', '')&#10;                })&#10;&#10;            # Enfrentamientos donde player2 vs player1&#10;            matches2 = df[&#10;                (df['player_1'].str.contains(player2, case=False, na=False)) &amp;&#10;                (df['player_2'].str.contains(player1, case=False, na=False))&#10;            ]&#10;&#10;            for _, match in matches2.iterrows():&#10;                winner = player2 if match.get('target', 0) == 1 else player1&#10;                loser = player1 if match.get('target', 0) == 1 else player2&#10;                h2h_matches.append({&#10;                    'date': match.get('tourney_date', ''),&#10;                    'tournament': match.get('tourney_name', 'Unknown'),&#10;                    'winner': winner,&#10;                    'loser': loser,&#10;                    'surface': match.get('surface', 'Unknown'),&#10;                    'score': match.get('score', ''),&#10;                    'round': match.get('round', '')&#10;                })&#10;&#10;        # Ordenar por fecha (más reciente primero) y tomar los últimos 5&#10;        h2h_matches = sorted(h2h_matches, key=lambda x: x['date'], reverse=True)[:5]&#10;&#10;        return h2h_matches&#10;&#10;    def _calculate_days_since(self, date_str):&#10;        &quot;&quot;&quot;&#10;        Calcular días desde una fecha&#10;        &quot;&quot;&quot;&#10;        try:&#10;            if pd.isna(date_str):&#10;                return None&#10;            date_obj = pd.to_datetime(date_str)&#10;            days_diff = (pd.Timestamp.now() - date_obj).days&#10;            return int(days_diff)&#10;        except:&#10;            return None&#10;&#10;class PlayerAnalyzer:&#10;    &quot;&quot;&quot;Servicio de análisis de jugadores&quot;&quot;&quot;&#10;&#10;    def __init__(self, data_cache):&#10;        self.data_cache = data_cache&#10;&#10;    def get_player_stats(self, player_name, limit_matches=100):&#10;        &quot;&quot;&quot;Obtener estadísticas completas de un jugador&quot;&quot;&quot;&#10;        try:&#10;            if 'historical_data' not in self.data_cache:&#10;                return None&#10;&#10;            df = self.data_cache['historical_data']&#10;            matches = self._get_player_matches(df, player_name, limit_matches)&#10;&#10;            if not matches:&#10;                return None&#10;&#10;            # Calcular estadísticas básicas&#10;            basic_stats = self._calculate_basic_stats(matches)&#10;&#10;            # Estadísticas por superficie&#10;            surface_stats = self._calculate_surface_stats(matches)&#10;&#10;            # Forma reciente&#10;            recent_form = self._calculate_recent_form(matches)&#10;&#10;            # Rivales más enfrentados&#10;            head_to_head = self._calculate_h2h_stats(matches)&#10;&#10;            return {&#10;                'player_name': player_name,&#10;                'basic_stats': basic_stats,&#10;                'surface_stats': surface_stats,&#10;                'recent_form': recent_form,&#10;                'head_to_head': head_to_head,&#10;                'recent_matches': matches[:20]  # Últimos 20 partidos&#10;            }&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error analizando jugador {player_name}: {e}&quot;)&#10;            return None&#10;&#10;    def _get_player_matches(self, df, player_name, limit):&#10;        &quot;&quot;&quot;Obtener partidos de un jugador&quot;&quot;&quot;&#10;        matches = []&#10;&#10;        # Buscar en diferentes formatos de columnas&#10;        for winner_col, loser_col in [('winner_name', 'loser_name'), ('player_1', 'player_2')]:&#10;            if winner_col in df.columns and loser_col in df.columns:&#10;                # Partidos ganados&#10;                won_matches = df[df[winner_col].str.contains(player_name, case=False, na=False)]&#10;                for _, match in won_matches.iterrows():&#10;                    matches.append(self._format_match(match, winner_col, loser_col, 'Won'))&#10;&#10;                # Partidos perdidos&#10;                lost_matches = df[df[loser_col].str.contains(player_name, case=False, na=False)]&#10;                for _, match in lost_matches.iterrows():&#10;                    matches.append(self._format_match(match, winner_col, loser_col, 'Lost'))&#10;                break&#10;&#10;        # Ordenar por fecha (más reciente primero) y limitar&#10;        matches.sort(key=lambda x: x.get('date', ''), reverse=True)&#10;        return matches[:limit]&#10;&#10;    def _format_match(self, match, winner_col, loser_col, result):&#10;        &quot;&quot;&quot;Formatear información de un partido&quot;&quot;&quot;&#10;        opponent = match.get(loser_col if result == 'Won' else winner_col, 'Unknown')&#10;&#10;        return {&#10;            'date': match.get('tourney_date', ''),&#10;            'tournament': match.get('tourney_name', 'Unknown'),&#10;            'surface': match.get('surface', 'Unknown'),&#10;            'opponent': opponent,&#10;            'result': result,&#10;            'score': match.get('score', ''),&#10;            'round': match.get('round', ''),&#10;            'tournament_level': match.get('tourney_level', '')&#10;        }&#10;&#10;    def _calculate_basic_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas básicas&quot;&quot;&quot;&#10;        total = len(matches)&#10;        wins = sum(1 for m in matches if m['result'] == 'Won')&#10;&#10;        return {&#10;            'total_matches': total,&#10;            'wins': wins,&#10;            'losses': total - wins,&#10;            'win_rate': round(wins / total if total &gt; 0 else 0, 3)&#10;        }&#10;&#10;    def _calculate_surface_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas por superficie&quot;&quot;&quot;&#10;        surface_stats = defaultdict(lambda: {'wins': 0, 'losses': 0})&#10;&#10;        for match in matches:&#10;            surface = match['surface']&#10;            if match['result'] == 'Won':&#10;                surface_stats[surface]['wins'] += 1&#10;            else:&#10;                surface_stats[surface]['losses'] += 1&#10;&#10;        # Calcular win rates&#10;        result = {}&#10;        for surface, stats in surface_stats.items():&#10;            total = stats['wins'] + stats['losses']&#10;            result[surface] = {&#10;                'wins': stats['wins'],&#10;                'losses': stats['losses'],&#10;                'total': total,&#10;                'win_rate': round(stats['wins'] / total if total &gt; 0 else 0, 3)&#10;            }&#10;&#10;        return result&#10;&#10;    def _calculate_recent_form(self, matches):&#10;        &quot;&quot;&quot;Calcular forma reciente (últimos 10 partidos)&quot;&quot;&quot;&#10;        recent = matches[:10]&#10;        if not recent:&#10;            return {'wins': 0, 'losses': 0, 'win_rate': 0, 'form_string': ''}&#10;&#10;        wins = sum(1 for m in recent if m['result'] == 'Won')&#10;        form_string = ''.join('W' if m['result'] == 'Won' else 'L' for m in recent)&#10;&#10;        return {&#10;            'wins': wins,&#10;            'losses': len(recent) - wins,&#10;            'win_rate': round(wins / len(recent), 3),&#10;            'form_string': form_string&#10;        }&#10;&#10;    def _calculate_h2h_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas head-to-head&quot;&quot;&quot;&#10;        h2h = defaultdict(lambda: {'wins': 0, 'losses': 0})&#10;&#10;        for match in matches:&#10;            opponent = match['opponent']&#10;            if opponent and opponent != 'Unknown':&#10;                if match['result'] == 'Won':&#10;                    h2h[opponent]['wins'] += 1&#10;                else:&#10;                    h2h[opponent]['losses'] += 1&#10;&#10;        # Convertir a lista ordenada por total de enfrentamientos&#10;        h2h_list = []&#10;        for opponent, stats in h2h.items():&#10;            total = stats['wins'] + stats['losses']&#10;            if total &gt;= 2:  # Solo mostrar rivales enfrentados al menos 2 veces&#10;                h2h_list.append({&#10;                    'opponent': opponent,&#10;                    'wins': stats['wins'],&#10;                    'losses': stats['losses'],&#10;                    'total': total,&#10;                    'win_rate': round(stats['wins'] / total, 3)&#10;                })&#10;&#10;        return sorted(h2h_list, key=lambda x: x['total'], reverse=True)[:10]&#10;&#10;class TournamentAnalyzer:&#10;    &quot;&quot;&quot;Servicio de análisis de torneos&quot;&quot;&quot;&#10;&#10;    def __init__(self, data_cache):&#10;        self.data_cache = data_cache&#10;&#10;    def get_tournament_stats(self):&#10;        &quot;&quot;&quot;Obtener estadísticas de torneos&quot;&quot;&quot;&#10;        try:&#10;            if 'historical_data' not in self.data_cache:&#10;                return []&#10;&#10;            df = self.data_cache['historical_data']&#10;&#10;            if 'tourney_name' not in df.columns:&#10;                return []&#10;&#10;            # Agrupar por torneo&#10;            tournament_stats = df.groupby('tourney_name').agg({&#10;                'tourney_name': 'count',  # Total matches&#10;                'surface': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',&#10;                'tourney_level': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',&#10;                'tourney_date': ['min', 'max']&#10;            }).reset_index()&#10;&#10;            tournament_stats.columns = ['tournament', 'total_matches', 'surface', 'level', 'first_year', 'last_year']&#10;&#10;            # Convertir a lista de diccionarios&#10;            tournaments = []&#10;            for _, row in tournament_stats.iterrows():&#10;                tournaments.append({&#10;                    'name': row['tournament'],&#10;                    'total_matches': int(row['total_matches']),&#10;                    'surface': row['surface'],&#10;                    'level': row['level'],&#10;                    'years_active': f&quot;{row['first_year']} - {row['last_year']}&quot;&#10;                })&#10;&#10;            return sorted(tournaments, key=lambda x: x['total_matches'], reverse=True)&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error obteniendo estadísticas de torneos: {e}&quot;)&#10;            return []&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Servicios de predicción y análisis de tenis&#10;NUEVO: Usa features pre-calculadas desde archivo&#10;&quot;&quot;&quot;&#10;import pandas as pd&#10;import numpy as np&#10;from datetime import datetime, timedelta&#10;from collections import defaultdict&#10;import logging&#10;import pickle&#10;&#10;logger = logging.getLogger(__name__)&#10;&#10;class TennisPredictor:&#10;    &quot;&quot;&quot;Servicio principal de predicción de tenis - Usa features pre-calculadas&quot;&quot;&quot;&#10;&#10;    def __init__(self, model_cache, data_cache):&#10;        self.model_cache = model_cache&#10;        self.data_cache = data_cache&#10;&#10;        # VALIDACIÓN ESTRICTA: todo debe estar presente&#10;        self.model = model_cache.get('xgb_model')&#10;        self.imputer = model_cache.get('imputer')&#10;        self.training_states = model_cache.get('training_states', {})&#10;        self.feature_columns = self.training_states.get('feature_columns', [])&#10;&#10;        # FALLO INMEDIATO si algo no está&#10;        if not self.model:&#10;            raise ValueError(&quot;MODELO XGBOOST NO ENCONTRADO - La aplicación no puede funcionar&quot;)&#10;        if not self.imputer:&#10;            raise ValueError(&quot;IMPUTER NO ENCONTRADO - La aplicación no puede funcionar&quot;)&#10;        if not self.feature_columns:&#10;            raise ValueError(&quot;FEATURE COLUMNS NO ENCONTRADAS - La aplicación no puede funcionar&quot;)&#10;&#10;        # NUEVO: Cargar features pre-calculadas de jugadores&#10;        self.player_features = self._load_player_features()&#10;&#10;        logger.info(f&quot;✅ TennisPredictor inicializado con {len(self.feature_columns)} features&quot;)&#10;        logger.info(f&quot; Features pre-calculadas para {len(self.player_features)} jugadores&quot;)&#10;&#10;    def _load_player_features(self):&#10;        &quot;&quot;&quot;Cargar features pre-calculadas de jugadores desde archivo&quot;&quot;&quot;&#10;        from pathlib import Path&#10;&#10;        try:&#10;            outputs_dir = Path(__file__).parent / 'outputs'&#10;            player_features_path = outputs_dir / 'player_features.pkl'&#10;&#10;            if not player_features_path.exists():&#10;                logger.warning(f&quot;❌ Archivo de features de jugadores no encontrado: {player_features_path}&quot;)&#10;                logger.warning(&quot; Ejecuta el notebook hasta la sección 15 para generarlo&quot;)&#10;                return {}&#10;&#10;            logger.info(f&quot; Cargando features de jugadores desde {player_features_path}&quot;)&#10;            with open(player_features_path, 'rb') as f:&#10;                player_features = pickle.load(f)&#10;&#10;            logger.info(f&quot;✅ Features cargadas para {len(player_features)} jugadores&quot;)&#10;            return player_features&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;❌ Error cargando features de jugadores: {e}&quot;)&#10;            return {}&#10;&#10;    def predict_match(self, player1, player2, surface='Hard', tournament_level='ATP500'):&#10;        &quot;&quot;&quot;&#10;        Predecir resultado usando features pre-calculadas&#10;        &quot;&quot;&quot;&#10;        try:&#10;            # Verificar que tengamos features para ambos jugadores&#10;            if not self.player_features:&#10;                raise ValueError(&quot;No hay features de jugadores cargadas. Ejecuta el notebook hasta la sección 15.&quot;)&#10;&#10;            # Buscar features de ambos jugadores&#10;            p1_features = self._get_player_features(player1)&#10;            p2_features = self._get_player_features(player2)&#10;&#10;            if p1_features is None:&#10;                logger.warning(f&quot;⚠️ Player1 '{player1}' no encontrado en features pre-calculadas&quot;)&#10;            if p2_features is None:&#10;                logger.warning(f&quot;⚠️ Player2 '{player2}' no encontrado en features pre-calculadas&quot;)&#10;&#10;            # Crear features para ambas direcciones del enfrentamiento&#10;            features_1 = self._create_match_features(p1_features, p2_features, surface, player1, player2)&#10;            features_2 = self._create_match_features(p2_features, p1_features, surface, player2, player1)&#10;&#10;            # Validar dimensiones&#10;            expected = len(self.feature_columns)&#10;            if len(features_1) != expected or len(features_2) != expected:&#10;                logger.error(f&quot;MISMATCH DE FEATURES: esperado {expected}, obtenido {len(features_1)}/{len(features_2)}&quot;)&#10;                # Ajustar features si hay diferencia&#10;                features_1 = self._adjust_features_length(features_1, expected)&#10;                features_2 = self._adjust_features_length(features_2, expected)&#10;&#10;            # Preparar arrays e imputar&#10;            arr1 = np.array([features_1])&#10;            arr2 = np.array([features_2])&#10;            arr1_imp = self.imputer.transform(arr1)&#10;            arr2_imp = self.imputer.transform(arr2)&#10;&#10;            # Predicciones del modelo&#10;            probs1 = self.model.predict_proba(arr1_imp)[0]&#10;            probs2 = self.model.predict_proba(arr2_imp)[0]&#10;&#10;            # Promediado simétrico para evitar bias&#10;            prob_p1_from_direct = float(probs1[1])&#10;            prob_p1_from_inverted = 1.0 - float(probs2[1])&#10;            prob_player1_wins = (prob_p1_from_direct + prob_p1_from_inverted) / 2.0&#10;            prob_player2_wins = 1.0 - prob_player1_wins&#10;&#10;            # Información de jugadores y H2D&#10;            player1_info = self._get_player_detailed_info(player1, surface)&#10;            player2_info = self._get_player_detailed_info(player2, surface)&#10;            h2h_info = self._get_h2h_info(player1, player2)&#10;&#10;            response = {&#10;                'player1': player1,&#10;                'player2': player2,&#10;                'surface': surface,&#10;                'predictions': {&#10;                    'player1_win_probability': round(prob_player1_wins, 3),&#10;                    'player2_win_probability': round(prob_player2_wins, 3),&#10;                    'predicted_winner': player1 if prob_player1_wins &gt; 0.5 else player2,&#10;                    'confidence': round(abs(prob_player1_wins - 0.5) * 2, 3)&#10;                },&#10;                'player1_info': player1_info,&#10;                'player2_info': player2_info,&#10;                'head_to_head': h2h_info,&#10;                'model_type': 'XGBoost con Features Pre-calculadas',&#10;                'features_used': expected,&#10;                'model_accuracy': self.model_cache.get('model_summary', {}).get('performance', {}).get('accuracy', 'N/A'),&#10;                'status': 'success'&#10;            }&#10;&#10;            # Diagnósticos&#10;            response['diagnostics'] = {&#10;                'player1_found_in_features': p1_features is not None,&#10;                'player2_found_in_features': p2_features is not None,&#10;                'features_1_non_zero': int((np.array(features_1) != 0).sum()),&#10;                'features_2_non_zero': int((np.array(features_2) != 0).sum()),&#10;                'total_players_in_db': len(self.player_features),&#10;                'method': 'pre_calculated_features'&#10;            }&#10;&#10;            return response&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;ERROR CRÍTICO EN PREDICCIÓN: {e}&quot;)&#10;            raise e&#10;&#10;    def _get_player_features(self, player_name):&#10;        &quot;&quot;&quot;&#10;        Buscar features de un jugador (con búsqueda flexible)&#10;        &quot;&quot;&quot;&#10;        # Búsqueda exacta&#10;        if player_name in self.player_features:&#10;            return self.player_features[player_name]['model_features']&#10;&#10;        # Búsqueda parcial por apellido&#10;        player_lower = player_name.lower()&#10;        name_parts = player_lower.split()&#10;&#10;        # Buscar por apellido (última parte del nombre)&#10;        if len(name_parts) &gt;= 2:&#10;            surname = name_parts[-1]&#10;            for stored_name in self.player_features.keys():&#10;                if surname in stored_name.lower():&#10;                    return self.player_features[stored_name]['model_features']&#10;&#10;        # Buscar por cualquier parte del nombre&#10;        for stored_name in self.player_features.keys():&#10;            stored_lower = stored_name.lower()&#10;            if any(part in stored_lower for part in name_parts):&#10;                return self.player_features[stored_name]['model_features']&#10;&#10;        return None  # No encontrado&#10;&#10;    def _create_match_features(self, p1_features, p2_features, surface, player1_name, player2_name):&#10;        &quot;&quot;&quot;&#10;        Crear vector de features para un enfrentamiento específico&#10;        &quot;&quot;&quot;&#10;        # Si no tenemos features de algún jugador, usar valores neutros&#10;        if p1_features is None:&#10;            p1_features = {col: 0.0 for col in self.feature_columns}&#10;        if p2_features is None:&#10;            p2_features = {col: 0.0 for col in self.feature_columns}&#10;&#10;        # Crear vector de features alineado con feature_columns del modelo&#10;        match_features = []&#10;&#10;        for col in self.feature_columns:&#10;            # Intentar obtener el valor de features del jugador&#10;            value = 0.0  # Valor por defecto&#10;&#10;            # Estrategia: usar features del jugador 1 como base,&#10;            # y complementar con diferencias/ratios respecto al jugador 2&#10;            if col in p1_features:&#10;                value = p1_features[col]&#10;            elif col in p2_features:&#10;                # Si es una feature de &quot;diferencia&quot; o &quot;ratio&quot;, usar p2 como referencia&#10;                if 'diff' in col.lower() or 'ratio' in col.lower():&#10;                    value = -p2_features[col]  # Invertir para perspectiva del jugador 1&#10;                else:&#10;                    value = p2_features[col]&#10;&#10;            # Para features específicas de superficie, ajustar según superficie actual&#10;            if surface.lower() in col.lower():&#10;                # Dar más peso a features de la superficie específica&#10;                value *= 1.1&#10;&#10;            # Asegurar que es un float válido&#10;            try:&#10;                value = float(value)&#10;                if not np.isfinite(value):&#10;                    value = 0.0&#10;            except (ValueError, TypeError):&#10;                value = 0.0&#10;&#10;            match_features.append(value)&#10;&#10;        return match_features&#10;&#10;    def _adjust_features_length(self, features, expected_length):&#10;        &quot;&quot;&quot;&#10;        Ajustar longitud de features si hay diferencia&#10;        &quot;&quot;&quot;&#10;        if len(features) &lt; expected_length:&#10;            # Rellenar con ceros&#10;            features.extend([0.0] * (expected_length - len(features)))&#10;        elif len(features) &gt; expected_length:&#10;            # Truncar&#10;            features = features[:expected_length]&#10;        return features&#10;&#10;    def _get_player_detailed_info(self, player_name, surface):&#10;        &quot;&quot;&quot;&#10;        Obtener información detallada de un jugador SOLO desde features pre-calculadas&#10;        &quot;&quot;&quot;&#10;        # Obtener metadata del archivo de features&#10;        player_metadata = None&#10;        if player_name in self.player_features:&#10;            player_metadata = self.player_features[player_name].get('metadata', {})&#10;        &#10;        # Si no encontramos metadata, buscar con búsqueda flexible&#10;        if not player_metadata:&#10;            # Búsqueda flexible igual que en _get_player_features&#10;            player_lower = player_name.lower()&#10;            name_parts = player_lower.split()&#10;            &#10;            # Buscar por apellido&#10;            if len(name_parts) &gt;= 2:&#10;                surname = name_parts[-1]&#10;                for stored_name in self.player_features.keys():&#10;                    if surname in stored_name.lower():&#10;                        player_metadata = self.player_features[stored_name].get('metadata', {})&#10;                        break&#10;            &#10;            # Buscar por cualquier parte del nombre&#10;            if not player_metadata:&#10;                for stored_name in self.player_features.keys():&#10;                    stored_lower = stored_name.lower()&#10;                    if any(part in stored_lower for part in name_parts):&#10;                        player_metadata = self.player_features[stored_name].get('metadata', {})&#10;                        break&#10;        &#10;        # Si aún no tenemos metadata, usar valores por defecto&#10;        if not player_metadata:&#10;            player_metadata = {&#10;                'last_match_date': None,&#10;                'total_matches': 0,&#10;                'global_elo': 1500,&#10;                'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500}&#10;            }&#10;        &#10;        # Obtener ELO para la superficie específica&#10;        surface_elos = player_metadata.get('surface_elos', {})&#10;        surface_elo = surface_elos.get(surface.lower(), player_metadata.get('global_elo', 1500))&#10;        global_elo = player_metadata.get('global_elo', 1500)&#10;        &#10;        # Información básica del jugador SOLO desde metadata pre-calculada&#10;        player_info = {&#10;            'name': player_name,&#10;            'elo_ratings': {&#10;                'global_elo': int(global_elo),&#10;                'surface_elo': int(surface_elo),&#10;                'elo_difference': int(surface_elo - global_elo)&#10;            },&#10;            'career_stats': {&#10;                'total_matches': player_metadata.get('total_matches', 0),&#10;                'wins': int(player_metadata.get('total_matches', 0) * 0.5),  # Estimación&#10;                'losses': int(player_metadata.get('total_matches', 0) * 0.5),  # Estimación&#10;                'win_rate': 0.5  # Valor neutro&#10;            },&#10;            'recent_form': {&#10;                'recent_matches': 0,&#10;                'recent_wins': 0,&#10;                'recent_win_rate': 0.5,&#10;                'form_string': 'N/A',&#10;                'note': 'Información desde features pre-calculadas'&#10;            },&#10;            'surface_performance': {&#10;                'matches_on_surface': 0,&#10;                'wins_on_surface': 0,&#10;                'surface_win_rate': 0.5,&#10;                'note': 'Información desde features pre-calculadas'&#10;            },&#10;            'last_match_info': {&#10;                'last_match': {&#10;                    'date': player_metadata.get('last_match_date', ''),&#10;                    'tournament': player_metadata.get('last_tournament', 'Unknown'),&#10;                    'opponent': player_metadata.get('last_opponent', 'Unknown'),&#10;                    'surface': player_metadata.get('last_surface', 'Unknown'),&#10;                    'result': 'Unknown',&#10;                    'score': '',&#10;                    'round': ''&#10;                } if player_metadata.get('last_match_date') else None,&#10;                'days_since_last_match': self._calculate_days_since(player_metadata.get('last_match_date'))&#10;            }&#10;        }&#10;&#10;        return player_info&#10;&#10;    def _get_h2h_info(self, player1, player2):&#10;        &quot;&quot;&quot;&#10;        Obtener información head-to-head SOLO desde training_states&#10;        &quot;&quot;&quot;&#10;        h2h_data = self.training_states.get('final_h2h', {})&#10;&#10;        # Buscar H2H en training_states&#10;        h2h_key1 = f&quot;{player1}_vs_{player2}&quot;&#10;        h2h_key2 = f&quot;{player2}_vs_{player1}&quot;&#10;&#10;        h2h_stats1 = h2h_data.get(h2h_key1, {})&#10;        h2h_stats2 = h2h_data.get(h2h_key2, {})&#10;&#10;        # Combinar estadísticas de training_states&#10;        player1_wins = h2h_stats1.get('wins', 0) + h2h_stats2.get('losses', 0)&#10;        player2_wins = h2h_stats1.get('losses', 0) + h2h_stats2.get('wins', 0)&#10;        total_matches = player1_wins + player2_wins&#10;&#10;        if total_matches == 0:&#10;            return {&#10;                'total_matches': 0,&#10;                'player1_wins': 0,&#10;                'player2_wins': 0,&#10;                'player1_h2h_rate': 0.5,&#10;                'note': 'No hay enfrentamientos previos registrados',&#10;                'recent_matches': []&#10;            }&#10;&#10;        return {&#10;            'total_matches': total_matches,&#10;            'player1_wins': player1_wins,&#10;            'player2_wins': player2_wins,&#10;            'player1_h2h_rate': round(player1_wins / total_matches, 3),&#10;            'player2_h2h_rate': round(player2_wins / total_matches, 3),&#10;            'head_to_head_advantage': player1 if player1_wins &gt; player2_wins else player2 if player2_wins &gt; player1_wins else 'Even',&#10;            'recent_matches': []  # No calculamos matches recientes&#10;        }&#10;&#10;    def _calculate_days_since(self, date_str):&#10;        &quot;&quot;&quot;&#10;        Calcular días desde una fecha&#10;        &quot;&quot;&quot;&#10;        try:&#10;            if not date_str or pd.isna(date_str) or date_str == 'None':&#10;                return None&#10;            date_obj = pd.to_datetime(date_str)&#10;            days_diff = (pd.Timestamp.now() - date_obj).days&#10;            return int(days_diff)&#10;        except:&#10;            return None&#10;&#10;class PlayerAnalyzer:&#10;    &quot;&quot;&quot;Servicio de análisis de jugadores&quot;&quot;&quot;&#10;&#10;    def __init__(self, data_cache):&#10;        self.data_cache = data_cache&#10;&#10;    def get_player_stats(self, player_name, limit_matches=100):&#10;        &quot;&quot;&quot;Obtener estadísticas completas de un jugador&quot;&quot;&quot;&#10;        try:&#10;            if 'historical_data' not in self.data_cache:&#10;                return None&#10;&#10;            df = self.data_cache['historical_data']&#10;            matches = self._get_player_matches(df, player_name, limit_matches)&#10;&#10;            if not matches:&#10;                return None&#10;&#10;            # Calcular estadísticas básicas&#10;            basic_stats = self._calculate_basic_stats(matches)&#10;&#10;            # Estadísticas por superficie&#10;            surface_stats = self._calculate_surface_stats(matches)&#10;&#10;            # Forma reciente&#10;            recent_form = self._calculate_recent_form(matches)&#10;&#10;            # Rivales más enfrentados&#10;            head_to_head = self._calculate_h2h_stats(matches)&#10;&#10;            return {&#10;                'player_name': player_name,&#10;                'basic_stats': basic_stats,&#10;                'surface_stats': surface_stats,&#10;                'recent_form': recent_form,&#10;                'head_to_head': head_to_head,&#10;                'recent_matches': matches[:20]  # Últimos 20 partidos&#10;            }&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error analizando jugador {player_name}: {e}&quot;)&#10;            return None&#10;&#10;    def _get_player_matches(self, df, player_name, limit):&#10;        &quot;&quot;&quot;Obtener partidos de un jugador&quot;&quot;&quot;&#10;        matches = []&#10;&#10;        # Buscar en diferentes formatos de columnas&#10;        for winner_col, loser_col in [('winner_name', 'loser_name'), ('player_1', 'player_2')]:&#10;            if winner_col in df.columns and loser_col in df.columns:&#10;                # Partidos ganados&#10;                won_matches = df[df[winner_col].str.contains(player_name, case=False, na=False)]&#10;                for _, match in won_matches.iterrows():&#10;                    matches.append(self._format_match(match, winner_col, loser_col, 'Won'))&#10;&#10;                # Partidos perdidos&#10;                lost_matches = df[df[loser_col].str.contains(player_name, case=False, na=False)]&#10;                for _, match in lost_matches.iterrows():&#10;                    matches.append(self._format_match(match, winner_col, loser_col, 'Lost'))&#10;                break&#10;&#10;        # Ordenar por fecha (más reciente primero) y limitar&#10;        matches.sort(key=lambda x: x.get('date', ''), reverse=True)&#10;        return matches[:limit]&#10;&#10;    def _format_match(self, match, winner_col, loser_col, result):&#10;        &quot;&quot;&quot;Formatear información de un partido&quot;&quot;&quot;&#10;        opponent = match.get(loser_col if result == 'Won' else winner_col, 'Unknown')&#10;&#10;        return {&#10;            'date': match.get('tourney_date', ''),&#10;            'tournament': match.get('tourney_name', 'Unknown'),&#10;            'surface': match.get('surface', 'Unknown'),&#10;            'opponent': opponent,&#10;            'result': result,&#10;            'score': match.get('score', ''),&#10;            'round': match.get('round', ''),&#10;            'tournament_level': match.get('tourney_level', '')&#10;        }&#10;&#10;    def _calculate_basic_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas básicas&quot;&quot;&quot;&#10;        total = len(matches)&#10;        wins = sum(1 for m in matches if m['result'] == 'Won')&#10;&#10;        return {&#10;            'total_matches': total,&#10;            'wins': wins,&#10;            'losses': total - wins,&#10;            'win_rate': round(wins / total if total &gt; 0 else 0, 3)&#10;        }&#10;&#10;    def _calculate_surface_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas por superficie&quot;&quot;&quot;&#10;        surface_stats = defaultdict(lambda: {'wins': 0, 'losses': 0})&#10;&#10;        for match in matches:&#10;            surface = match['surface']&#10;            if match['result'] == 'Won':&#10;                surface_stats[surface]['wins'] += 1&#10;            else:&#10;                surface_stats[surface]['losses'] += 1&#10;&#10;        # Calcular win rates&#10;        result = {}&#10;        for surface, stats in surface_stats.items():&#10;            total = stats['wins'] + stats['losses']&#10;            result[surface] = {&#10;                'wins': stats['wins'],&#10;                'losses': stats['losses'],&#10;                'total': total,&#10;                'win_rate': round(stats['wins'] / total if total &gt; 0 else 0, 3)&#10;            }&#10;&#10;        return result&#10;&#10;    def _calculate_recent_form(self, matches):&#10;        &quot;&quot;&quot;Calcular forma reciente (últimos 10 partidos)&quot;&quot;&quot;&#10;        recent = matches[:10]&#10;        if not recent:&#10;            return {'wins': 0, 'losses': 0, 'win_rate': 0, 'form_string': ''}&#10;&#10;        wins = sum(1 for m in recent if m['result'] == 'Won')&#10;        form_string = ''.join('W' if m['result'] == 'Won' else 'L' for m in recent)&#10;&#10;        return {&#10;            'wins': wins,&#10;            'losses': len(recent) - wins,&#10;            'win_rate': round(wins / len(recent), 3),&#10;            'form_string': form_string&#10;        }&#10;&#10;    def _calculate_h2h_stats(self, matches):&#10;        &quot;&quot;&quot;Calcular estadísticas head-to-head&quot;&quot;&quot;&#10;        h2h = defaultdict(lambda: {'wins': 0, 'losses': 0})&#10;&#10;        for match in matches:&#10;            opponent = match['opponent']&#10;            if opponent and opponent != 'Unknown':&#10;                if match['result'] == 'Won':&#10;                    h2h[opponent]['wins'] += 1&#10;                else:&#10;                    h2h[opponent]['losses'] += 1&#10;&#10;        # Convertir a lista ordenada por total de enfrentamientos&#10;        h2h_list = []&#10;        for opponent, stats in h2h.items():&#10;            total = stats['wins'] + stats['losses']&#10;            if total &gt;= 2:  # Solo mostrar rivales enfrentados al menos 2 veces&#10;                h2h_list.append({&#10;                    'opponent': opponent,&#10;                    'wins': stats['wins'],&#10;                    'losses': stats['losses'],&#10;                    'total': total,&#10;                    'win_rate': round(stats['wins'] / total, 3)&#10;                })&#10;&#10;        return sorted(h2h_list, key=lambda x: x['total'], reverse=True)[:10]&#10;&#10;class TournamentAnalyzer:&#10;    &quot;&quot;&quot;Servicio de análisis de torneos&quot;&quot;&quot;&#10;&#10;    def __init__(self, data_cache):&#10;        self.data_cache = data_cache&#10;&#10;    def get_tournament_stats(self):&#10;        &quot;&quot;&quot;Obtener estadísticas de torneos&quot;&quot;&quot;&#10;        try:&#10;            if 'historical_data' not in self.data_cache:&#10;                return []&#10;&#10;            df = self.data_cache['historical_data']&#10;&#10;            if 'tourney_name' not in df.columns:&#10;                return []&#10;&#10;            # Agrupar por torneo&#10;            tournament_stats = df.groupby('tourney_name').agg({&#10;                'tourney_name': 'count',  # Total matches&#10;                'surface': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',&#10;                'tourney_level': lambda x: x.mode().iloc[0] if not x.empty else 'Unknown',&#10;                'tourney_date': ['min', 'max']&#10;            }).reset_index()&#10;&#10;            tournament_stats.columns = ['tournament', 'total_matches', 'surface', 'level', 'first_year', 'last_year']&#10;&#10;            # Convertir a lista de diccionarios&#10;            tournaments = []&#10;            for _, row in tournament_stats.iterrows():&#10;                tournaments.append({&#10;                    'name': row['tournament'],&#10;                    'total_matches': int(row['total_matches']),&#10;                    'surface': row['surface'],&#10;                    'level': row['level'],&#10;                    'years_active': f&quot;{row['first_year']} - {row['last_year']}&quot;&#10;                })&#10;&#10;            return sorted(tournaments, key=lambda x: x['total_matches'], reverse=True)&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Error obteniendo estadísticas de torneos: {e}&quot;)&#10;            return []" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/.env">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/.env" />
              <option name="updatedContent" value="# Database&#10;DATABASE_URL=&quot;file:./dev.db&quot;&#10;&#10;# Next.js&#10;NEXTAUTH_SECRET=&quot;your-secret-key-here&quot;&#10;NEXTAUTH_URL=&quot;http://localhost:3000&quot;&#10;&#10;# Optional: For production&#10;# VERCEL_ENV=&quot;development&quot;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/next.config.js">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/next.config.js" />
              <option name="updatedContent" value="/** @type {import('next').NextConfig} */&#10;const nextConfig = {&#10;  experimental: {&#10;    serverComponentsExternalPackages: ['@prisma/client'],&#10;  },&#10;  images: {&#10;    domains: ['images.unsplash.com', 'example.com'],&#10;    formats: ['image/webp', 'image/avif'],&#10;  },&#10;  async headers() {&#10;    return [&#10;      {&#10;        source: '/api/:path*',&#10;        headers: [&#10;          {&#10;            key: 'Access-Control-Allow-Origin',&#10;            value: '*',&#10;          },&#10;          {&#10;            key: 'Access-Control-Allow-Methods',&#10;            value: 'GET, POST, PUT, DELETE, OPTIONS',&#10;          },&#10;          {&#10;            key: 'Access-Control-Allow-Headers',&#10;            value: 'Content-Type, Authorization',&#10;          },&#10;        ],&#10;      },&#10;    ]&#10;  },&#10;}&#10;&#10;module.exports = nextConfig" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/package.json">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/package.json" />
              <option name="updatedContent" value="{&#10;  &quot;name&quot;: &quot;tennis-predictor&quot;,&#10;  &quot;version&quot;: &quot;0.1.0&quot;,&#10;  &quot;private&quot;: true,&#10;  &quot;scripts&quot;: {&#10;    &quot;dev&quot;: &quot;next dev&quot;,&#10;    &quot;build&quot;: &quot;next build&quot;,&#10;    &quot;start&quot;: &quot;next start&quot;,&#10;    &quot;lint&quot;: &quot;next lint&quot;,&#10;    &quot;db:push&quot;: &quot;prisma db push&quot;,&#10;    &quot;db:generate&quot;: &quot;prisma generate&quot;,&#10;    &quot;db:migrate&quot;: &quot;prisma db migrate dev&quot;,&#10;    &quot;db:seed&quot;: &quot;tsx scripts/seed.ts&quot;,&#10;    &quot;type-check&quot;: &quot;tsc --noEmit&quot;&#10;  },&#10;  &quot;dependencies&quot;: {&#10;    &quot;next&quot;: &quot;14.2.4&quot;,&#10;    &quot;react&quot;: &quot;^18.3.1&quot;,&#10;    &quot;react-dom&quot;: &quot;^18.3.1&quot;,&#10;    &quot;@prisma/client&quot;: &quot;^5.15.0&quot;,&#10;    &quot;@radix-ui/react-avatar&quot;: &quot;^1.0.4&quot;,&#10;    &quot;@radix-ui/react-button&quot;: &quot;^2.0.3&quot;,&#10;    &quot;@radix-ui/react-card&quot;: &quot;^1.0.4&quot;,&#10;    &quot;@radix-ui/react-dropdown-menu&quot;: &quot;^2.0.6&quot;,&#10;    &quot;@radix-ui/react-icons&quot;: &quot;^1.3.0&quot;,&#10;    &quot;@radix-ui/react-label&quot;: &quot;^2.0.2&quot;,&#10;    &quot;@radix-ui/react-select&quot;: &quot;^2.0.0&quot;,&#10;    &quot;@radix-ui/react-separator&quot;: &quot;^1.0.3&quot;,&#10;    &quot;@radix-ui/react-slot&quot;: &quot;^1.0.2&quot;,&#10;    &quot;@radix-ui/react-tabs&quot;: &quot;^1.0.4&quot;,&#10;    &quot;@radix-ui/react-toast&quot;: &quot;^1.1.5&quot;,&#10;    &quot;class-variance-authority&quot;: &quot;^0.7.0&quot;,&#10;    &quot;clsx&quot;: &quot;^2.1.1&quot;,&#10;    &quot;date-fns&quot;: &quot;^3.6.0&quot;,&#10;    &quot;lucide-react&quot;: &quot;^0.395.0&quot;,&#10;    &quot;recharts&quot;: &quot;^2.12.7&quot;,&#10;    &quot;tailwind-merge&quot;: &quot;^2.3.0&quot;,&#10;    &quot;tailwindcss-animate&quot;: &quot;^1.0.7&quot;,&#10;    &quot;zod&quot;: &quot;^3.23.8&quot;,&#10;    &quot;csv-parser&quot;: &quot;^3.0.0&quot;,&#10;    &quot;papaparse&quot;: &quot;^5.4.1&quot;&#10;  },&#10;  &quot;devDependencies&quot;: {&#10;    &quot;typescript&quot;: &quot;^5.5.2&quot;,&#10;    &quot;@types/node&quot;: &quot;^20.14.8&quot;,&#10;    &quot;@types/react&quot;: &quot;^18.3.3&quot;,&#10;    &quot;@types/react-dom&quot;: &quot;^18.3.0&quot;,&#10;    &quot;@types/papaparse&quot;: &quot;^5.3.14&quot;,&#10;    &quot;autoprefixer&quot;: &quot;^10.4.19&quot;,&#10;    &quot;eslint&quot;: &quot;^8.57.0&quot;,&#10;    &quot;eslint-config-next&quot;: &quot;14.2.4&quot;,&#10;    &quot;postcss&quot;: &quot;^8.4.38&quot;,&#10;    &quot;tailwindcss&quot;: &quot;^3.4.4&quot;,&#10;    &quot;prisma&quot;: &quot;^5.15.0&quot;,&#10;    &quot;tsx&quot;: &quot;^4.15.7&quot;&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/prisma/schema.prisma">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/prisma/schema.prisma" />
              <option name="updatedContent" value="// This is your Prisma schema file,&#10;// learn more about it in the docs: https://pris.ly/d/prisma-schema&#10;&#10;generator client {&#10;  provider = &quot;prisma-client-js&quot;&#10;}&#10;&#10;datasource db {&#10;  provider = &quot;sqlite&quot;&#10;  url      = env(&quot;DATABASE_URL&quot;)&#10;}&#10;&#10;model Player {&#10;  id        String   @id @default(cuid())&#10;  name      String   @unique&#10;  country   String?&#10;  birthDate DateTime?&#10;  height    Int?      // in cm&#10;  hand      String?   // &quot;R&quot; or &quot;L&quot;&#10;  backhand  String?   // &quot;1&quot; or &quot;2&quot;&#10;  createdAt DateTime @default(now())&#10;  updatedAt DateTime @updatedAt&#10;&#10;  // Relaciones&#10;  player1Matches Match[] @relation(&quot;Player1Matches&quot;)&#10;  player2Matches Match[] @relation(&quot;Player2Matches&quot;)&#10;  winnerMatches  Match[] @relation(&quot;WinnerMatches&quot;)&#10;  loserMatches   Match[] @relation(&quot;LoserMatches&quot;)&#10;  &#10;  eloHistories   EloHistory[]&#10;  predictions1   Prediction[] @relation(&quot;Player1Predictions&quot;)&#10;  predictions2   Prediction[] @relation(&quot;Player2Predictions&quot;)&#10;  &#10;  @@map(&quot;players&quot;)&#10;}&#10;&#10;model Tournament {&#10;  id       String @id @default(cuid())&#10;  name     String&#10;  level    String // &quot;G&quot; for Grand Slam, &quot;M&quot; for Masters, etc.&#10;  surface  Surface&#10;  location String?&#10;  &#10;  matches Match[]&#10;  &#10;  @@map(&quot;tournaments&quot;)&#10;}&#10;&#10;model Match {&#10;  id           String    @id @default(cuid())&#10;  date         DateTime&#10;  surface      Surface&#10;  round        String?&#10;  bestOf       Int       @default(3)&#10;  minutes      Int?&#10;  &#10;  // Jugadores&#10;  player1Id    String&#10;  player2Id    String&#10;  winnerId     String?&#10;  loserId      String?&#10;  &#10;  // Score&#10;  score        String?&#10;  sets         String?&#10;  &#10;  // Tournament info&#10;  tournamentId String&#10;  &#10;  // Stats del partido (migrados de tus CSVs)&#10;  p1Ace        Int?&#10;  p1Df         Int?&#10;  p1Svpt       Int?&#10;  p1FirstIn    Int?&#10;  p1FirstWon   Int?&#10;  p1SecondWon  Int?&#10;  p1BpSaved    Int?&#10;  p1BpFaced    Int?&#10;  &#10;  p2Ace        Int?&#10;  p2Df         Int?&#10;  p2Svpt       Int?&#10;  p2FirstIn    Int?&#10;  p2FirstWon   Int?&#10;  p2SecondWon  Int?&#10;  p2BpSaved    Int?&#10;  p2BpFaced    Int?&#10;  &#10;  // ELO ratings antes del partido&#10;  p1EloRating  Float?&#10;  p2EloRating  Float?&#10;  p1SurfaceElo Float?&#10;  p2SurfaceElo Float?&#10;  &#10;  createdAt    DateTime @default(now())&#10;  &#10;  // Relaciones&#10;  player1      Player     @relation(&quot;Player1Matches&quot;, fields: [player1Id], references: [id])&#10;  player2      Player     @relation(&quot;Player2Matches&quot;, fields: [player2Id], references: [id])&#10;  winner       Player?    @relation(&quot;WinnerMatches&quot;, fields: [winnerId], references: [id])&#10;  loser        Player?    @relation(&quot;LoserMatches&quot;, fields: [loserId], references: [id])&#10;  tournament   Tournament @relation(fields: [tournamentId], references: [id])&#10;  &#10;  @@map(&quot;matches&quot;)&#10;}&#10;&#10;model EloHistory {&#10;  id          String   @id @default(cuid())&#10;  playerId    String&#10;  date        DateTime&#10;  rating      Float&#10;  surfaceElo  Float?&#10;  surface     Surface?&#10;  matches     Int      @default(0)&#10;  &#10;  player      Player   @relation(fields: [playerId], references: [id])&#10;  &#10;  @@unique([playerId, date, surface])&#10;  @@map(&quot;elo_histories&quot;)&#10;}&#10;&#10;model Prediction {&#10;  id              String           @id @default(cuid())&#10;  player1Id       String&#10;  player2Id       String&#10;  surface         Surface&#10;  prediction      PredictionResult&#10;  confidence      Float&#10;  eloAdvantage    Float?&#10;  formDifference  Float?&#10;  surfaceBonus    Float?&#10;  &#10;  // Resultado real si ya se jugó&#10;  actualResult    PredictionResult?&#10;  matchId         String?&#10;  &#10;  createdAt       DateTime         @default(now())&#10;  &#10;  // Relaciones&#10;  player1         Player           @relation(&quot;Player1Predictions&quot;, fields: [player1Id], references: [id])&#10;  player2         Player           @relation(&quot;Player2Predictions&quot;, fields: [player2Id], references: [id])&#10;  &#10;  @@map(&quot;predictions&quot;)&#10;}&#10;&#10;enum Surface {&#10;  HARD&#10;  CLAY&#10;  GRASS&#10;  CARPET&#10;}&#10;&#10;enum PredictionResult {&#10;  PLAYER1_WIN&#10;  PLAYER2_WIN&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/app/api/players/[id]/route.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/app/api/players/[id]/route.ts" />
              <option name="updatedContent" value="import { NextRequest, NextResponse } from 'next/server';&#10;import { PlayerService } from '@/lib/player-service';&#10;&#10;export async function GET(&#10;  request: NextRequest,&#10;  { params }: { params: { id: string } }&#10;) {&#10;  try {&#10;    const playerId = params.id;&#10;    &#10;    if (!playerId) {&#10;      return NextResponse.json(&#10;        { error: 'ID de jugador requerido' },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    // Obtener perfil completo del jugador&#10;    const playerProfile = await PlayerService.getPlayerProfile(playerId);&#10;    &#10;    if (!playerProfile) {&#10;      return NextResponse.json(&#10;        { error: 'Jugador no encontrado' },&#10;        { status: 404 }&#10;      );&#10;    }&#10;&#10;    return NextResponse.json({&#10;      success: true,&#10;      player: playerProfile,&#10;      timestamp: new Date().toISOString()&#10;    });&#10;&#10;  } catch (error) {&#10;    console.error('Error fetching player profile:', error);&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/app/api/players/search/route.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/app/api/players/search/route.ts" />
              <option name="updatedContent" value="import { NextRequest, NextResponse } from 'next/server';&#10;import { PlayerService } from '@/lib/player-service';&#10;import { z } from 'zod';&#10;&#10;const searchSchema = z.object({&#10;  query: z.string().min(1).max(100),&#10;  limit: z.number().min(1).max(50).optional()&#10;});&#10;&#10;export async function GET(request: NextRequest) {&#10;  try {&#10;    const { searchParams } = new URL(request.url);&#10;    const query = searchParams.get('query');&#10;    const limit = parseInt(searchParams.get('limit') || '20');&#10;&#10;    if (!query) {&#10;      return NextResponse.json(&#10;        { error: 'Query de búsqueda requerido' },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    const { query: searchQuery, limit: searchLimit } = searchSchema.parse({&#10;      query,&#10;      limit&#10;    });&#10;&#10;    const players = await PlayerService.searchPlayers(searchQuery, searchLimit);&#10;&#10;    return NextResponse.json({&#10;      success: true,&#10;      players,&#10;      total: players.length,&#10;      query: searchQuery&#10;    });&#10;&#10;  } catch (error) {&#10;    console.error('Error searching players:', error);&#10;    &#10;    if (error instanceof z.ZodError) {&#10;      return NextResponse.json(&#10;        { error: 'Parámetros de búsqueda inválidos', details: error.errors },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}&#10;&#10;export async function POST(request: NextRequest) {&#10;  try {&#10;    // Para búsquedas más complejas con filtros&#10;    const body = await request.json();&#10;    // TODO: Implementar búsqueda avanzada con filtros&#10;    return NextResponse.json({ message: 'Búsqueda avanzada en desarrollo' });&#10;  } catch (error) {&#10;    console.error('Error in advanced search:', error);&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/app/api/predictions/route.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/app/api/predictions/route.ts" />
              <option name="updatedContent" value="import { NextRequest, NextResponse } from 'next/server';&#10;import { PlayerService } from '@/lib/player-service';&#10;import { PredictionEngine } from '@/lib/prediction-engine';&#10;import { Surface } from '@/types/tennis';&#10;import { z } from 'zod';&#10;&#10;const predictionSchema = z.object({&#10;  player1Id: z.string(),&#10;  player2Id: z.string(),&#10;  surface: z.nativeEnum(Surface)&#10;});&#10;&#10;/**&#10; * API para crear predicciones&#10; * Migra la funcionalidad de simple_prediction() desde Python&#10; */&#10;export async function POST(request: NextRequest) {&#10;  try {&#10;    const body = await request.json();&#10;    const { player1Id, player2Id, surface } = predictionSchema.parse(body);&#10;&#10;    // Obtener estadísticas de ambos jugadores&#10;    const [player1Stats, player2Stats] = await Promise.all([&#10;      PlayerService.getPlayerStats(player1Id),&#10;      PlayerService.getPlayerStats(player2Id)&#10;    ]);&#10;&#10;    if (!player1Stats || !player2Stats) {&#10;      return NextResponse.json(&#10;        { error: 'Jugador no encontrado' },&#10;        { status: 404 }&#10;      );&#10;    }&#10;&#10;    // Generar predicción usando el motor migrado&#10;    const prediction = PredictionEngine.predictMatch(&#10;      player1Stats,&#10;      player2Stats,&#10;      surface&#10;    );&#10;&#10;    // Obtener H2H para contexto adicional&#10;    const h2hRecord = await PlayerService.getH2HRecord(player1Id, player2Id);&#10;&#10;    return NextResponse.json({&#10;      success: true,&#10;      prediction,&#10;      players: {&#10;        player1: player1Stats,&#10;        player2: player2Stats&#10;      },&#10;      h2hRecord,&#10;      surface,&#10;      timestamp: new Date().toISOString()&#10;    });&#10;&#10;  } catch (error) {&#10;    console.error('Error creating prediction:', error);&#10;    &#10;    if (error instanceof z.ZodError) {&#10;      return NextResponse.json(&#10;        { error: 'Datos inválidos', details: error.errors },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}&#10;&#10;/**&#10; * API para obtener predicciones guardadas&#10; */&#10;export async function GET(request: NextRequest) {&#10;  try {&#10;    const { searchParams } = new URL(request.url);&#10;    const limit = Math.min(parseInt(searchParams.get('limit') || '20'), 100);&#10;    &#10;    // TODO: Implementar cuando tengamos tabla de predicciones guardadas&#10;    // const predictions = await db.prediction.findMany({&#10;    //   take: limit,&#10;    //   orderBy: { createdAt: 'desc' },&#10;    //   include: {&#10;    //     player1: true,&#10;    //     player2: true&#10;    //   }&#10;    // });&#10;&#10;    return NextResponse.json({&#10;      success: true,&#10;      predictions: [], // predictions,&#10;      message: 'Funcionalidad de historial en desarrollo'&#10;    });&#10;&#10;  } catch (error) {&#10;    console.error('Error fetching predictions:', error);&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/app/api/stats/elo-evolution/route.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/app/api/stats/elo-evolution/route.ts" />
              <option name="updatedContent" value="import { NextRequest, NextResponse } from 'next/server';&#10;import { db } from '@/lib/db';&#10;import { z } from 'zod';&#10;&#10;const eloEvolutionSchema = z.object({&#10;  playerId: z.string(),&#10;  surface: z.enum(['HARD', 'CLAY', 'GRASS', 'CARPET']).optional(),&#10;  fromDate: z.string().optional(),&#10;  toDate: z.string().optional(),&#10;  limit: z.number().min(1).max(500).optional()&#10;});&#10;&#10;export async function GET(request: NextRequest) {&#10;  try {&#10;    const { searchParams } = new URL(request.url);&#10;    const playerId = searchParams.get('playerId');&#10;    const surface = searchParams.get('surface');&#10;    const fromDate = searchParams.get('fromDate');&#10;    const toDate = searchParams.get('toDate');&#10;    const limit = parseInt(searchParams.get('limit') || '100');&#10;&#10;    if (!playerId) {&#10;      return NextResponse.json(&#10;        { error: 'ID de jugador requerido' },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    const { playerId: validPlayerId, surface: validSurface, limit: validLimit } = &#10;      eloEvolutionSchema.parse({&#10;        playerId,&#10;        surface: surface as any,&#10;        fromDate,&#10;        toDate,&#10;        limit&#10;      });&#10;&#10;    // Construir filtros para la consulta&#10;    const whereClause: any = {&#10;      playerId: validPlayerId&#10;    };&#10;&#10;    if (validSurface) {&#10;      whereClause.surface = validSurface;&#10;    }&#10;&#10;    if (fromDate) {&#10;      whereClause.date = { gte: new Date(fromDate) };&#10;    }&#10;&#10;    if (toDate) {&#10;      whereClause.date = { &#10;        ...whereClause.date,&#10;        lte: new Date(toDate)&#10;      };&#10;    }&#10;&#10;    // Obtener evolución de ELO&#10;    const eloHistory = await db.eloHistory.findMany({&#10;      where: whereClause,&#10;      orderBy: { date: 'asc' },&#10;      take: validLimit,&#10;      include: {&#10;        player: {&#10;          select: {&#10;            name: true,&#10;            country: true&#10;          }&#10;        }&#10;      }&#10;    });&#10;&#10;    // Formatear datos para gráficos&#10;    const evolution = eloHistory.map(record =&gt; ({&#10;      date: record.date.toISOString().split('T')[0],&#10;      rating: record.rating,&#10;      surfaceElo: record.surfaceElo,&#10;      surface: record.surface,&#10;      matches: record.matches,&#10;      playerName: record.player.name&#10;    }));&#10;&#10;    return NextResponse.json({&#10;      success: true,&#10;      evolution,&#10;      total: evolution.length,&#10;      player: eloHistory[0]?.player || null&#10;    });&#10;&#10;  } catch (error) {&#10;    console.error('Error fetching ELO evolution:', error);&#10;    &#10;    if (error instanceof z.ZodError) {&#10;      return NextResponse.json(&#10;        { error: 'Parámetros inválidos', details: error.errors },&#10;        { status: 400 }&#10;      );&#10;    }&#10;&#10;    return NextResponse.json(&#10;      { error: 'Error interno del servidor' },&#10;      { status: 500 }&#10;    );&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/components/ui/button.tsx">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/components/ui/button.tsx" />
              <option name="updatedContent" value="import { type VariantProps, cva } from &quot;class-variance-authority&quot;&#10;import * as React from &quot;react&quot;&#10;&#10;import { cn } from &quot;@/lib/utils&quot;&#10;&#10;const buttonVariants = cva(&#10;  &quot;inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50&quot;,&#10;  {&#10;    variants: {&#10;      variant: {&#10;        default: &quot;bg-primary text-primary-foreground hover:bg-primary/90&quot;,&#10;        destructive:&#10;          &quot;bg-destructive text-destructive-foreground hover:bg-destructive/90&quot;,&#10;        outline:&#10;          &quot;border border-input bg-background hover:bg-accent hover:text-accent-foreground&quot;,&#10;        secondary:&#10;          &quot;bg-secondary text-secondary-foreground hover:bg-secondary/80&quot;,&#10;        ghost: &quot;hover:bg-accent hover:text-accent-foreground&quot;,&#10;        link: &quot;text-primary underline-offset-4 hover:underline&quot;,&#10;      },&#10;      size: {&#10;        default: &quot;h-10 px-4 py-2&quot;,&#10;        sm: &quot;h-9 rounded-md px-3&quot;,&#10;        lg: &quot;h-11 rounded-md px-8&quot;,&#10;        icon: &quot;h-10 w-10&quot;,&#10;      },&#10;    },&#10;    defaultVariants: {&#10;      variant: &quot;default&quot;,&#10;      size: &quot;default&quot;,&#10;    },&#10;  }&#10;)&#10;&#10;export interface ButtonProps&#10;  extends React.ButtonHTMLAttributes&lt;HTMLButtonElement&gt;,&#10;    VariantProps&lt;typeof buttonVariants&gt; {&#10;  asChild?: boolean&#10;}&#10;&#10;const Button = React.forwardRef&lt;HTMLButtonElement, ButtonProps&gt;(&#10;  ({ className, variant, size, asChild = false, ...props }, ref) =&gt; {&#10;    return (&#10;      &lt;button&#10;        className={cn(buttonVariants({ variant, size, className }))}&#10;        ref={ref}&#10;        {...props}&#10;      /&gt;&#10;    )&#10;  }&#10;)&#10;Button.displayName = &quot;Button&quot;&#10;&#10;export { Button, buttonVariants }" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/components/ui/card.tsx">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/components/ui/card.tsx" />
              <option name="updatedContent" value="import * as React from &quot;react&quot;&#10;&#10;import { cn } from &quot;@/lib/utils&quot;&#10;&#10;const Card = React.forwardRef&lt;&#10;  HTMLDivElement,&#10;  React.HTMLAttributes&lt;HTMLDivElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;div&#10;    ref={ref}&#10;    className={cn(&#10;      &quot;rounded-lg border bg-card text-card-foreground shadow-sm&quot;,&#10;      className&#10;    )}&#10;    {...props}&#10;  /&gt;&#10;))&#10;Card.displayName = &quot;Card&quot;&#10;&#10;const CardHeader = React.forwardRef&lt;&#10;  HTMLDivElement,&#10;  React.HTMLAttributes&lt;HTMLDivElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;div ref={ref} className={cn(&quot;flex flex-col space-y-1.5 p-6&quot;, className)} {...props} /&gt;&#10;))&#10;CardHeader.displayName = &quot;CardHeader&quot;&#10;&#10;const CardTitle = React.forwardRef&lt;&#10;  HTMLParagraphElement,&#10;  React.HTMLAttributes&lt;HTMLHeadingElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;h3&#10;    ref={ref}&#10;    className={cn(&#10;      &quot;text-2xl font-semibold leading-none tracking-tight&quot;,&#10;      className&#10;    )}&#10;    {...props}&#10;  /&gt;&#10;))&#10;CardTitle.displayName = &quot;CardTitle&quot;&#10;&#10;const CardDescription = React.forwardRef&lt;&#10;  HTMLParagraphElement,&#10;  React.HTMLAttributes&lt;HTMLParagraphElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;p&#10;    ref={ref}&#10;    className={cn(&quot;text-sm text-muted-foreground&quot;, className)}&#10;    {...props}&#10;  /&gt;&#10;))&#10;CardDescription.displayName = &quot;CardDescription&quot;&#10;&#10;const CardContent = React.forwardRef&lt;&#10;  HTMLDivElement,&#10;  React.HTMLAttributes&lt;HTMLDivElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;div ref={ref} className={cn(&quot;p-6 pt-0&quot;, className)} {...props} /&gt;&#10;))&#10;CardContent.displayName = &quot;CardContent&quot;&#10;&#10;const CardFooter = React.forwardRef&lt;&#10;  HTMLDivElement,&#10;  React.HTMLAttributes&lt;HTMLDivElement&gt;&#10;&gt;(({ className, ...props }, ref) =&gt; (&#10;  &lt;div ref={ref} className={cn(&quot;flex items-center p-6 pt-0&quot;, className)} {...props} /&gt;&#10;))&#10;CardFooter.displayName = &quot;CardFooter&quot;&#10;&#10;export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/lib/db.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/lib/db.ts" />
              <option name="updatedContent" value="import { PrismaClient } from '@prisma/client'&#10;&#10;const globalForPrisma = globalThis as unknown as {&#10;  prisma: PrismaClient | undefined&#10;}&#10;&#10;export const db =&#10;  globalForPrisma.prisma ??&#10;  new PrismaClient({&#10;    log: ['query'],&#10;  })&#10;&#10;if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = db" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/lib/player-service.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/lib/player-service.ts" />
              <option name="updatedContent" value="import { db } from '@/lib/db';&#10;import { PlayerStats, PlayerProfile, H2HRecord, Surface, MatchData } from '@/types/tennis';&#10;import { PredictionEngine } from './prediction-engine';&#10;&#10;/**&#10; * Servicio de datos de jugadores&#10; * Migra la funcionalidad de calculate_player_basic_stats desde Python&#10; */&#10;export class PlayerService {&#10;  /**&#10;   * Obtiene estadísticas básicas de un jugador&#10;   * Migrado desde tu función calculate_player_basic_stats&#10;   */&#10;  static async getPlayerStats(playerId: string): Promise&lt;PlayerStats | null&gt; {&#10;    const player = await db.player.findUnique({&#10;      where: { id: playerId },&#10;      include: {&#10;        player1Matches: {&#10;          include: {&#10;            player2: true,&#10;            winner: true,&#10;            tournament: true&#10;          },&#10;          orderBy: { date: 'desc' },&#10;          take: 50&#10;        },&#10;        player2Matches: {&#10;          include: {&#10;            player1: true,&#10;            winner: true,&#10;            tournament: true&#10;          },&#10;          orderBy: { date: 'desc' },&#10;          take: 50&#10;        },&#10;        eloHistories: {&#10;          orderBy: { date: 'desc' },&#10;          take: 1&#10;        }&#10;      }&#10;    });&#10;&#10;    if (!player) return null;&#10;&#10;    // Combinar todos los partidos&#10;    const allMatches = [&#10;      ...player.player1Matches.map(m =&gt; ({ ...m, playerPosition: 1 as const })),&#10;      ...player.player2Matches.map(m =&gt; ({ ...m, playerPosition: 2 as const }))&#10;    ].sort((a, b) =&gt; b.date.getTime() - a.date.getTime());&#10;&#10;    const matchesPlayed = allMatches.length;&#10;    const wins = allMatches.filter(match =&gt; match.winnerId === playerId).length;&#10;    const winRate = matchesPlayed &gt; 0 ? wins / matchesPlayed : 0;&#10;&#10;    // ELO rating actual&#10;    const currentElo = player.eloHistories[0]?.rating || 1500;&#10;&#10;    // Último partido&#10;    const lastMatch = allMatches[0]?.date?.toISOString().split('T')[0] || null;&#10;&#10;    // Forma reciente (últimos 10 partidos)&#10;    const recentMatches = allMatches.slice(0, 10);&#10;    const recentWins = recentMatches.filter(match =&gt; match.winnerId === playerId).length;&#10;    const recentForm = recentMatches.length &gt; 0 ? recentWins / recentMatches.length : 0;&#10;&#10;    return {&#10;      id: player.id,&#10;      name: player.name,&#10;      matchesPlayed,&#10;      winRate,&#10;      eloRating: currentElo,&#10;      lastMatch,&#10;      recentForm,&#10;      country: player.country || undefined&#10;    };&#10;  }&#10;&#10;  /**&#10;   * Obtiene el perfil completo de un jugador&#10;   */&#10;  static async getPlayerProfile(playerId: string): Promise&lt;PlayerProfile | null&gt; {&#10;    const player = await db.player.findUnique({&#10;      where: { id: playerId },&#10;      include: {&#10;        player1Matches: {&#10;          include: {&#10;            player2: true,&#10;            winner: true,&#10;            tournament: true&#10;          },&#10;          orderBy: { date: 'desc' }&#10;        },&#10;        player2Matches: {&#10;          include: {&#10;            player1: true,&#10;            winner: true,&#10;            tournament: true&#10;          },&#10;          orderBy: { date: 'desc' }&#10;        },&#10;        eloHistories: {&#10;          orderBy: { date: 'asc' }&#10;        }&#10;      }&#10;    });&#10;&#10;    if (!player) return null;&#10;&#10;    // Combinar partidos&#10;    const allMatches = [&#10;      ...player.player1Matches.map(m =&gt; ({ ...m, playerPosition: 1 as const })),&#10;      ...player.player2Matches.map(m =&gt; ({ ...m, playerPosition: 2 as const }))&#10;    ].sort((a, b) =&gt; b.date.getTime() - a.date.getTime());&#10;&#10;    const wins = allMatches.filter(m =&gt; m.winnerId === playerId).length;&#10;    const losses = allMatches.length - wins;&#10;&#10;    // Estadísticas por superficie&#10;    const surfaceStats = {&#10;      [Surface.HARD]: { matches: 0, wins: 0, winPercentage: 0 },&#10;      [Surface.CLAY]: { matches: 0, wins: 0, winPercentage: 0 },&#10;      [Surface.GRASS]: { matches: 0, wins: 0, winPercentage: 0 },&#10;      [Surface.CARPET]: { matches: 0, wins: 0, winPercentage: 0 }&#10;    };&#10;&#10;    allMatches.forEach(match =&gt; {&#10;      const surface = match.surface;&#10;      surfaceStats[surface].matches++;&#10;      if (match.winnerId === playerId) {&#10;        surfaceStats[surface].wins++;&#10;      }&#10;    });&#10;&#10;    // Calcular porcentajes&#10;    Object.keys(surfaceStats).forEach(surface =&gt; {&#10;      const stats = surfaceStats[surface as Surface];&#10;      stats.winPercentage = stats.matches &gt; 0 ? stats.wins / stats.matches : 0;&#10;    });&#10;&#10;    return {&#10;      id: player.id,&#10;      name: player.name,&#10;      country: player.country || undefined,&#10;      birthDate: player.birthDate || undefined,&#10;      height: player.height || undefined,&#10;      hand: player.hand as 'R' | 'L' || undefined,&#10;      backhand: player.backhand as '1' | '2' || undefined,&#10;      currentElo: player.eloHistories[player.eloHistories.length - 1]?.rating || 1500,&#10;      careerStats: {&#10;        totalMatches: allMatches.length,&#10;        wins,&#10;        losses,&#10;        winPercentage: allMatches.length &gt; 0 ? wins / allMatches.length : 0,&#10;        titlesWon: 0 // TODO: Calcular desde torneos ganados&#10;      },&#10;      surfaceStats,&#10;      recentMatches: allMatches.slice(0, 20).map(this.convertToMatchData),&#10;      eloHistory: player.eloHistories.map(h =&gt; ({&#10;        date: h.date,&#10;        rating: h.rating,&#10;        surface: h.surface || undefined,&#10;        matches: h.matches&#10;      }))&#10;    };&#10;  }&#10;&#10;  /**&#10;   * Busca jugadores por nombre&#10;   * Migrado desde tu funcionalidad de load_player_database&#10;   */&#10;  static async searchPlayers(query: string, limit: number = 20): Promise&lt;PlayerStats[]&gt; {&#10;    const players = await db.player.findMany({&#10;      where: {&#10;        name: {&#10;          contains: query,&#10;          mode: 'insensitive'&#10;        }&#10;      },&#10;      take: limit,&#10;      include: {&#10;        eloHistories: {&#10;          orderBy: { date: 'desc' },&#10;          take: 1&#10;        }&#10;      }&#10;    });&#10;&#10;    const playerStats = await Promise.all(&#10;      players.map(async (player) =&gt; {&#10;        const stats = await this.getPlayerStats(player.id);&#10;        return stats!;&#10;      })&#10;    );&#10;&#10;    return playerStats.filter(Boolean);&#10;  }&#10;&#10;  /**&#10;   * Obtiene el historial H2H entre dos jugadores&#10;   */&#10;  static async getH2HRecord(player1Id: string, player2Id: string): Promise&lt;H2HRecord&gt; {&#10;    const matches = await db.match.findMany({&#10;      where: {&#10;        OR: [&#10;          { player1Id: player1Id, player2Id: player2Id },&#10;          { player1Id: player2Id, player2Id: player1Id }&#10;        ]&#10;      },&#10;      include: {&#10;        winner: true,&#10;        tournament: true&#10;      },&#10;      orderBy: { date: 'desc' }&#10;    });&#10;&#10;    const player1Wins = matches.filter(m =&gt; m.winnerId === player1Id).length;&#10;    const player2Wins = matches.filter(m =&gt; m.winnerId === player2Id).length;&#10;&#10;    // Estadísticas por superficie&#10;    const surfaceRecord: H2HRecord['surfaceRecord'] = {};&#10;    &#10;    Object.values(Surface).forEach(surface =&gt; {&#10;      const surfaceMatches = matches.filter(m =&gt; m.surface === surface);&#10;      if (surfaceMatches.length &gt; 0) {&#10;        surfaceRecord[surface] = {&#10;          matches: surfaceMatches.length,&#10;          player1Wins: surfaceMatches.filter(m =&gt; m.winnerId === player1Id).length,&#10;          player2Wins: surfaceMatches.filter(m =&gt; m.winnerId === player2Id).length&#10;        };&#10;      }&#10;    });&#10;&#10;    return {&#10;      totalMatches: matches.length,&#10;      player1Wins,&#10;      player2Wins,&#10;      lastMeeting: matches[0]?.date || undefined,&#10;      surfaceRecord&#10;    };&#10;  }&#10;&#10;  /**&#10;   * Obtiene todos los jugadores para el dropdown&#10;   */&#10;  static async getAllPlayers(): Promise&lt;{ id: string; name: string; country?: string }[]&gt; {&#10;    return db.player.findMany({&#10;      select: {&#10;        id: true,&#10;        name: true,&#10;        country: true&#10;      },&#10;      orderBy: {&#10;        name: 'asc'&#10;      }&#10;    });&#10;  }&#10;&#10;  /**&#10;   * Convierte un match de DB a MatchData&#10;   */&#10;  private static convertToMatchData(match: any): MatchData {&#10;    return {&#10;      id: match.id,&#10;      date: match.date,&#10;      player1: {&#10;        id: match.player1?.id || match.player1Id,&#10;        name: match.player1?.name || 'Unknown',&#10;        matchesPlayed: 0,&#10;        winRate: 0,&#10;        eloRating: match.p1EloRating || 1500,&#10;        lastMatch: null,&#10;        recentForm: 0&#10;      },&#10;      player2: {&#10;        id: match.player2?.id || match.player2Id,&#10;        name: match.player2?.name || 'Unknown',&#10;        matchesPlayed: 0,&#10;        winRate: 0,&#10;        eloRating: match.p2EloRating || 1500,&#10;        lastMatch: null,&#10;        recentForm: 0&#10;      },&#10;      surface: match.surface,&#10;      winner: match.winner?.name,&#10;      score: match.score || undefined,&#10;      tournament: match.tournament?.name&#10;    };&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/lib/prediction-engine.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/lib/prediction-engine.ts" />
              <option name="updatedContent" value="import { PlayerStats, PredictionResult, PredictionFactors, Surface } from '@/types/tennis';&#10;&#10;/**&#10; * Motor de predicción migrado desde Python (simple_prediction function)&#10; * Calcula la probabilidad de victoria basada en ELO, forma reciente y superficie&#10; */&#10;export class PredictionEngine {&#10;  /**&#10;   * Crea una predicción entre dos jugadores&#10;   * Migrado desde tu función simple_prediction() en app.py&#10;   */&#10;  static predictMatch(&#10;    player1Stats: PlayerStats,&#10;    player2Stats: PlayerStats,&#10;    surface: Surface&#10;  ): PredictionResult {&#10;    // Calcular factores de predicción (misma lógica que tu código Python)&#10;    const factors: PredictionFactors = {&#10;      eloAdvantage: (player1Stats.eloRating - player2Stats.eloRating) / 400,&#10;      formDifference: player1Stats.recentForm - player2Stats.recentForm,&#10;      experienceDifference: (player1Stats.matchesPlayed - player2Stats.matchesPlayed) / 1000,&#10;      surfaceBonus: this.calculateSurfaceBonus(surface)&#10;    };&#10;&#10;    // Probabilidad base usando función logística (igual que Python)&#10;    const probRaw = 1 / (1 + Math.exp(-(&#10;      factors.eloAdvantage + &#10;      factors.formDifference * 0.3 + &#10;      factors.experienceDifference * 0.1 + &#10;      factors.surfaceBonus&#10;    )));&#10;&#10;    // Normalizar para evitar predicciones extremas (0.1 - 0.9)&#10;    const probP1 = Math.max(0.1, Math.min(0.9, probRaw));&#10;    const probP2 = 1 - probP1;&#10;&#10;    const winner = probP1 &gt; 0.5 ? player1Stats.name : player2Stats.name;&#10;    const confidence = Math.max(probP1, probP2);&#10;&#10;    return {&#10;      probabilityP1: probP1,&#10;      probabilityP2: probP2,&#10;      winnerPrediction: winner,&#10;      confidence: confidence,&#10;      factors: factors&#10;    };&#10;  }&#10;&#10;  /**&#10;   * Calcula bonus/malus por superficie&#10;   * Migrado desde tu código Python&#10;   */&#10;  private static calculateSurfaceBonus(surface: Surface): number {&#10;    switch (surface) {&#10;      case Surface.CLAY:&#10;        return 0.02; // Ligero bonus para especialistas&#10;      case Surface.GRASS:&#10;        return -0.02; // Ligero malus por rareza&#10;      case Surface.HARD:&#10;      case Surface.CARPET:&#10;      default:&#10;        return 0;&#10;    }&#10;  }&#10;&#10;  /**&#10;   * Calcula ELO rating actualizado después de un partido&#10;   * Migrado desde tu lógica de compute_elo_ratings&#10;   */&#10;  static updateEloRating(&#10;    currentRating: number,&#10;    opponentRating: number,&#10;    matchResult: number, // 1 for win, 0 for loss&#10;    kFactor: number = 32&#10;  ): number {&#10;    const expectedScore = 1 / (1 + Math.pow(10, (opponentRating - currentRating) / 400));&#10;    return currentRating + kFactor * (matchResult - expectedScore);&#10;  }&#10;&#10;  /**&#10;   * Calcula K-factor adaptativo basado en número de partidos&#10;   * Migrado desde tu función _k_adaptive&#10;   */&#10;  static calculateAdaptiveK(&#10;    matchesPlayed: number,&#10;    kMin: number = 18,&#10;    kMax: number = 32,&#10;    halfLife: number = 50&#10;  ): number {&#10;    return kMin + (kMax - kMin) * Math.exp(-matchesPlayed / halfLife);&#10;  }&#10;&#10;  /**&#10;   * Calcula la forma reciente de un jugador&#10;   * Basado en tu lógica de add_recent_form_and_fatigue&#10;   */&#10;  static calculateRecentForm(recentResults: boolean[], windowSize: number = 5): number {&#10;    if (recentResults.length === 0) return 0;&#10;    &#10;    const relevantResults = recentResults.slice(-windowSize);&#10;    const wins = relevantResults.filter(result =&gt; result).length;&#10;    return wins / relevantResults.length;&#10;  }&#10;&#10;  /**&#10;   * Determina la confianza de una predicción&#10;   */&#10;  static calculateConfidence(probability: number): 'LOW' | 'MEDIUM' | 'HIGH' {&#10;    const confidence = Math.abs(probability - 0.5) * 2;&#10;    &#10;    if (confidence &lt; 0.3) return 'LOW';&#10;    if (confidence &lt; 0.6) return 'MEDIUM';&#10;    return 'HIGH';&#10;  }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/lib/utils.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/lib/utils.ts" />
              <option name="updatedContent" value="import { type ClassValue, clsx } from &quot;clsx&quot;&#10;import { twMerge } from &quot;tailwind-merge&quot;&#10;&#10;export function cn(...inputs: ClassValue[]) {&#10;  return twMerge(clsx(inputs))&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/src/types/tennis.ts">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/src/types/tennis.ts" />
              <option name="updatedContent" value="export interface PlayerStats {&#10;  id: string;&#10;  name: string;&#10;  matchesPlayed: number;&#10;  winRate: number;&#10;  eloRating: number;&#10;  lastMatch: string | null;&#10;  recentForm: number;&#10;  country?: string;&#10;  ranking?: number;&#10;}&#10;&#10;export interface PredictionFactors {&#10;  eloAdvantage: number;&#10;  formDifference: number;&#10;  experienceDifference: number;&#10;  surfaceBonus: number;&#10;}&#10;&#10;export interface PredictionResult {&#10;  probabilityP1: number;&#10;  probabilityP2: number;&#10;  winnerPrediction: string;&#10;  confidence: number;&#10;  factors: PredictionFactors;&#10;}&#10;&#10;export interface MatchData {&#10;  id: string;&#10;  date: Date;&#10;  player1: PlayerStats;&#10;  player2: PlayerStats;&#10;  surface: Surface;&#10;  winner?: string;&#10;  score?: string;&#10;  tournament?: string;&#10;}&#10;&#10;export interface EloHistory {&#10;  date: Date;&#10;  rating: number;&#10;  surface?: Surface;&#10;  matches: number;&#10;}&#10;&#10;export interface H2HRecord {&#10;  totalMatches: number;&#10;  player1Wins: number;&#10;  player2Wins: number;&#10;  lastMeeting?: Date;&#10;  surfaceRecord?: {&#10;    [key in Surface]?: {&#10;      matches: number;&#10;      player1Wins: number;&#10;      player2Wins: number;&#10;    }&#10;  };&#10;}&#10;&#10;export enum Surface {&#10;  HARD = 'HARD',&#10;  CLAY = 'CLAY',&#10;  GRASS = 'GRASS',&#10;  CARPET = 'CARPET'&#10;}&#10;&#10;export interface PlayerProfile {&#10;  id: string;&#10;  name: string;&#10;  country?: string;&#10;  birthDate?: Date;&#10;  height?: number;&#10;  hand?: 'R' | 'L';&#10;  backhand?: '1' | '2';&#10;  currentElo: number;&#10;  currentRanking?: number;&#10;  careerStats: {&#10;    totalMatches: number;&#10;    wins: number;&#10;    losses: number;&#10;    winPercentage: number;&#10;    titlesWon: number;&#10;  };&#10;  surfaceStats: {&#10;    [key in Surface]: {&#10;      matches: number;&#10;      wins: number;&#10;      winPercentage: number;&#10;    }&#10;  };&#10;  recentMatches: MatchData[];&#10;  eloHistory: EloHistory[];&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/tailwind.config.js">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/tailwind.config.js" />
              <option name="updatedContent" value="/** @type {import('tailwindcss').Config} */&#10;module.exports = {&#10;  darkMode: [&quot;class&quot;],&#10;  content: [&#10;    './pages/**/*.{ts,tsx}',&#10;    './components/**/*.{ts,tsx}',&#10;    './app/**/*.{ts,tsx}',&#10;    './src/**/*.{ts,tsx}',&#10;  ],&#10;  theme: {&#10;    container: {&#10;      center: true,&#10;      padding: &quot;2rem&quot;,&#10;      screens: {&#10;        &quot;2xl&quot;: &quot;1400px&quot;,&#10;      },&#10;    },&#10;    extend: {&#10;      colors: {&#10;        border: &quot;hsl(var(--border))&quot;,&#10;        input: &quot;hsl(var(--input))&quot;,&#10;        ring: &quot;hsl(var(--ring))&quot;,&#10;        background: &quot;hsl(var(--background))&quot;,&#10;        foreground: &quot;hsl(var(--foreground))&quot;,&#10;        primary: {&#10;          DEFAULT: &quot;hsl(var(--primary))&quot;,&#10;          foreground: &quot;hsl(var(--foreground))&quot;,&#10;        },&#10;        secondary: {&#10;          DEFAULT: &quot;hsl(var(--secondary))&quot;,&#10;          foreground: &quot;hsl(var(--secondary-foreground))&quot;,&#10;        },&#10;        destructive: {&#10;          DEFAULT: &quot;hsl(var(--destructive))&quot;,&#10;          foreground: &quot;hsl(var(--destructive-foreground))&quot;,&#10;        },&#10;        muted: {&#10;          DEFAULT: &quot;hsl(var(--muted))&quot;,&#10;          foreground: &quot;hsl(var(--muted-foreground))&quot;,&#10;        },&#10;        accent: {&#10;          DEFAULT: &quot;hsl(var(--accent))&quot;,&#10;          foreground: &quot;hsl(var(--accent-foreground))&quot;,&#10;        },&#10;        popover: {&#10;          DEFAULT: &quot;hsl(var(--popover))&quot;,&#10;          foreground: &quot;hsl(var(--popover-foreground))&quot;,&#10;        },&#10;        card: {&#10;          DEFAULT: &quot;hsl(var(--card))&quot;,&#10;          foreground: &quot;hsl(var(--card-foreground))&quot;,&#10;        },&#10;        // Tennis-specific colors&#10;        tennis: {&#10;          clay: '#D2691E',&#10;          grass: '#228B22',&#10;          hard: '#4169E1',&#10;          carpet: '#8B4513'&#10;        }&#10;      },&#10;      borderRadius: {&#10;        lg: &quot;var(--radius)&quot;,&#10;        md: &quot;calc(var(--radius) - 2px)&quot;,&#10;        sm: &quot;calc(var(--radius) - 4px)&quot;,&#10;      },&#10;      keyframes: {&#10;        &quot;accordion-down&quot;: {&#10;          from: { height: 0 },&#10;          to: { height: &quot;var(--radix-accordion-content-height)&quot; },&#10;        },&#10;        &quot;accordion-up&quot;: {&#10;          from: { height: &quot;var(--radix-accordion-content-height)&quot; },&#10;          to: { height: 0 },&#10;        },&#10;      },&#10;      animation: {&#10;        &quot;accordion-down&quot;: &quot;accordion-down 0.2s ease-out&quot;,&#10;        &quot;accordion-up&quot;: &quot;accordion-up 0.2s ease-out&quot;,&#10;      },&#10;    },&#10;  },&#10;  plugins: [require(&quot;tailwindcss-animate&quot;)],&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../TennisPredictor/tsconfig.json">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../TennisPredictor/tsconfig.json" />
              <option name="updatedContent" value="{&#10;  &quot;compilerOptions&quot;: {&#10;    &quot;lib&quot;: [&quot;dom&quot;, &quot;dom.iterable&quot;, &quot;es6&quot;],&#10;    &quot;allowJs&quot;: true,&#10;    &quot;skipLibCheck&quot;: true,&#10;    &quot;strict&quot;: true,&#10;    &quot;noEmit&quot;: true,&#10;    &quot;esModuleInterop&quot;: true,&#10;    &quot;module&quot;: &quot;esnext&quot;,&#10;    &quot;moduleResolution&quot;: &quot;bundler&quot;,&#10;    &quot;resolveJsonModule&quot;: true,&#10;    &quot;isolatedModules&quot;: true,&#10;    &quot;jsx&quot;: &quot;preserve&quot;,&#10;    &quot;incremental&quot;: true,&#10;    &quot;plugins&quot;: [&#10;      {&#10;        &quot;name&quot;: &quot;next&quot;&#10;      }&#10;    ],&#10;    &quot;paths&quot;: {&#10;      &quot;@/*&quot;: [&quot;./src/*&quot;],&#10;      &quot;@/components/*&quot;: [&quot;./src/components/*&quot;],&#10;      &quot;@/lib/*&quot;: [&quot;./src/lib/*&quot;],&#10;      &quot;@/utils/*&quot;: [&quot;./src/utils/*&quot;],&#10;      &quot;@/types/*&quot;: [&quot;./src/types/*&quot;]&#10;    }&#10;  },&#10;  &quot;include&quot;: [&quot;next-env.d.ts&quot;, &quot;**/*.ts&quot;, &quot;**/*.tsx&quot;, &quot;.next/types/**/*.ts&quot;],&#10;  &quot;exclude&quot;: [&quot;node_modules&quot;]&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$USER_HOME$/PytharmProjects/PythonProject/generate_player_features.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$USER_HOME$/PytharmProjects/PythonProject/generate_player_features.py" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Script para generar un archivo con las features más recientes de cada jugador&#10;Se ejecuta desde el notebook o como script independiente&#10;&quot;&quot;&quot;&#10;import pandas as pd&#10;import numpy as np&#10;import pickle&#10;from pathlib import Path&#10;from datetime import datetime&#10;from src.features import add_all_features&#10;import logging&#10;&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;def generate_player_features_file():&#10;    &quot;&quot;&quot;&#10;    Generar archivo con features actuales de todos los jugadores&#10;    &quot;&quot;&quot;&#10;    # Paths&#10;    BASE_DIR = Path(__file__).parent&#10;    DATA_DIR = BASE_DIR / 'data' / 'processed'&#10;    OUTPUTS_DIR = BASE_DIR / 'outputs'&#10;    &#10;    # Cargar datos históricos más recientes&#10;    train_path = DATA_DIR / 'train_full.csv'&#10;    test_path = DATA_DIR / 'test_full.csv'&#10;    &#10;    if not train_path.exists() or not test_path.exists():&#10;        raise FileNotFoundError(&quot;No se encontraron los datos procesados. Ejecuta el notebook primero.&quot;)&#10;    &#10;    logger.info(&quot;Cargando datos históricos...&quot;)&#10;    train_df = pd.read_csv(train_path, low_memory=False)&#10;    test_df = pd.read_csv(test_path, low_memory=False)&#10;    &#10;    # Combinar datos&#10;    full_df = pd.concat([train_df, test_df], ignore_index=True)&#10;    &#10;    # Convertir fechas&#10;    if 'tourney_date' in full_df.columns:&#10;        full_df['tourney_date'] = pd.to_datetime(full_df['tourney_date'], errors='coerce')&#10;        full_df = full_df.dropna(subset=['tourney_date'])&#10;        full_df = full_df.sort_values('tourney_date').reset_index(drop=True)&#10;    &#10;    logger.info(f&quot;Datos cargados: {len(full_df):,} partidos&quot;)&#10;    &#10;    # Cargar estados de entrenamiento para usar los mismos parámetros&#10;    training_states_path = OUTPUTS_DIR / 'training_states.pkl'&#10;    if training_states_path.exists():&#10;        logger.info(&quot;Cargando estados de entrenamiento...&quot;)&#10;        with open(training_states_path, 'rb') as f:&#10;            training_states = pickle.load(f)&#10;    else:&#10;        raise FileNotFoundError(&quot;No se encontraron estados de entrenamiento. Ejecuta el notebook primero.&quot;)&#10;    &#10;    # Cargar feature_columns y otros estados necesarios&#10;    feature_columns = training_states.get(&quot;feature_columns&quot;, [])&#10;    if not feature_columns:&#10;        raise ValueError(&quot;No se encontraron feature_columns en training_states&quot;)&#10;    &#10;    # Generar features completas usando el pipeline existente&#10;    logger.info(&quot;Generando features completas...&quot;)&#10;    try:&#10;        outputs = add_all_features(&#10;            full_df,&#10;            initial_global_elos=training_states.get(&quot;final_global_elos&quot;),&#10;            initial_surface_elos=training_states.get(&quot;final_surface_elos&quot;),&#10;            initial_h2h=training_states.get(&quot;final_h2h&quot;),&#10;            initial_stats=training_states.get(&quot;final_stats&quot;),&#10;            mode=&quot;inference&quot;,  # Usar modo inference para usar estados existentes&#10;            fast=False,        # No usar modo rápido para tener features completas&#10;            pca_state=training_states.get(&quot;pca_state&quot;),&#10;            randomize_players=False,&#10;            return_full=True,&#10;            return_pca_state=False&#10;        )&#10;        &#10;        df_with_features = outputs[0]  # DataFrame final con features&#10;        df_full_features = outputs[1]  # DataFrame antes de PCA&#10;        &#10;        logger.info(f&quot;Features generadas: {df_with_features.shape}&quot;)&#10;        &#10;    except Exception as e:&#10;        logger.error(f&quot;Error generando features: {e}&quot;)&#10;        raise&#10;    &#10;    # Cargar lista de jugadores&#10;    players_list_path = OUTPUTS_DIR / 'players_list.pkl'&#10;    if players_list_path.exists():&#10;        with open(players_list_path, 'rb') as f:&#10;            players_list = pickle.load(f)&#10;    else:&#10;        # Extraer jugadores únicos si no existe el archivo&#10;        all_players = set()&#10;        for df in [train_df, test_df]:&#10;            if 'player_1' in df.columns:&#10;                all_players.update(df['player_1'].dropna().unique())&#10;            if 'player_2' in df.columns:&#10;                all_players.update(df['player_2'].dropna().unique())&#10;            if 'winner_name' in df.columns:&#10;                all_players.update(df['winner_name'].dropna().unique())&#10;            if 'loser_name' in df.columns:&#10;                all_players.update(df['loser_name'].dropna().unique())&#10;        players_list = sorted(list(all_players))&#10;    &#10;    # Extraer jugadores únicos con sus features más recientes&#10;    logger.info(&quot;Extrayendo features por jugador...&quot;)&#10;    player_features = extract_latest_player_features(&#10;        df_with_features, df_full_features, feature_columns, players_list&#10;    )&#10;    &#10;    # Guardar archivo de features de jugadores&#10;    output_path = OUTPUTS_DIR / 'player_features.pkl'&#10;    logger.info(f&quot;Guardando features de jugadores en {output_path}...&quot;)&#10;    &#10;    with open(output_path, 'wb') as f:&#10;        pickle.dump(player_features, f)&#10;    &#10;    # Guardar también en CSV para inspección&#10;    csv_path = OUTPUTS_DIR / 'player_features.csv'&#10;    logger.info(f&quot;Guardando CSV de inspección en {csv_path}...&quot;)&#10;    &#10;    # Convertir a DataFrame para CSV&#10;    player_df_list = []&#10;    for player, features_dict in player_features.items():&#10;        row = {'player_name': player}&#10;        row.update(features_dict['model_features'])&#10;        row.update({&#10;            'last_match_date': features_dict['metadata']['last_match_date'],&#10;            'total_matches': features_dict['metadata']['total_matches'],&#10;            'global_elo': features_dict['metadata']['global_elo'],&#10;            'surface_elos': str(features_dict['metadata']['surface_elos'])&#10;        })&#10;        player_df_list.append(row)&#10;    &#10;    player_df = pd.DataFrame(player_df_list)&#10;    player_df.to_csv(csv_path, index=False)&#10;    &#10;    logger.info(f&quot;✅ Proceso completado!&quot;)&#10;    logger.info(f&quot; Jugadores procesados: {len(player_features)}&quot;)&#10;    logger.info(f&quot; Archivo principal: {output_path}&quot;)&#10;    logger.info(f&quot; Archivo CSV: {csv_path}&quot;)&#10;    &#10;    return player_features&#10;&#10;def extract_latest_player_features(df_model, df_full, features_list, players_list):&#10;    &quot;&quot;&quot;&#10;    Extraer las features más recientes para cada jugador único&#10;    &quot;&quot;&quot;&#10;    player_features = {}&#10;    &#10;    # Asegurar que hay una columna de orden temporal&#10;    if 'tourney_date' not in df_full.columns:&#10;        # Usar índice como proxy de orden temporal&#10;        df_full['temp_order'] = df_full.index&#10;        sort_col = 'temp_order'&#10;    else:&#10;        sort_col = 'tourney_date'&#10;    &#10;    logger.info(f&quot;Procesando {len(players_list)} jugadores únicos...&quot;)&#10;    &#10;    for i, player in enumerate(players_list):&#10;        if i % 500 == 0:&#10;            logger.info(f&quot;Procesado {i}/{len(players_list)} jugadores...&quot;)&#10;        &#10;        # Buscar las filas más recientes donde aparece el jugador&#10;        player_rows = []&#10;        &#10;        # Como player_1&#10;        if 'player_1' in df_full.columns:&#10;            mask = df_full['player_1'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(df_full[mask].index.tolist())&#10;        &#10;        # Como player_2&#10;        if 'player_2' in df_full.columns:&#10;            mask = df_full['player_2'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(df_full[mask].index.tolist())&#10;        &#10;        # Como winner_name&#10;        if 'winner_name' in df_full.columns:&#10;            mask = df_full['winner_name'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(df_full[mask].index.tolist())&#10;        &#10;        # Como loser_name&#10;        if 'loser_name' in df_full.columns:&#10;            mask = df_full['loser_name'].fillna('').str.contains(str(player), case=False, na=False)&#10;            player_rows.extend(df_full[mask].index.tolist())&#10;        &#10;        if not player_rows:&#10;            # Jugador no encontrado, usar features neutras&#10;            model_features = {col: 0.0 for col in features_list}&#10;            metadata = {&#10;                'last_match_date': None,&#10;                'total_matches': 0,&#10;                'global_elo': 1500,&#10;                'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500}&#10;            }&#10;        else:&#10;            # Obtener la fila más reciente&#10;            latest_idx = max(player_rows)&#10;            &#10;            # Extraer features del modelo (df_model)&#10;            if latest_idx &lt; len(df_model):&#10;                model_row = df_model.iloc[latest_idx]&#10;                &#10;                # Extraer solo las features que usa el modelo&#10;                model_features = {}&#10;                for feature in features_list:&#10;                    if feature in model_row:&#10;                        value = model_row[feature]&#10;                        try:&#10;                            if pd.notna(value) and np.isfinite(float(value)):&#10;                                model_features[feature] = float(value)&#10;                            else:&#10;                                model_features[feature] = 0.0&#10;                        except (ValueError, TypeError):&#10;                            model_features[feature] = 0.0&#10;                    else:&#10;                        model_features[feature] = 0.0&#10;            else:&#10;                # Fallback: features en cero&#10;                model_features = {col: 0.0 for col in features_list}&#10;            &#10;            # Metadata adicional del df_full&#10;            if latest_idx &lt; len(df_full):&#10;                full_row = df_full.iloc[latest_idx]&#10;                metadata = {&#10;                    'last_match_date': str(full_row.get('tourney_date', '')),&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': full_row.get('elo_p1', 1500) if 'elo_p1' in full_row else 1500,&#10;                    'surface_elos': {&#10;                        'hard': full_row.get('hard_elo_p1', 1500) if 'hard_elo_p1' in full_row else 1500,&#10;                        'clay': full_row.get('clay_elo_p1', 1500) if 'clay_elo_p1' in full_row else 1500,&#10;                        'grass': full_row.get('grass_elo_p1', 1500) if 'grass_elo_p1' in full_row else 1500,&#10;                    }&#10;                }&#10;            else:&#10;                metadata = {&#10;                    'last_match_date': None,&#10;                    'total_matches': len(player_rows),&#10;                    'global_elo': 1500,&#10;                    'surface_elos': {'hard': 1500, 'clay': 1500, 'grass': 1500}&#10;                }&#10;        &#10;        player_features[player] = {&#10;            'model_features': model_features,&#10;            'metadata': metadata&#10;        }&#10;    &#10;    return player_features&#10;&#10;if __name__ == '__main__':&#10;    try:&#10;        player_features = generate_player_features_file()&#10;        print(f&quot;✅ Features generadas para {len(player_features)} jugadores&quot;)&#10;    except Exception as e:&#10;        print(f&quot;❌ Error: {e}&quot;)&#10;        exit(1)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>