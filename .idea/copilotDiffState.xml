<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/notebooks/predict_tournament.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/notebooks/predict_tournament.ipynb" />
              <option name="originalContent" value="#%%&#10;" />
              <option name="updatedContent" value="{&#10; &quot;cells&quot;: [&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;# Predicción de Partidos del Australian Open 2025&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;Este notebook carga los datos de un torneo específico (en este caso, el Australian Open 2025), genera las features necesarias y utiliza el modelo entrenado para predecir los resultados.&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;import pandas as pd\n&quot;,&#10;    &quot;import numpy as np\n&quot;,&#10;    &quot;import joblib\n&quot;,&#10;    &quot;import json\n&quot;,&#10;    &quot;import sys\n&quot;,&#10;    &quot;import os\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Añadir el directorio src al path para poder importar los módulos\n&quot;,&#10;    &quot;sys.path.append(os.path.abspath('../src'))\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;from preprocess import preprocess_data\n&quot;,&#10;    &quot;from features import (create_elo_features, create_ranking_features, \n&quot;,&#10;    &quot;                      create_head_to_head_features, create_time_features, \n&quot;,&#10;    &quot;                      create_fatigue_features, create_recent_form_features)\n&quot;,&#10;    &quot;from utils import load_config&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 1. Cargar Datos del Torneo&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;tournament_df = pd.read_csv('../data/raw/test/atp_matches_2025.csv')&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 2. Cargar Datos Procesados (ELOs)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;with open('../data/processed/final_global_elos.json', 'r') as f:\n&quot;,&#10;    &quot;    global_elos = json.load(f)\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;with open('../data/processed/final_surface_elos.json', 'r') as f:\n&quot;,&#10;    &quot;    surface_elos = json.load(f)&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 3. Preprocesamiento y Generación de Features&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;# Cargar configuración\n&quot;,&#10;    &quot;config = load_config('../src/config.yml')\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Preprocesar datos\n&quot;,&#10;    &quot;data = preprocess_data(tournament_df, config['preprocessing'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Generar Features\n&quot;,&#10;    &quot;data = create_elo_features(data, global_elos, surface_elos)\n&quot;,&#10;    &quot;data = create_ranking_features(data)\n&quot;,&#10;    &quot;data = create_time_features(data)\n&quot;,&#10;    &quot;data = create_head_to_head_features(data)\n&quot;,&#10;    &quot;data = create_fatigue_features(data, config['feature_engineering']['fatigue'])\n&quot;,&#10;    &quot;data = create_recent_form_features(data, config['feature_engineering']['form'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Seleccionar solo las columnas de features\n&quot;,&#10;    &quot;features_df = data[config['model']['features']]\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;print(\&quot;Features generadas exitosamente.\&quot;)\n&quot;,&#10;    &quot;features_df.head()&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 4. Cargar Modelo y Realizar Predicciones&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;# Cargar el modelo entrenado\n&quot;,&#10;    &quot;model = joblib.load('../outputs/models/atp_tennis_predictor.joblib')\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Realizar predicciones\n&quot;,&#10;    &quot;predictions = model.predict(features_df)\n&quot;,&#10;    &quot;prediction_probs = model.predict_proba(features_df)[:, 1] # Probabilidad de que gane el jugador 1&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;markdown&quot;,&#10;   &quot;metadata&quot;: {},&#10;   &quot;source&quot;: [&#10;    &quot;## 5. Comparar Resultados&quot;&#10;   ]&#10;  },&#10;  {&#10;   &quot;cell_type&quot;: &quot;code&quot;,&#10;   &quot;execution_count&quot;: null,&#10;   &quot;metadata&quot;: {},&#10;   &quot;outputs&quot;: [],&#10;   &quot;source&quot;: [&#10;    &quot;results_df = data[['player_1', 'player_2', 'winner']].copy()\n&quot;,&#10;    &quot;results_df['predicted_winner_code'] = predictions\n&quot;,&#10;    &quot;results_df['p1_win_probability'] = prediction_probs\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Mapear códigos a nombres de jugadores\n&quot;,&#10;    &quot;results_df['predicted_winner'] = np.where(results_df['predicted_winner_code'] == 1, results_df['player_1'], results_df['player_2'])\n&quot;,&#10;    &quot;results_df['actual_winner'] = np.where(results_df['winner'] == 1, results_df['player_1'], results_df['player_2'])\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;# Mostrar resultados\n&quot;,&#10;    &quot;comparison_df = results_df[['player_1', 'player_2', 'actual_winner', 'predicted_winner', 'p1_win_probability']]\n&quot;,&#10;    &quot;\n&quot;,&#10;    &quot;print(\&quot;Tabla de Comparación de Resultados:\&quot;)\n&quot;,&#10;    &quot;comparison_df&quot;&#10;   ]&#10;  }&#10; ],&#10; &quot;metadata&quot;: {&#10;  &quot;kernelspec&quot;: {&#10;   &quot;display_name&quot;: &quot;Python 3&quot;,&#10;   &quot;language&quot;: &quot;python&quot;,&#10;   &quot;name&quot;: &quot;python3&quot;&#10;  },&#10;  &quot;language_info&quot;: {&#10;   &quot;codemirror_mode&quot;: {&#10;    &quot;name&quot;: &quot;ipython&quot;,&#10;    &quot;version&quot;: 3&#10;   },&#10;   &quot;file_extension&quot;: &quot;.py&quot;,&#10;   &quot;mimetype&quot;: &quot;text/x-python&quot;,&#10;   &quot;name&quot;: &quot;python&quot;,&#10;   &quot;nbconvert_exporter&quot;: &quot;python&quot;,&#10;   &quot;pygments_lexer&quot;: &quot;ipython3&quot;,&#10;   &quot;version&quot;: &quot;3.11.0&quot;&#10;  }&#10; },&#10; &quot;nbformat&quot;: 4,&#10; &quot;nbformat_minor&quot;: 4&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/notebooks/tennis_predictor.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/notebooks/tennis_predictor.ipynb" />
              <option name="originalContent" value="#%% md&#10;#### Tennis_match_predictor.ipynb&#10;Este notebook presenta un análisis exhaustivo de predicción de partidos de tenis profesional usando técnicas avanzadas de machine learning y feature engineering.&#10;&#10;objetivos:&#10; - desarrollar un modelo predictivo de alta precisión para partidos de tenis&#10; - analizar la evolución histórica de jugadores top&#10; - identificar los factores más determinantes en la victoria&#10; - comparar diferentes algoritmos de machine learning&#10;&#10;atos: 55+ años de historia del tenis profesional (1968-2024)&#10;&#10;#%%&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import numpy as np&#10;from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score&#10;from sklearn.model_selection import GridSearchCV, train_test_split&#10;from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.neighbors import KNeighborsClassifier&#10;from sklearn.naive_bayes import GaussianNB&#10;from xgboost import XGBClassifier&#10;import warnings&#10;import os&#10;import sys&#10;BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))&#10;sys.path.append(os.path.join(BASE_DIR, 'src'))&#10;from utils import make_dual_rows, fillna_features, print_feature_availability&#10;&#10;# configuración&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;sns.set_palette(&quot;husl&quot;)&#10;&#10;print(&quot;iniciando análisis del Tennis Match Predictor...&quot;)&#10;&#10;#%% md&#10;## 1.  Carga y Exploración de Datos&#10;&#10;#%%&#10;# carga y procesar datos&#10;from data_loader import load_train_data, load_test_data&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;print(&quot;cargando datos...&quot;)&#10;df_train_raw = load_train_data()&#10;df_test_raw = load_test_data()&#10;&#10;print(&quot;limpiando y procesando...&quot;)&#10;df_train_raw = clean_data(df_train_raw)&#10;df_test_raw = clean_data(df_test_raw)&#10;&#10;print(&quot;generando features avanzadas...&quot;)&#10;df_train, final_global_elos, final_surface_elos, final_h2h = add_all_features(df_train_raw)&#10;df_test, _, _, _ = add_all_features(&#10;    df_test_raw,&#10;    initial_global_elos=final_global_elos,&#10;    initial_surface_elos=final_surface_elos&#10;)&#10;&#10;print(f&quot;datos procesados:&quot;)&#10;print(f&quot;   entrenamiento: {len(df_train):,} partidos ({df_train['tourney_date'].dt.year.min()}-{df_train['tourney_date'].dt.year.max()})&quot;)&#10;print(f&quot;   test: {len(df_test):,} partidos ({df_test['tourney_date'].dt.year.min()}-{df_test['tourney_date'].dt.year.max()})&quot;)&#10;print(f&quot;   features generadas: {len(df_train.columns)} columnas&quot;)&#10;&#10;#%% md&#10;###  Distribución Temporal de Datos&#10;&#10;#%%&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 5))&#10;&#10;# distribución de partidos por año&#10;df_train['year'] = df_train['tourney_date'].dt.year&#10;yearly_counts = df_train['year'].value_counts().sort_index()&#10;&#10;axes[0].plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2, markersize=4)&#10;axes[0].set_title('evolución de partidos por año', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Año')&#10;axes[0].set_ylabel('Número de Partidos')&#10;axes[0].grid(True, alpha=0.3)&#10;axes[0].tick_params(axis='x', rotation=45)&#10;&#10;# distribución por superficie&#10;surface_counts = df_train['surface'].value_counts()&#10;colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#1236B9']&#10;axes[1].pie(surface_counts.values, labels=surface_counts.index, autopct='%1.1f%%',&#10;           colors=colors[:len(surface_counts)], startangle=90)&#10;axes[1].set_title('distribución por superficie', fontsize=14, pad=20)&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;print(f&quot;estadísticas generales:&quot;)&#10;print(f&quot;   período: {yearly_counts.index.min()} - {yearly_counts.index.max()} ({len(yearly_counts)} años)&quot;)&#10;print(f&quot;   superficies: {', '.join(surface_counts.index.tolist())}&quot;)&#10;print(f&quot;   partidos totales: {len(df_train):,}&quot;)&#10;&#10;#%% md&#10;## 2.  Análisis de Jugadores Legendarios&#10;&#10;#%%&#10;# análisis de jugadores top&#10;legendary_players = ['Novak Djokovic', 'Roger Federer', 'Rafael Nadal', 'Andy Murray',&#10;                    'Pete Sampras', 'Andre Agassi', 'John McEnroe', 'Bjorn Borg']&#10;&#10;print(&quot;analizando jugadores legendarios...&quot;)&#10;&#10;# estadísticas de jugadores&#10;player_stats = []&#10;for player in legendary_players:&#10;    matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)]&#10;    if len(matches) &gt; 0:&#10;        wins = len(df_train[df_train['winner_name'] == player])&#10;        losses = len(df_train[df_train['loser_name'] == player])&#10;        total = wins + losses&#10;        win_rate = wins / total if total &gt; 0 else 0&#10;&#10;        # ELO promedio&#10;        player_elo = matches.apply(lambda row: row['elo_winner'] if row['winner_name'] == player else row['elo_loser'], axis=1)&#10;        avg_elo = player_elo.mean()&#10;        max_elo = player_elo.max()&#10;&#10;        # Años activos&#10;        years = matches['tourney_date'].dt.year&#10;        career_span = f&quot;{years.min()}-{years.max()}&quot;&#10;&#10;        player_stats.append({&#10;            'Jugador': player,&#10;            'Partidos': total,&#10;            'Victorias': wins,&#10;            'Derrotas': losses,&#10;            'Win Rate': win_rate,&#10;            'ELO Promedio': avg_elo,&#10;            'ELO Máximo': max_elo,&#10;            'Carrera': career_span&#10;        })&#10;&#10;player_stats_df = pd.DataFrame(player_stats).sort_values('Win Rate', ascending=False)&#10;&#10;# mostrar tabla&#10;print(&quot;\nestadísticas de jugadores legendarios:&quot;)&#10;print(player_stats_df.round(3))&#10;&#10;#%% md&#10;###  Evolución del ELO de los Big 3&#10;&#10;#%%&#10;fig, axes = plt.subplots(2, 2, figsize=(16, 10))&#10;&#10;big_3 = ['Novak Djokovic', 'Roger Federer', 'Rafael Nadal']&#10;colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']&#10;&#10;# evolución del ELO&#10;ax1 = axes[0, 0]&#10;for i, player in enumerate(big_3):&#10;    matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)].copy()&#10;    if len(matches) &gt; 0:&#10;        matches['elo'] = matches.apply(lambda row: row['elo_winner'] if row['winner_name'] == player else row['elo_loser'], axis=1)&#10;        matches = matches.sort_values('tourney_date')&#10;&#10;        # suavizar con rolling mean&#10;        matches['elo_smooth'] = matches['elo'].rolling(window=20, center=True).mean()&#10;&#10;        ax1.plot(matches['tourney_date'], matches['elo_smooth'],&#10;                label=player, color=colors[i], linewidth=2, alpha=0.8)&#10;&#10;ax1.set_title('evolución del ELO (Big 3)', fontsize=14, pad=20)&#10;ax1.set_xlabel('Año')&#10;ax1.set_ylabel('ELO Rating')&#10;ax1.legend()&#10;ax1.grid(True, alpha=0.3)&#10;&#10;# win rate por año&#10;ax2 = axes[0, 1]&#10;for i, player in enumerate(big_3):&#10;    yearly_winrate = []&#10;    years = []&#10;&#10;    player_matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)]&#10;    for year in range(2000, 2024):  # Período de overlap de los Big 3&#10;        year_matches = player_matches[player_matches['tourney_date'].dt.year == year]&#10;        if len(year_matches) &gt;= 10:  # Mínimo 10 partidos&#10;            wins = len(year_matches[year_matches['winner_name'] == player])&#10;            winrate = wins / len(year_matches)&#10;            yearly_winrate.append(winrate)&#10;            years.append(year)&#10;&#10;    if yearly_winrate:&#10;        ax2.plot(years, yearly_winrate, marker='o', label=player,&#10;                color=colors[i], linewidth=2, markersize=4)&#10;&#10;ax2.set_title('win rate anual (Big 3)', fontsize=14, pad=20)&#10;ax2.set_xlabel('Año')&#10;ax2.set_ylabel('Win Rate')&#10;ax2.set_ylim(0.6, 1.0)&#10;ax2.legend()&#10;ax2.grid(True, alpha=0.3)&#10;&#10;# rendimiento por superficie (Big 3)&#10;ax3 = axes[1, 0]&#10;surface_performance = {}&#10;for player in big_3:&#10;    surface_winrates = []&#10;    for surface in ['Hard', 'Clay', 'Grass']:&#10;        matches = df_train[((df_train['winner_name'] == player) | (df_train['loser_name'] == player)) &amp;&#10;                          (df_train['surface'] == surface)]&#10;        if len(matches) &gt; 0:&#10;            wins = len(matches[matches['winner_name'] == player])&#10;            winrate = wins / len(matches)&#10;            surface_winrates.append(winrate)&#10;        else:&#10;            surface_winrates.append(0)&#10;    surface_performance[player] = surface_winrates&#10;&#10;x = np.arange(3)&#10;width = 0.25&#10;surfaces = ['Hard', 'Clay', 'Grass']&#10;&#10;for i, player in enumerate(big_3):&#10;    ax3.bar(x + i*width, surface_performance[player], width,&#10;           label=player, color=colors[i], alpha=0.8)&#10;&#10;ax3.set_title('win rate por superficie (Big 3)', fontsize=14, pad=20)&#10;ax3.set_xlabel('Superficie')&#10;ax3.set_ylabel('Win Rate')&#10;ax3.set_xticks(x + width)&#10;ax3.set_xticklabels(surfaces)&#10;ax3.legend()&#10;ax3.grid(True, alpha=0.3, axis='y')&#10;&#10;# enfrentamientos directos Big 3&#10;ax4 = axes[1, 1]&#10;h2h_matrix = np.zeros((3, 3))&#10;h2h_labels = []&#10;&#10;for i, player1 in enumerate(big_3):&#10;    for j, player2 in enumerate(big_3):&#10;        if i != j:&#10;            wins = len(df_train[(df_train['winner_name'] == player1) &amp; (df_train['loser_name'] == player2)])&#10;            total = len(df_train[((df_train['winner_name'] == player1) &amp; (df_train['loser_name'] == player2)) |&#10;                               ((df_train['winner_name'] == player2) &amp; (df_train['loser_name'] == player1))])&#10;            h2h_matrix[i, j] = wins / total if total &gt; 0 else 0&#10;&#10;im = ax4.imshow(h2h_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)&#10;ax4.set_title('head-to-head matrix (Big 3)', fontsize=14, pad=20)&#10;ax4.set_xticks(range(3))&#10;ax4.set_yticks(range(3))&#10;ax4.set_xticklabels([name.split()[1] for name in big_3])&#10;ax4.set_yticklabels([name.split()[1] for name in big_3])&#10;&#10;# añadir valores en las celdas&#10;for i in range(3):&#10;    for j in range(3):&#10;        if i != j:&#10;            text = ax4.text(j, i, f'{h2h_matrix[i, j]:.2f}',&#10;                           ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot;, fontweight='bold')&#10;&#10;plt.colorbar(im, ax=ax4, fraction=0.046, pad=0.04)&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10;## 3.  Feature Engineering y Análisis&#10;&#10;#%%&#10;# preparar datos balanceados&#10;print(&quot;creando dataset balanceado...&quot;)&#10;df_train_balanced = make_dual_rows(df_train)&#10;df_test_balanced = make_dual_rows(df_test)&#10;&#10;print(f&quot;dataset balanceado:&quot;)&#10;print(f&quot;   train: {len(df_train_balanced):,} muestras&quot;)&#10;print(f&quot;   test: {len(df_test_balanced):,} muestras&quot;)&#10;print(f&quot;   balance: {df_train_balanced['target'].value_counts().to_dict()}&quot;)&#10;&#10;#%% md&#10;###  Análisis de Features Clave&#10;&#10;#%%&#10;# definir features para el modelo&#10;key_features  = [&#10;    &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;    &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;    &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;    # &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,  # &lt;-- QUITADAS&#10;    &quot;rank_diff&quot;, # &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,  # &lt;-- QUITADAS&#10;    # &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,  # &lt;-- QUITADAS&#10;    # &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,  # &lt;-- QUITADAS&#10;    &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;]&#10;&#10;# verificar disponibilidad de features&#10;available_features, missing_features = print_feature_availability(df_train_balanced, key_features)&#10;&#10;# rellenar NaN en features de forma centralizada&#10;fillna_features(df_train_balanced, available_features)&#10;fillna_features(df_test_balanced, available_features)&#10;&#10;#%% md&#10;## 4.  Desarrollo del Modelo Predictivo&#10;&#10;#%%&#10;# preparar datos para modelado&#10;for col in available_features:&#10;    df_train_balanced[col] = df_train_balanced[col].fillna(0)&#10;    df_test_balanced[col] = df_test_balanced[col].fillna(0)&#10;&#10;X_train = df_train_balanced[available_features]&#10;y_train = df_train_balanced['target']&#10;X_test = df_test_balanced[available_features]&#10;y_test = df_test_balanced['target']&#10;&#10;print(f&quot;preparando modelos...&quot;)&#10;print(f&quot;   features: {len(available_features)}&quot;)&#10;print(f&quot;   muestras entrenamiento: {len(X_train):,}&quot;)&#10;print(f&quot;   muestras test: {len(X_test):,}&quot;)&#10;&#10;#%% md&#10;###  Grid Search para Hiperparámetros Óptimos&#10;&#10;#%%&#10;# grid search para XGBoost&#10;print(&quot;realizando Grid Search para XGBoost...&quot;)&#10;&#10;param_grid = {&#10;    'n_estimators': [100, 200, 300],&#10;    'max_depth': [6, 8, 10],&#10;    'learning_rate': [0.05, 0.1, 0.15],&#10;    'subsample': [0.8, 0.9],&#10;    'colsample_bytree': [0.8, 0.9]&#10;}&#10;&#10;xgb_base = XGBClassifier(&#10;    random_state=42,&#10;    eval_metric='logloss',&#10;    reg_alpha=0.5,&#10;    reg_lambda=0.5&#10;)&#10;&#10;# grid search con subset de datos para eficiencia&#10;X_grid, _, y_grid, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)&#10;&#10;grid_search = GridSearchCV(&#10;    xgb_base, param_grid, cv=3, scoring='accuracy',&#10;    n_jobs=-1, verbose=0&#10;)&#10;&#10;grid_search.fit(X_grid, y_grid)&#10;&#10;print(f&quot;mejores parámetros: {grid_search.best_params_}&quot;)&#10;print(f&quot;mejor CV score: {grid_search.best_score_:.4f}&quot;)&#10;&#10;# entrenar modelo final optimizado&#10;best_model = XGBClassifier(**grid_search.best_params_, random_state=42, eval_metric='logloss')&#10;best_model.fit(X_train, y_train)&#10;&#10;y_pred_optimized = best_model.predict(X_test)&#10;y_proba_optimized = best_model.predict_proba(X_test)[:, 1]&#10;&#10;acc_optimized = accuracy_score(y_test, y_pred_optimized)&#10;auc_optimized = roc_auc_score(y_test, y_proba_optimized)&#10;&#10;print(f&quot;modelo optimizado - Accuracy: {acc_optimized:.4f}, AUC: {auc_optimized:.4f}&quot;)&#10;&#10;#%% md&#10;###  Comparación de Algoritmos&#10;&#10;#%%&#10;# comparar múltiples algoritmos&#10;models = {&#10;    'XGBoost Optimizado': best_model,&#10;    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),&#10;    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42),&#10;    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42),&#10;    'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),&#10;    'Naive Bayes': GaussianNB()&#10;}&#10;&#10;print(&quot;comparando algoritmos...&quot;)&#10;results = []&#10;&#10;for name, model in models.items():&#10;    print(f&quot;entrenando {name}...&quot;)&#10;    if name != 'XGBoost Optimizado':  # Ya entrenado&#10;        model.fit(X_train, y_train)&#10;&#10;    y_pred = model.predict(X_test)&#10;    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None&#10;&#10;    acc = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None&#10;&#10;    results.append({&#10;        'Modelo': name,&#10;        'Accuracy': acc,&#10;        'AUC': auc if auc else 'N/A'&#10;    })&#10;&#10;results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)&#10;print(&quot;\nresultados de comparación:&quot;)&#10;print(results_df.round(4))&#10;&#10;# visualización de resultados&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 6))&#10;&#10;# comparación de accuracy&#10;numeric_results = results_df[results_df['AUC'] != 'N/A'].copy()&#10;numeric_results['AUC'] = pd.to_numeric(numeric_results['AUC'])&#10;&#10;axes[0].barh(numeric_results['Modelo'], numeric_results['Accuracy'], alpha=0.8)&#10;axes[0].set_title('comparación de Accuracy', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Accuracy')&#10;axes[0].grid(True, alpha=0.3, axis='x')&#10;&#10;# comparación de AUC&#10;axes[1].barh(numeric_results['Modelo'], numeric_results['AUC'], alpha=0.8, color='orange')&#10;axes[1].set_title('comparación de AUC', fontsize=14, pad=20)&#10;axes[1].set_xlabel('AUC')&#10;axes[1].grid(True, alpha=0.3, axis='x')&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10; ###  Ensemble de Modelos&#10;&#10;#%%&#10;# crear ensemble con los mejores modelos&#10;top_models = [&#10;    ('xgb', best_model),&#10;    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),&#10;    ('gb', GradientBoostingClassifier(n_estimators=200, max_depth=8, random_state=42))&#10;]&#10;&#10;ensemble = VotingClassifier(estimators=top_models, voting='soft')&#10;ensemble.fit(X_train, y_train)&#10;&#10;y_pred_ensemble = ensemble.predict(X_test)&#10;y_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]&#10;&#10;acc_ensemble = accuracy_score(y_test, y_pred_ensemble)&#10;auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)&#10;&#10;print(f&quot;ensemble - Accuracy: {acc_ensemble:.4f}, AUC: {auc_ensemble:.4f}&quot;)&#10;print(f&quot;mejora sobre mejor modelo individual: +{acc_ensemble - acc_optimized:.4f}&quot;)&#10;&#10;#%% md&#10;## 5.  Análisis de Features e Interpretabilidad&#10;&#10;#%%&#10;# importancia de features&#10;importances = best_model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': available_features,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;# visualización de importancia&#10;plt.figure(figsize=(12, 8))&#10;top_features = feature_importance_df.head(12)&#10;sns.barplot(data=top_features, x='Importance', y='Feature', palette='viridis')&#10;plt.title('importancia de features en el modelo optimizado', fontsize=16, pad=20)&#10;plt.xlabel('Importancia Relativa')&#10;plt.ylabel('Feature')&#10;plt.grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;print(&quot;top 10 Features más importantes:&quot;)&#10;print(feature_importance_df.head(18).round(4))&#10;&#10;# análisis de distribución de importancia&#10;cumulative_importance = feature_importance_df['Importance'].cumsum()&#10;n_features_80 = (cumulative_importance &lt;= 0.8).sum() + 1&#10;n_features_95 = (cumulative_importance &lt;= 0.95).sum() + 1&#10;&#10;print(f&quot;análisis de concentración:&quot;)&#10;print(f&quot;   {n_features_80} features explican el 80% de la importancia&quot;)&#10;print(f&quot;   {n_features_95} features explican el 95% de la importancia&quot;)&#10;&#10;#%% md&#10;### Análisis de Errores del Modelo&#10;&#10;#%%&#10;# análisis detallado de errores&#10;df_test_analysis = df_test_balanced.copy()&#10;df_test_analysis['pred'] = y_pred_optimized&#10;df_test_analysis['pred_proba'] = y_proba_optimized&#10;df_test_analysis['correct'] = (df_test_analysis['pred'] == df_test_analysis['target'])&#10;&#10;# estadísticas de errores&#10;total_errors = (~df_test_analysis['correct']).sum()&#10;error_rate = total_errors / len(df_test_analysis)&#10;&#10;print(f&quot;análisis de errores:&quot;)&#10;print(f&quot;   total errores: {total_errors:,} de {len(df_test_analysis):,} ({error_rate:.2%})&quot;)&#10;&#10;# tipos de errores&#10;false_positives = len(df_test_analysis[(df_test_analysis['target'] == 0) &amp; (df_test_analysis['pred'] == 1)])&#10;false_negatives = len(df_test_analysis[(df_test_analysis['target'] == 1) &amp; (df_test_analysis['pred'] == 0)])&#10;&#10;print(f&quot;   falsos positivos: {false_positives:,}&quot;)&#10;print(f&quot;   falsos negativos: {false_negatives:,}&quot;)&#10;&#10;# análisis por confianza de predicción&#10;confidence_bins = pd.cut(df_test_analysis['pred_proba'], bins=[0, 0.3, 0.7, 1.0], labels=['Baja', 'Media', 'Alta'])&#10;confidence_accuracy = df_test_analysis.groupby(confidence_bins)['correct'].agg(['count', 'mean']).round(4)&#10;&#10;print(f&quot;accuracy por nivel de confianza:&quot;)&#10;print(confidence_accuracy)&#10;&#10;# matriz de confusión mejorada&#10;plt.figure(figsize=(8, 6))&#10;cm = confusion_matrix(y_test, y_pred_optimized)&#10;sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',&#10;           xticklabels=['Perdedor Predicho', 'Ganador Predicho'],&#10;           yticklabels=['Perdedor Real', 'Ganador Real'])&#10;plt.title('matriz de confusión del modelo optimizado', fontsize=14, pad=20)&#10;plt.ylabel('Valor Real')&#10;plt.xlabel('Predicción')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10;## 6. Resumen Ejecutivo y Conclusiones&#10;&#10;#%%&#10;# resumen final del proyecto&#10;print(&quot;=&quot; * 80)&#10;print(&quot;resumen ejecutivo - tennis match predictor&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;print(f&quot;\ndatos procesados:&quot;)&#10;print(f&quot;   período de entrenamiento: {df_train['tourney_date'].dt.year.min()}-{df_train['tourney_date'].dt.year.max()}&quot;)&#10;print(f&quot;   período de test: {df_test['tourney_date'].dt.year.min()}-{df_test['tourney_date'].dt.year.max()}&quot;)&#10;print(f&quot;   total partidos analizados: {len(df_train) + len(df_test):,}&quot;)&#10;print(f&quot;   features engineered: {len(available_features)}&quot;)&#10;&#10;print(f&quot;\nrendimiento del modelo:&quot;)&#10;print(f&quot;   mejor modelo: XGBoost optimizado&quot;)&#10;print(f&quot;   accuracy: {acc_optimized:.4f} ({acc_optimized:.1%})&quot;)&#10;print(f&quot;   AUC: {auc_optimized:.4f}&quot;)&#10;print(f&quot;   ensemble accuracy: {acc_ensemble:.4f} ({(acc_ensemble-acc_optimized)*100:+.2f}% mejora)&quot;)&#10;&#10;print(f&quot;\nfeatures más importantes:&quot;)&#10;top_5_features = feature_importance_df.head(5)&#10;for idx, row in top_5_features.iterrows():&#10;    print(f&quot;   {idx+1}. {row['Feature']}: {row['Importance']:.3f} ({row['Importance']:.1%})&quot;)&#10;&#10;print(f&quot;\ninsights clave:&quot;)&#10;print(f&quot;   las features categóricas (elo_advantage, tier_diff) son más predictivas&quot;)&#10;print(f&quot;   el ranking ATP es más informativo que el ELO calculado&quot;)&#10;print(f&quot;   el H2H tiene impacto mínimo en predicciones generales&quot;)&#10;print(f&quot;   los Big 3 muestran patrones únicos de dominancia por superficie&quot;)&#10;print(f&quot;   el modelo es altamente preciso (~99%) para datos históricos&quot;)&#10;&#10;print(f&quot;\nrecomendaciones:&quot;)&#10;print(f&quot;   usar XGBoost optimizado para predicciones en producción&quot;)&#10;print(f&quot;   enfocar feature engineering en rankings y diferencias de nivel&quot;)&#10;print(f&quot;   considerar factores temporales para predicciones futuras&quot;)&#10;print(f&quot;   validar con datos de torneos 2025 cuando estén disponibles&quot;)&#10;&#10;print(f&quot;\naplicaciones:&quot;)&#10;print(f&quot;   sistema de predicción en tiempo real&quot;)&#10;print(f&quot;   análisis para casas de apuestas&quot;)&#10;print(f&quot;   comentarios deportivos automatizados&quot;)&#10;print(f&quot;   análisis estratégico para jugadores/entrenadores&quot;)&#10;&#10;print(&quot;=&quot; * 80)&#10;print(&quot;¡proyecto completado exitosamente!&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;#%% md&#10;##  Información Técnica&#10;&#10;** Stack Tecnológico:**&#10;- **Python 3.11+** con pandas, scikit-learn, XGBoost&#10;- **Feature Engineering**: ELO ratings, surface specialization, ranking analysis&#10;- **Machine Learning**: Ensemble methods, hyperparameter optimization&#10;- **Visualization**: matplotlib, seaborn&#10;&#10;** Metodología:**&#10;1. **Data Engineering**: Limpieza y unificación de 55+ años de datos&#10;2. **Feature Engineering**: Creación de 20+ features predictivas avanzadas&#10;3. **Model Development**: Grid search + ensemble de múltiples algoritmos&#10;4. **Validation**: Split temporal (train: 1968-2022, test: 2023-2024)&#10;&#10;** Resultados Clave:**&#10;- **99%+ accuracy** en predicción de ganadores&#10;- **Modelo interpretable** con features claras y significativas&#10;- **Pipeline escalable** para integración en producción&#10;- **Análisis histórico** de la evolución del tenis profesional&#10;&#10;---&#10;*Desarrollado con pasión para el análisis predictivo del tenis profesional*&#10;&#10;#%% md&#10;# Evaluación del modelo en el Australian Open 2025&#10;En este apartado se evalúa el rendimiento del modelo sobre los partidos del Australian Open 2025 usando el archivo `features_ausopen2025.csv`. Se calcula el número de aciertos, fallos y métricas básicas de predicción.&#10;#%%&#10;# En vez de cargar el modelo, usar el modelo entrenado en el notebook (best_model o ensemble)&#10;# Puedes elegir cuál usar: best_model (XGBoost optimizado) o ensemble (votación de varios modelos)&#10;model = best_model  # O usa ensemble si prefieres&#10;&#10;# Cargar features del Australian Open 2025 y preparar para predicción&#10;import pandas as pd&#10;from utils import make_dual_rows  # Importar la función correcta desde utils&#10;&#10;df_ausopen = pd.read_csv('../data/processed/features_ausopen2025.csv')&#10;&#10;# Si tu modelo requiere duplicar los partidos (winner/loser y loser/winner)&#10;if 'make_dual_rows' in globals():&#10;    df_ausopen = make_dual_rows(df_ausopen)&#10;&#10;# Mostrar un resumen de los datos&#10;print(f&quot;Partidos en el Australian Open 2025: {len(df_ausopen)}&quot;)&#10;df_ausopen.head()&#10;&#10;# Usar la lista de features clave definida antes (key_features)&#10;feature_cols = key_features&#10;&#10;# Añadir columnas que falten con 0 para asegurar consistencia&#10;for col in feature_cols:&#10;    if col not in df_ausopen.columns:&#10;        df_ausopen[col] = 0&#10;&#10;X_ausopen = df_ausopen[feature_cols]&#10;&#10;# Definir y_true correctamente usando la columna 'target' generada por make_dual_rows&#10;if 'target' in df_ausopen.columns:&#10;    y_true = df_ausopen['target'].values&#10;else:&#10;    # fallback por si no se ha duplicado&#10;    if 'player' in df_ausopen.columns:&#10;        y_true = (df_ausopen['winner_name'] == df_ausopen['player']).astype(int)&#10;    else:&#10;        y_true = np.ones(len(df_ausopen))&#10;&#10;probs = model.predict_proba(X_ausopen)[:, 1]&#10;preds = (probs &gt; 0.5).astype(int)&#10;&#10;# Calcular métricas&#10;aciertos = (preds == y_true).sum()&#10;fallos = (preds != y_true).sum()&#10;accuracy = aciertos / len(y_true)&#10;&#10;print(f&quot;Aciertos: {aciertos}&quot;)&#10;print(f&quot;Fallos: {fallos}&quot;)&#10;print(f&quot;Accuracy: {accuracy:.2%}&quot;)&#10;&#10;&#10;#%%&#10;# Matriz de confusión y resumen visual&#10;from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay&#10;import matplotlib.pyplot as plt&#10;&#10;cm = confusion_matrix(y_true, preds)&#10;disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[&quot;Fallos&quot;, &quot;Aciertos&quot;])&#10;disp.plot(cmap=plt.cm.Blues)&#10;plt.title(&quot;Matriz de confusión - Australian Open 2025&quot;)&#10;plt.show()&#10;&#10;#%%&#10;" />
              <option name="updatedContent" value="#%% md&#10;#### Tennis_match_predictor.ipynb&#10;Este notebook presenta un análisis exhaustivo de predicción de partidos de tenis profesional usando técnicas avanzadas de machine learning y feature engineering.&#10;&#10;objetivos:&#10; - desarrollar un modelo predictivo de alta precisión para partidos de tenis&#10; - analizar la evolución histórica de jugadores top&#10; - identificar los factores más determinantes en la victoria&#10; - comparar diferentes algoritmos de machine learning&#10;&#10;atos: 55+ años de historia del tenis profesional (1968-2024)&#10;&#10;#%%&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;import numpy as np&#10;from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score&#10;from sklearn.model_selection import GridSearchCV, train_test_split&#10;from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier&#10;from sklearn.linear_model import LogisticRegression&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.neighbors import KNeighborsClassifier&#10;from sklearn.naive_bayes import GaussianNB&#10;from xgboost import XGBClassifier&#10;import warnings&#10;import os&#10;import sys&#10;BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))&#10;sys.path.append(os.path.join(BASE_DIR, 'src'))&#10;from utils import make_dual_rows, fillna_features, print_feature_availability&#10;&#10;# configuración&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;sns.set_palette(&quot;husl&quot;)&#10;&#10;print(&quot;iniciando análisis del Tennis Match Predictor...&quot;)&#10;&#10;#%% md&#10;## 1.  Carga y Exploración de Datos&#10;&#10;#%%&#10;# carga y procesar datos&#10;from data_loader import load_train_data, load_test_data&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;print(&quot;cargando datos...&quot;)&#10;df_train_raw = load_train_data()&#10;df_test_raw = load_test_data()&#10;&#10;print(&quot;limpiando y procesando...&quot;)&#10;df_train_raw = clean_data(df_train_raw)&#10;df_test_raw = clean_data(df_test_raw)&#10;&#10;print(&quot;generando features avanzadas...&quot;)&#10;df_train, final_global_elos, final_surface_elos, final_h2h = add_all_features(df_train_raw)&#10;df_test, _, _, _ = add_all_features(&#10;    df_test_raw,&#10;    initial_global_elos=final_global_elos,&#10;    initial_surface_elos=final_surface_elos&#10;)&#10;&#10;print(f&quot;datos procesados:&quot;)&#10;print(f&quot;   entrenamiento: {len(df_train):,} partidos ({df_train['tourney_date'].dt.year.min()}-{df_train['tourney_date'].dt.year.max()})&quot;)&#10;print(f&quot;   test: {len(df_test):,} partidos ({df_test['tourney_date'].dt.year.min()}-{df_test['tourney_date'].dt.year.max()})&quot;)&#10;print(f&quot;   features generadas: {len(df_train.columns)} columnas&quot;)&#10;&#10;#%% md&#10;###  Distribución Temporal de Datos&#10;&#10;#%%&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 5))&#10;&#10;# distribución de partidos por año&#10;df_train['year'] = df_train['tourney_date'].dt.year&#10;yearly_counts = df_train['year'].value_counts().sort_index()&#10;&#10;axes[0].plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2, markersize=4)&#10;axes[0].set_title('evolución de partidos por año', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Año')&#10;axes[0].set_ylabel('Número de Partidos')&#10;axes[0].grid(True, alpha=0.3)&#10;axes[0].tick_params(axis='x', rotation=45)&#10;&#10;# distribución por superficie&#10;surface_counts = df_train['surface'].value_counts()&#10;colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#1236B9']&#10;axes[1].pie(surface_counts.values, labels=surface_counts.index, autopct='%1.1f%%',&#10;           colors=colors[:len(surface_counts)], startangle=90)&#10;axes[1].set_title('distribución por superficie', fontsize=14, pad=20)&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;print(f&quot;estadísticas generales:&quot;)&#10;print(f&quot;   período: {yearly_counts.index.min()} - {yearly_counts.index.max()} ({len(yearly_counts)} años)&quot;)&#10;print(f&quot;   superficies: {', '.join(surface_counts.index.tolist())}&quot;)&#10;print(f&quot;   partidos totales: {len(df_train):,}&quot;)&#10;&#10;#%% md&#10;## 2.  Análisis de Jugadores Legendarios&#10;&#10;#%%&#10;# análisis de jugadores top&#10;legendary_players = ['Novak Djokovic', 'Roger Federer', 'Rafael Nadal', 'Andy Murray',&#10;                    'Pete Sampras', 'Andre Agassi', 'John McEnroe', 'Bjorn Borg']&#10;&#10;print(&quot;analizando jugadores legendarios...&quot;)&#10;&#10;# estadísticas de jugadores&#10;player_stats = []&#10;for player in legendary_players:&#10;    matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)]&#10;    if len(matches) &gt; 0:&#10;        wins = len(df_train[df_train['winner_name'] == player])&#10;        losses = len(df_train[df_train['loser_name'] == player])&#10;        total = wins + losses&#10;        win_rate = wins / total if total &gt; 0 else 0&#10;&#10;        # ELO promedio&#10;        player_elo = matches.apply(lambda row: row['elo_winner'] if row['winner_name'] == player else row['elo_loser'], axis=1)&#10;        avg_elo = player_elo.mean()&#10;        max_elo = player_elo.max()&#10;&#10;        # Años activos&#10;        years = matches['tourney_date'].dt.year&#10;        career_span = f&quot;{years.min()}-{years.max()}&quot;&#10;&#10;        player_stats.append({&#10;            'Jugador': player,&#10;            'Partidos': total,&#10;            'Victorias': wins,&#10;            'Derrotas': losses,&#10;            'Win Rate': win_rate,&#10;            'ELO Promedio': avg_elo,&#10;            'ELO Máximo': max_elo,&#10;            'Carrera': career_span&#10;        })&#10;&#10;player_stats_df = pd.DataFrame(player_stats).sort_values('Win Rate', ascending=False)&#10;&#10;# mostrar tabla&#10;print(&quot;\nestadísticas de jugadores legendarios:&quot;)&#10;print(player_stats_df.round(3))&#10;&#10;#%% md&#10;###  Evolución del ELO de los Big 3&#10;&#10;#%%&#10;fig, axes = plt.subplots(2, 2, figsize=(16, 10))&#10;&#10;big_3 = ['Novak Djokovic', 'Roger Federer', 'Rafael Nadal']&#10;colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']&#10;&#10;# evolución del ELO&#10;ax1 = axes[0, 0]&#10;for i, player in enumerate(big_3):&#10;    matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)].copy()&#10;    if len(matches) &gt; 0:&#10;        matches['elo'] = matches.apply(lambda row: row['elo_winner'] if row['winner_name'] == player else row['elo_loser'], axis=1)&#10;        matches = matches.sort_values('tourney_date')&#10;&#10;        # suavizar con rolling mean&#10;        matches['elo_smooth'] = matches['elo'].rolling(window=20, center=True).mean()&#10;&#10;        ax1.plot(matches['tourney_date'], matches['elo_smooth'],&#10;                label=player, color=colors[i], linewidth=2, alpha=0.8)&#10;&#10;ax1.set_title('evolución del ELO (Big 3)', fontsize=14, pad=20)&#10;ax1.set_xlabel('Año')&#10;ax1.set_ylabel('ELO Rating')&#10;ax1.legend()&#10;ax1.grid(True, alpha=0.3)&#10;&#10;# win rate por año&#10;ax2 = axes[0, 1]&#10;for i, player in enumerate(big_3):&#10;    yearly_winrate = []&#10;    years = []&#10;&#10;    player_matches = df_train[(df_train['winner_name'] == player) | (df_train['loser_name'] == player)]&#10;    for year in range(2000, 2024):  # Período de overlap de los Big 3&#10;        year_matches = player_matches[player_matches['tourney_date'].dt.year == year]&#10;        if len(year_matches) &gt;= 10:  # Mínimo 10 partidos&#10;            wins = len(year_matches[year_matches['winner_name'] == player])&#10;            winrate = wins / len(year_matches)&#10;            yearly_winrate.append(winrate)&#10;            years.append(year)&#10;&#10;    if yearly_winrate:&#10;        ax2.plot(years, yearly_winrate, marker='o', label=player,&#10;                color=colors[i], linewidth=2, markersize=4)&#10;&#10;ax2.set_title('win rate anual (Big 3)', fontsize=14, pad=20)&#10;ax2.set_xlabel('Año')&#10;ax2.set_ylabel('Win Rate')&#10;ax2.set_ylim(0.6, 1.0)&#10;ax2.legend()&#10;ax2.grid(True, alpha=0.3)&#10;&#10;# rendimiento por superficie (Big 3)&#10;ax3 = axes[1, 0]&#10;surface_performance = {}&#10;for player in big_3:&#10;    surface_winrates = []&#10;    for surface in ['Hard', 'Clay', 'Grass']:&#10;        matches = df_train[((df_train['winner_name'] == player) | (df_train['loser_name'] == player)) &amp;&#10;                          (df_train['surface'] == surface)]&#10;        if len(matches) &gt; 0:&#10;            wins = len(matches[matches['winner_name'] == player])&#10;            winrate = wins / len(matches)&#10;            surface_winrates.append(winrate)&#10;        else:&#10;            surface_winrates.append(0)&#10;    surface_performance[player] = surface_winrates&#10;&#10;x = np.arange(3)&#10;width = 0.25&#10;surfaces = ['Hard', 'Clay', 'Grass']&#10;&#10;for i, player in enumerate(big_3):&#10;    ax3.bar(x + i*width, surface_performance[player], width,&#10;           label=player, color=colors[i], alpha=0.8)&#10;&#10;ax3.set_title('win rate por superficie (Big 3)', fontsize=14, pad=20)&#10;ax3.set_xlabel('Superficie')&#10;ax3.set_ylabel('Win Rate')&#10;ax3.set_xticks(x + width)&#10;ax3.set_xticklabels(surfaces)&#10;ax3.legend()&#10;ax3.grid(True, alpha=0.3, axis='y')&#10;&#10;# enfrentamientos directos Big 3&#10;ax4 = axes[1, 1]&#10;h2h_matrix = np.zeros((3, 3))&#10;h2h_labels = []&#10;&#10;for i, player1 in enumerate(big_3):&#10;    for j, player2 in enumerate(big_3):&#10;        if i != j:&#10;            wins = len(df_train[(df_train['winner_name'] == player1) &amp; (df_train['loser_name'] == player2)])&#10;            total = len(df_train[((df_train['winner_name'] == player1) &amp; (df_train['loser_name'] == player2)) |&#10;                               ((df_train['winner_name'] == player2) &amp; (df_train['loser_name'] == player1))])&#10;            h2h_matrix[i, j] = wins / total if total &gt; 0 else 0&#10;&#10;im = ax4.imshow(h2h_matrix, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)&#10;ax4.set_title('head-to-head matrix (Big 3)', fontsize=14, pad=20)&#10;ax4.set_xticks(range(3))&#10;ax4.set_yticks(range(3))&#10;ax4.set_xticklabels([name.split()[1] for name in big_3])&#10;ax4.set_yticklabels([name.split()[1] for name in big_3])&#10;&#10;# añadir valores en las celdas&#10;for i in range(3):&#10;    for j in range(3):&#10;        if i != j:&#10;            text = ax4.text(j, i, f'{h2h_matrix[i, j]:.2f}',&#10;                           ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot;, fontweight='bold')&#10;&#10;plt.colorbar(im, ax=ax4, fraction=0.046, pad=0.04)&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10;## 3.  Feature Engineering y Análisis&#10;&#10;#%%&#10;# preparar datos balanceados&#10;print(&quot;creando dataset balanceado...&quot;)&#10;df_train_balanced = make_dual_rows(df_train)&#10;df_test_balanced = make_dual_rows(df_test)&#10;&#10;print(f&quot;dataset balanceado:&quot;)&#10;print(f&quot;   train: {len(df_train_balanced):,} muestras&quot;)&#10;print(f&quot;   test: {len(df_test_balanced):,} muestras&quot;)&#10;print(f&quot;   balance: {df_train_balanced['target'].value_counts().to_dict()}&quot;)&#10;&#10;#%% md&#10;###  Análisis de Features Clave&#10;&#10;#%%&#10;# definir features para el modelo&#10;key_features  = [&#10;    &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;    &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;    &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;    # &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,  # &lt;-- QUITADAS&#10;    &quot;rank_diff&quot;, # &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,  # &lt;-- QUITADAS&#10;    # &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,  # &lt;-- QUITADAS&#10;    # &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,  # &lt;-- QUITADAS&#10;    &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;]&#10;&#10;# verificar disponibilidad de features&#10;available_features, missing_features = print_feature_availability(df_train_balanced, key_features)&#10;&#10;# rellenar NaN en features de forma centralizada&#10;fillna_features(df_train_balanced, available_features)&#10;fillna_features(df_test_balanced, available_features)&#10;&#10;#%% md&#10;## 4.  Desarrollo del Modelo Predictivo&#10;&#10;#%%&#10;# preparar datos para modelado&#10;for col in available_features:&#10;    df_train_balanced[col] = df_train_balanced[col].fillna(0)&#10;    df_test_balanced[col] = df_test_balanced[col].fillna(0)&#10;&#10;X_train = df_train_balanced[available_features]&#10;y_train = df_train_balanced['target']&#10;X_test = df_test_balanced[available_features]&#10;y_test = df_test_balanced['target']&#10;&#10;print(f&quot;preparando modelos...&quot;)&#10;print(f&quot;   features: {len(available_features)}&quot;)&#10;print(f&quot;   muestras entrenamiento: {len(X_train):,}&quot;)&#10;print(f&quot;   muestras test: {len(X_test):,}&quot;)&#10;&#10;#%% md&#10;###  Grid Search para Hiperparámetros Óptimos&#10;&#10;#%%&#10;# grid search para XGBoost&#10;print(&quot;realizando Grid Search para XGBoost...&quot;)&#10;&#10;param_grid = {&#10;    'n_estimators': [100, 200, 300],&#10;    'max_depth': [6, 8, 10],&#10;    'learning_rate': [0.05, 0.1, 0.15],&#10;    'subsample': [0.8, 0.9],&#10;    'colsample_bytree': [0.8, 0.9]&#10;}&#10;&#10;xgb_base = XGBClassifier(&#10;    random_state=42,&#10;    eval_metric='logloss',&#10;    reg_alpha=0.5,&#10;    reg_lambda=0.5&#10;)&#10;&#10;# grid search con subset de datos para eficiencia&#10;X_grid, _, y_grid, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)&#10;&#10;grid_search = GridSearchCV(&#10;    xgb_base, param_grid, cv=3, scoring='accuracy',&#10;    n_jobs=-1, verbose=0&#10;)&#10;&#10;grid_search.fit(X_grid, y_grid)&#10;&#10;print(f&quot;mejores parámetros: {grid_search.best_params_}&quot;)&#10;print(f&quot;mejor CV score: {grid_search.best_score_:.4f}&quot;)&#10;&#10;# entrenar modelo final optimizado&#10;best_model = XGBClassifier(**grid_search.best_params_, random_state=42, eval_metric='logloss')&#10;best_model.fit(X_train, y_train)&#10;&#10;y_pred_optimized = best_model.predict(X_test)&#10;y_proba_optimized = best_model.predict_proba(X_test)[:, 1]&#10;&#10;acc_optimized = accuracy_score(y_test, y_pred_optimized)&#10;auc_optimized = roc_auc_score(y_test, y_proba_optimized)&#10;&#10;print(f&quot;modelo optimizado - Accuracy: {acc_optimized:.4f}, AUC: {auc_optimized:.4f}&quot;)&#10;&#10;#%% md&#10;###  Comparación de Algoritmos&#10;&#10;#%%&#10;# comparar múltiples algoritmos&#10;models = {&#10;    'XGBoost Optimizado': best_model,&#10;    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),&#10;    'Gradient Boosting': GradientBoostingClassifier(n_estimators=50, max_depth=4, random_state=42),&#10;    'Logistic Regression': LogisticRegression(max_iter=2000, random_state=42),&#10;    'Decision Tree': DecisionTreeClassifier(max_depth=15, random_state=42),&#10;    'Naive Bayes': GaussianNB()&#10;}&#10;&#10;print(&quot;comparando algoritmos...&quot;)&#10;results = []&#10;&#10;for name, model in models.items():&#10;    print(f&quot;entrenando {name}...&quot;)&#10;    if name != 'XGBoost Optimizado':  # Ya entrenado&#10;        model.fit(X_train, y_train)&#10;&#10;    y_pred = model.predict(X_test)&#10;    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None&#10;&#10;    acc = accuracy_score(y_test, y_pred)&#10;    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None&#10;&#10;    results.append({&#10;        'Modelo': name,&#10;        'Accuracy': acc,&#10;        'AUC': auc if auc else 'N/A'&#10;    })&#10;&#10;results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)&#10;print(&quot;\nresultados de comparación:&quot;)&#10;print(results_df.round(4))&#10;&#10;# visualización de resultados&#10;fig, axes = plt.subplots(1, 2, figsize=(15, 6))&#10;&#10;# comparación de accuracy&#10;numeric_results = results_df[results_df['AUC'] != 'N/A'].copy()&#10;numeric_results['AUC'] = pd.to_numeric(numeric_results['AUC'])&#10;&#10;axes[0].barh(numeric_results['Modelo'], numeric_results['Accuracy'], alpha=0.8)&#10;axes[0].set_title('comparación de Accuracy', fontsize=14, pad=20)&#10;axes[0].set_xlabel('Accuracy')&#10;axes[0].grid(True, alpha=0.3, axis='x')&#10;&#10;# comparación de AUC&#10;axes[1].barh(numeric_results['Modelo'], numeric_results['AUC'], alpha=0.8, color='orange')&#10;axes[1].set_title('comparación de AUC', fontsize=14, pad=20)&#10;axes[1].set_xlabel('AUC')&#10;axes[1].grid(True, alpha=0.3, axis='x')&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10; ###  Ensemble de Modelos&#10;&#10;#%%&#10;# crear ensemble con los mejores modelos&#10;top_models = [&#10;    ('xgb', best_model),&#10;    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)),&#10;    ('gb', GradientBoostingClassifier(n_estimators=200, max_depth=8, random_state=42))&#10;]&#10;&#10;ensemble = VotingClassifier(estimators=top_models, voting='soft')&#10;ensemble.fit(X_train, y_train)&#10;&#10;y_pred_ensemble = ensemble.predict(X_test)&#10;y_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]&#10;&#10;acc_ensemble = accuracy_score(y_test, y_pred_ensemble)&#10;auc_ensemble = roc_auc_score(y_test, y_proba_ensemble)&#10;&#10;print(f&quot;ensemble - Accuracy: {acc_ensemble:.4f}, AUC: {auc_ensemble:.4f}&quot;)&#10;print(f&quot;mejora sobre mejor modelo individual: +{acc_ensemble - acc_optimized:.4f}&quot;)&#10;&#10;#%% md&#10;## 5.  Análisis de Features e Interpretabilidad&#10;&#10;#%%&#10;# importancia de features&#10;importances = best_model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': available_features,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;# visualización de importancia&#10;plt.figure(figsize=(12, 8))&#10;top_features = feature_importance_df.head(12)&#10;sns.barplot(data=top_features, x='Importance', y='Feature', palette='viridis')&#10;plt.title('importancia de features en el modelo optimizado', fontsize=16, pad=20)&#10;plt.xlabel('Importancia Relativa')&#10;plt.ylabel('Feature')&#10;plt.grid(True, alpha=0.3, axis='x')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;print(&quot;top 10 Features más importantes:&quot;)&#10;print(feature_importance_df.head(18).round(4))&#10;&#10;# análisis de distribución de importancia&#10;cumulative_importance = feature_importance_df['Importance'].cumsum()&#10;n_features_80 = (cumulative_importance &lt;= 0.8).sum() + 1&#10;n_features_95 = (cumulative_importance &lt;= 0.95).sum() + 1&#10;&#10;print(f&quot;análisis de concentración:&quot;)&#10;print(f&quot;   {n_features_80} features explican el 80% de la importancia&quot;)&#10;print(f&quot;   {n_features_95} features explican el 95% de la importancia&quot;)&#10;&#10;#%% md&#10;### Análisis de Errores del Modelo&#10;&#10;#%%&#10;# análisis detallado de errores&#10;df_test_analysis = df_test_balanced.copy()&#10;df_test_analysis['pred'] = y_pred_optimized&#10;df_test_analysis['pred_proba'] = y_proba_optimized&#10;df_test_analysis['correct'] = (df_test_analysis['pred'] == df_test_analysis['target'])&#10;&#10;# estadísticas de errores&#10;total_errors = (~df_test_analysis['correct']).sum()&#10;error_rate = total_errors / len(df_test_analysis)&#10;&#10;print(f&quot;análisis de errores:&quot;)&#10;print(f&quot;   total errores: {total_errors:,} de {len(df_test_analysis):,} ({error_rate:.2%})&quot;)&#10;&#10;# tipos de errores&#10;false_positives = len(df_test_analysis[(df_test_analysis['target'] == 0) &amp; (df_test_analysis['pred'] == 1)])&#10;false_negatives = len(df_test_analysis[(df_test_analysis['target'] == 1) &amp; (df_test_analysis['pred'] == 0)])&#10;&#10;print(f&quot;   falsos positivos: {false_positives:,}&quot;)&#10;print(f&quot;   falsos negativos: {false_negatives:,}&quot;)&#10;&#10;# análisis por confianza de predicción&#10;confidence_bins = pd.cut(df_test_analysis['pred_proba'], bins=[0, 0.3, 0.7, 1.0], labels=['Baja', 'Media', 'Alta'])&#10;confidence_accuracy = df_test_analysis.groupby(confidence_bins)['correct'].agg(['count', 'mean']).round(4)&#10;&#10;print(f&quot;accuracy por nivel de confianza:&quot;)&#10;print(confidence_accuracy)&#10;&#10;# matriz de confusión mejorada&#10;plt.figure(figsize=(8, 6))&#10;cm = confusion_matrix(y_test, y_pred_optimized)&#10;sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',&#10;           xticklabels=['Perdedor Predicho', 'Ganador Predicho'],&#10;           yticklabels=['Perdedor Real', 'Ganador Real'])&#10;plt.title('matriz de confusión del modelo optimizado', fontsize=14, pad=20)&#10;plt.ylabel('Valor Real')&#10;plt.xlabel('Predicción')&#10;plt.tight_layout()&#10;plt.show()&#10;&#10;#%% md&#10;## 6. Resumen Ejecutivo y Conclusiones&#10;&#10;#%%&#10;# resumen final del proyecto&#10;print(&quot;=&quot; * 80)&#10;print(&quot;resumen ejecutivo - tennis match predictor&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;print(f&quot;\ndatos procesados:&quot;)&#10;print(f&quot;   período de entrenamiento: {df_train['tourney_date'].dt.year.min()}-{df_train['tourney_date'].dt.year.max()}&quot;)&#10;print(f&quot;   período de test: {df_test['tourney_date'].dt.year.min()}-{df_test['tourney_date'].dt.year.max()}&quot;)&#10;print(f&quot;   total partidos analizados: {len(df_train) + len(df_test):,}&quot;)&#10;print(f&quot;   features engineered: {len(available_features)}&quot;)&#10;&#10;print(f&quot;\nrendimiento del modelo:&quot;)&#10;print(f&quot;   mejor modelo: XGBoost optimizado&quot;)&#10;print(f&quot;   accuracy: {acc_optimized:.4f} ({acc_optimized:.1%})&quot;)&#10;print(f&quot;   AUC: {auc_optimized:.4f}&quot;)&#10;print(f&quot;   ensemble accuracy: {acc_ensemble:.4f} ({(acc_ensemble-acc_optimized)*100:+.2f}% mejora)&quot;)&#10;&#10;print(f&quot;\nfeatures más importantes:&quot;)&#10;top_5_features = feature_importance_df.head(5)&#10;for idx, row in top_5_features.iterrows():&#10;    print(f&quot;   {idx+1}. {row['Feature']}: {row['Importance']:.3f} ({row['Importance']:.1%})&quot;)&#10;&#10;print(f&quot;\ninsights clave:&quot;)&#10;print(f&quot;   las features categóricas (elo_advantage, tier_diff) son más predictivas&quot;)&#10;print(f&quot;   el ranking ATP es más informativo que el ELO calculado&quot;)&#10;print(f&quot;   el H2H tiene impacto mínimo en predicciones generales&quot;)&#10;print(f&quot;   los Big 3 muestran patrones únicos de dominancia por superficie&quot;)&#10;print(f&quot;   el modelo es altamente preciso (~99%) para datos históricos&quot;)&#10;&#10;print(f&quot;\nrecomendaciones:&quot;)&#10;print(f&quot;   usar XGBoost optimizado para predicciones en producción&quot;)&#10;print(f&quot;   enfocar feature engineering en rankings y diferencias de nivel&quot;)&#10;print(f&quot;   considerar factores temporales para predicciones futuras&quot;)&#10;print(f&quot;   validar con datos de torneos 2025 cuando estén disponibles&quot;)&#10;&#10;print(f&quot;\naplicaciones:&quot;)&#10;print(f&quot;   sistema de predicción en tiempo real&quot;)&#10;print(f&quot;   análisis para casas de apuestas&quot;)&#10;print(f&quot;   comentarios deportivos automatizados&quot;)&#10;print(f&quot;   análisis estratégico para jugadores/entrenadores&quot;)&#10;&#10;print(&quot;=&quot; * 80)&#10;print(&quot;¡proyecto completado exitosamente!&quot;)&#10;print(&quot;=&quot; * 80)&#10;&#10;#%% md&#10;##  Información Técnica&#10;&#10;** Stack Tecnológico:**&#10;- **Python 3.11+** con pandas, scikit-learn, XGBoost&#10;- **Feature Engineering**: ELO ratings, surface specialization, ranking analysis&#10;- **Machine Learning**: Ensemble methods, hyperparameter optimization&#10;- **Visualization**: matplotlib, seaborn&#10;&#10;** Metodología:**&#10;1. **Data Engineering**: Limpieza y unificación de 55+ años de datos&#10;2. **Feature Engineering**: Creación de 20+ features predictivas avanzadas&#10;3. **Model Development**: Grid search + ensemble de múltiples algoritmos&#10;4. **Validation**: Split temporal (train: 1968-2022, test: 2023-2024)&#10;&#10;** Resultados Clave:**&#10;- **99%+ accuracy** en predicción de ganadores&#10;- **Modelo interpretable** con features claras y significativas&#10;- **Pipeline escalable** para integración en producción&#10;- **Análisis histórico** de la evolución del tenis profesional&#10;&#10;---&#10;*Desarrollado con pasión para el análisis predictivo del tenis profesional*&#10;&#10;#%% md&#10;# Evaluación del modelo en el Australian Open 2025&#10;En este apartado se evalúa el rendimiento del modelo sobre los partidos del Australian Open 2025 usando el archivo `features_ausopen2025.csv`. Se calcula el número de aciertos, fallos y métricas básicas de predicción.&#10;#%%&#10;# En vez de cargar el modelo, usar el modelo entrenado en el notebook (best_model o ensemble)&#10;# Puedes elegir cuál usar: best_model (XGBoost optimizado) o ensemble (votación de varios modelos)&#10;model = best_model  # O usa ensemble si prefieres&#10;&#10;# Cargar features del Australian Open 2025 y preparar para predicción&#10;import pandas as pd&#10;from utils import make_dual_rows  # Importar la función correcta desde utils&#10;&#10;df_ausopen = pd.read_csv('../data/processed/features_ausopen2025.csv')&#10;&#10;# Si tu modelo requiere duplicar los partidos (winner/loser y loser/winner)&#10;if 'make_dual_rows' in globals():&#10;    df_ausopen = make_dual_rows(df_ausopen)&#10;&#10;# Mostrar un resumen de los datos&#10;print(f&quot;Partidos en el Australian Open 2025: {len(df_ausopen)}&quot;)&#10;df_ausopen.head()&#10;&#10;# Usar la lista de features clave definida antes (key_features)&#10;feature_cols = key_features&#10;&#10;# Añadir columnas que falten con 0 para asegurar consistencia&#10;for col in feature_cols:&#10;    if col not in df_ausopen.columns:&#10;        df_ausopen[col] = 0&#10;&#10;X_ausopen = df_ausopen[feature_cols]&#10;&#10;# Definir y_true correctamente usando la columna 'target' generada por make_dual_rows&#10;y_true = df_ausopen['target'].values&#10;&#10;probs = model.predict_proba(X_ausopen)[:, 1]&#10;preds = (probs &gt; 0.5).astype(int)&#10;&#10;# Calcular métricas&#10;aciertos = (preds == y_true).sum()&#10;fallos = (preds != y_true).sum()&#10;accuracy = aciertos / len(y_true)&#10;&#10;print(f&quot;Aciertos: {aciertos}&quot;)&#10;print(f&quot;Fallos: {fallos}&quot;)&#10;print(f&quot;Accuracy: {accuracy:.2%}&quot;)&#10;&#10;&#10;#%%&#10;# Matriz de confusión y resumen visual&#10;from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay&#10;import matplotlib.pyplot as plt&#10;&#10;cm = confusion_matrix(y_true, preds)&#10;disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[&quot;Fallos&quot;, &quot;Aciertos&quot;])&#10;disp.plot(cmap=plt.cm.Blues)&#10;plt.title(&quot;Matriz de confusión - Australian Open 2025&quot;)&#10;plt.show()&#10;&#10;#%%" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/regenerate_features.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/regenerate_features.py" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;# Regenerar features con H2H balanceado&#10;&#10;import sys&#10;import os&#10;sys.path.append('C:\\Users\\pepeg\\PycharmProjects\\PythonProject\\src')&#10;&#10;from data_loader import load_train_data, load_test_data, BASE_DIR&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;# Regenerar features de entrenamiento&#10;print(&quot; Regenerando features de entrenamiento...&quot;)&#10;df_train = load_train_data()&#10;df_train = clean_data(df_train)&#10;df_train = add_all_features(df_train)&#10;&#10;output_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;)&#10;os.makedirs(output_path, exist_ok=True)&#10;df_train.to_csv(os.path.join(output_path, &quot;features_train.csv&quot;), index=False)&#10;print(&quot;✅ Features de entrenamiento guardadas&quot;)&#10;&#10;# Regenerar features de test&#10;print(&quot; Regenerando features de test...&quot;)&#10;df_test = load_test_data()&#10;df_test = clean_data(df_test)&#10;df_test = add_all_features(df_test)&#10;df_test.to_csv(os.path.join(output_path, &quot;features_test.csv&quot;), index=False)&#10;print(&quot;✅ Features de test guardadas&quot;)&#10;&#10;print(&quot; Regeneración completa!&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/australian_open_2025_simulator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/australian_open_2025_simulator.py" />
              <option name="originalContent" value="# src/australian_open_2025_simulator.py&#10;&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;from data_loader import BASE_DIR, load_train_data&#10;from preprocess import clean_data&#10;from features import add_all_features, compute_elo_ratings, compute_surface_elo, compute_h2h&#10;from utils import make_dual_rows, fillna_features&#10;from model import train_model&#10;import pickle&#10;from collections import defaultdict&#10;&#10;# simulador completo del australian open 2025 que usa datos históricos&#10;&#10;def extract_historical_elos_and_h2h():&#10;    &quot;&quot;&quot;extrae los elos finales y historial h2h de todos los datos de entrenamiento&quot;&quot;&quot;&#10;    print(&quot;extrayendo elos y h2h históricos...&quot;)&#10;&#10;    # cargar todos los datos históricos&#10;    df_historical = load_train_data()&#10;    df_historical = clean_data(df_historical)&#10;&#10;    # calcular elos progresivamente en todo el dataset histórico&#10;    df_with_features = add_all_features(df_historical)&#10;&#10;    # extraer elos finales de cada jugador&#10;    final_elos = {}&#10;    final_surface_elos = {}&#10;&#10;    # obtener el último elo de cada jugador&#10;    for _, row in df_with_features.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;&#10;        final_elos[winner] = row[&quot;elo_winner&quot;]&#10;        final_elos[loser] = row[&quot;elo_loser&quot;]&#10;&#10;        # elos de superficie&#10;        surface = row.get(&quot;surface&quot;, &quot;Hard&quot;)&#10;        final_surface_elos[f&quot;{winner}_{surface}&quot;] = row[&quot;surface_elo_winner&quot;]&#10;        final_surface_elos[f&quot;{loser}_{surface}&quot;] = row[&quot;surface_elo_loser&quot;]&#10;&#10;    # extraer historial h2h completo&#10;    h2h_history = defaultdict(lambda: {&quot;count&quot;: 0, &quot;winner_wins&quot;: 0})&#10;&#10;    for _, row in df_historical.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;        pair = tuple(sorted([winner, loser]))&#10;&#10;        h2h_history[pair][&quot;count&quot;] += 1&#10;        # contar victorias del ganador&#10;        if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;            h2h_history[pair][&quot;winner_wins&quot;] += 1&#10;&#10;    print(f&quot;elos extraídos: {len(final_elos)} jugadores&quot;)&#10;    print(f&quot;h2h extraído: {len(h2h_history)} pares&quot;)&#10;&#10;    return final_elos, final_surface_elos, h2h_history&#10;&#10;def create_ao_2025_r32():&#10;    &quot;&quot;&quot;crea el dataframe base con los partidos de R32 del australian open 2025&quot;&quot;&quot;&#10;&#10;    # emparejamientos reales de la R32 (puedes actualizar con los datos reales)&#10;    r32_matches = [&#10;        # cuarto superior&#10;        {&quot;player1&quot;: &quot;Jannik Sinner&quot;, &quot;player2&quot;: &quot;Nicolas Jarry&quot;},&#10;        {&quot;player1&quot;: &quot;Daniil Medvedev&quot;, &quot;player2&quot;: &quot;Learner Tien&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Zverev&quot;, &quot;player2&quot;: &quot;Ugo Humbert&quot;},&#10;        {&quot;player1&quot;: &quot;Carlos Alcaraz&quot;, &quot;player2&quot;: &quot;Jack Draper&quot;},&#10;        {&quot;player1&quot;: &quot;Tommy Paul&quot;, &quot;player2&quot;: &quot;Alejandro Davidovich Fokina&quot;},&#10;        {&quot;player1&quot;: &quot;Ben Shelton&quot;, &quot;player2&quot;: &quot;Lorenzo Musetti&quot;},&#10;        {&quot;player1&quot;: &quot;Novak Djokovic&quot;, &quot;player2&quot;: &quot;Jiri Lehecka&quot;},&#10;        {&quot;player1&quot;: &quot;Taylor Fritz&quot;, &quot;player2&quot;: &quot;Gael Monfils&quot;},&#10;&#10;        # cuarto medio-superior&#10;        {&quot;player1&quot;: &quot;Casper Ruud&quot;, &quot;player2&quot;: &quot;Jenson Brooksby&quot;},&#10;        {&quot;player1&quot;: &quot;Alex de Minaur&quot;, &quot;player2&quot;: &quot;Alex Michelsen&quot;},&#10;        {&quot;player1&quot;: &quot;Stefanos Tsitsipas&quot;, &quot;player2&quot;: &quot;Thanasi Kokkinakis&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Korda&quot;, &quot;player2&quot;: &quot;Corentin Moutet&quot;},&#10;        {&quot;player1&quot;: &quot;Hubert Hurkacz&quot;, &quot;player2&quot;: &quot;Arthur Fils&quot;},&#10;        {&quot;player1&quot;: &quot;Frances Tiafoe&quot;, &quot;player2&quot;: &quot;Fabian Marozsan&quot;},&#10;        {&quot;player1&quot;: &quot;Grigor Dimitrov&quot;, &quot;player2&quot;: &quot;Rinky Hijikata&quot;},&#10;        {&quot;player1&quot;: &quot;Andrey Rublev&quot;, &quot;player2&quot;: &quot;Jakub Mensik&quot;},&#10;&#10;        # cuarto medio-inferior&#10;        {&quot;player1&quot;: &quot;Holger Rune&quot;, &quot;player2&quot;: &quot;Matteo Berrettini&quot;},&#10;        {&quot;player1&quot;: &quot;Lorenzo Sonego&quot;, &quot;player2&quot;: &quot;Facundo Diaz Acosta&quot;},&#10;        {&quot;player1&quot;: &quot;Felix Auger-Aliassime&quot;, &quot;player2&quot;: &quot;Botic van de Zandschulp&quot;},&#10;        {&quot;player1&quot;: &quot;Karen Khachanov&quot;, &quot;player2&quot;: &quot;Giovanni Mpetshi Perricard&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Baez&quot;, &quot;player2&quot;: &quot;Pavel Kotov&quot;},&#10;        {&quot;player1&quot;: &quot;Jordan Thompson&quot;, &quot;player2&quot;: &quot;Adrian Mannarino&quot;},&#10;        {&quot;player1&quot;: &quot;Francisco Cerundolo&quot;, &quot;player2&quot;: &quot;Tomas Martin Etcheverry&quot;},&#10;        {&quot;player1&quot;: &quot;Flavio Cobolli&quot;, &quot;player2&quot;: &quot;James Duckworth&quot;},&#10;&#10;        # cuarto inferior&#10;        {&quot;player1&quot;: &quot;Alexei Popyrin&quot;, &quot;player2&quot;: &quot;Marcos Giron&quot;},&#10;        {&quot;player1&quot;: &quot;Matteo Arnaldi&quot;, &quot;player2&quot;: &quot;Zhang Yifan&quot;},&#10;        {&quot;player1&quot;: &quot;Cameron Norrie&quot;, &quot;player2&quot;: &quot;Yoshihito Nishioka&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Bublik&quot;, &quot;player2&quot;: &quot;Brandon Nakashima&quot;},&#10;        {&quot;player1&quot;: &quot;Arthur Cazaux&quot;, &quot;player2&quot;: &quot;Nuno Borges&quot;},&#10;        {&quot;player1&quot;: &quot;Daniel Evans&quot;, &quot;player2&quot;: &quot;Quentin Halys&quot;},&#10;        {&quot;player1&quot;: &quot;Roman Safiullin&quot;, &quot;player2&quot;: &quot;Roberto Carballes Baena&quot;},&#10;        {&quot;player1&quot;: &quot;Mariano Navone&quot;, &quot;player2&quot;: &quot;Christopher O'Connell&quot;}&#10;    ]&#10;&#10;    # crear dataframe base&#10;    matches = []&#10;    for i, match in enumerate(r32_matches):&#10;        # crear fila base para cada partido&#10;        row = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,  # fecha estimada&#10;            &quot;match_num&quot;: i + 1,&#10;            &quot;winner_name&quot;: match[&quot;player1&quot;],  # placeholder, se determinará por predicción&#10;            &quot;loser_name&quot;: match[&quot;player2&quot;],   # placeholder&#10;            &quot;round&quot;: &quot;R32&quot;,&#10;            &quot;best_of&quot;: 5,&#10;            &quot;score&quot;: None,&#10;            &quot;minutes&quot;: None&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;]:&#10;            row[col] = None&#10;&#10;        matches.append(row)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def load_trained_model():&#10;    &quot;&quot;&quot;carga el modelo entrenado o entrena uno nuevo&quot;&quot;&quot;&#10;    model_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;trained_model.pkl&quot;)&#10;&#10;    if os.path.exists(model_path):&#10;        print(&quot;cargando modelo preentrenado...&quot;)&#10;        with open(model_path, 'rb') as f:&#10;            model = pickle.load(f)&#10;&#10;        # obtener las features exactas que usa el modelo&#10;        if hasattr(model, 'feature_names_in_'):&#10;            model_features = list(model.feature_names_in_)&#10;            print(f&quot;modelo entrenado con features: {model_features}&quot;)&#10;            return model, model_features&#10;        else:&#10;            # fallback a features por defecto&#10;            default_features = [&#10;                &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;                &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;                &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;                &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;                &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;                &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;                &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;            ]&#10;            return model, default_features&#10;    else:&#10;        print(&quot;entrenando nuevo modelo...&quot;)&#10;        # cargar datos de entrenamiento&#10;        features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;        df_train = pd.read_csv(features_train_path)&#10;        df_train = make_dual_rows(df_train)&#10;&#10;        feature_cols = [&#10;            &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;            &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;            &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;            &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,&#10;            &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;            &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;            &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;            &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;        ]&#10;&#10;        # filtrar features disponibles&#10;        available_features = [col for col in feature_cols if col in df_train.columns]&#10;        df_train = fillna_features(df_train, available_features)&#10;&#10;        X_train = df_train[available_features]&#10;        y_train = df_train[&quot;target&quot;]&#10;&#10;        model, _ = train_model(X_train, y_train)&#10;&#10;        # guardar modelo&#10;        os.makedirs(os.path.dirname(model_path), exist_ok=True)&#10;        with open(model_path, 'wb') as f:&#10;            pickle.dump(model, f)&#10;&#10;        return model, available_features&#10;&#10;def predict_match_winner(df_match, model, feature_cols):&#10;    &quot;&quot;&quot;predice el ganador de un partido específico&quot;&quot;&quot;&#10;&#10;    # generar features&#10;    df_processed = clean_data(df_match.copy())&#10;    df_features = add_all_features(df_processed)&#10;&#10;    # crear ambas versiones del partido (A vs B y B vs A)&#10;    df_balanced = make_dual_rows(df_features)&#10;    df_balanced = fillna_features(df_balanced, feature_cols)&#10;&#10;    # solo usar la primera fila (player1 como ganador)&#10;    X = df_balanced.iloc[[0]][feature_cols]&#10;&#10;    # predecir probabilidad&#10;    prob = model.predict_proba(X)[0][1]  # probabilidad de que player1 gane&#10;&#10;    # determinar ganador&#10;    if prob &gt; 0.5:&#10;        winner = df_match.iloc[0][&quot;winner_name&quot;]&#10;        loser = df_match.iloc[0][&quot;loser_name&quot;]&#10;        confidence = prob&#10;    else:&#10;        winner = df_match.iloc[0][&quot;loser_name&quot;]&#10;        loser = df_match.iloc[0][&quot;winner_name&quot;]&#10;        confidence = 1 - prob&#10;&#10;    return winner, loser, confidence&#10;&#10;def predict_match_winner_with_history(df_match, model, feature_cols,&#10;                                    current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;predice el ganador usando elos y h2h históricos actualizados&quot;&quot;&quot;&#10;&#10;    # obtener nombres de jugadores&#10;    player1 = df_match.iloc[0][&quot;winner_name&quot;]&#10;    player2 = df_match.iloc[0][&quot;loser_name&quot;]&#10;    surface = df_match.iloc[0][&quot;surface&quot;]&#10;&#10;    # obtener elos actuales (o por defecto si es jugador nuevo)&#10;    elo1 = current_elos.get(player1, 1500)&#10;    elo2 = current_elos.get(player2, 1500)&#10;&#10;    surface_elo1 = current_surface_elos.get(f&quot;{player1}_{surface}&quot;, 1500)&#10;    surface_elo2 = current_surface_elos.get(f&quot;{player2}_{surface}&quot;, 1500)&#10;&#10;    # obtener h2h actual&#10;    pair = tuple(sorted([player1, player2]))&#10;    h2h_data = current_h2h[pair]&#10;&#10;    # probar ambas configuraciones: player1 como ganador Y player2 como ganador&#10;    # y elegir la que tenga mayor probabilidad&#10;&#10;    configs = [&#10;        {&#10;            &quot;winner&quot;: player1, &quot;loser&quot;: player2,&#10;            &quot;elo_winner&quot;: elo1, &quot;elo_loser&quot;: elo2,&#10;            &quot;surface_elo_winner&quot;: surface_elo1, &quot;surface_elo_loser&quot;: surface_elo2&#10;        },&#10;        {&#10;            &quot;winner&quot;: player2, &quot;loser&quot;: player1,&#10;            &quot;elo_winner&quot;: elo2, &quot;elo_loser&quot;: elo1,&#10;            &quot;surface_elo_winner&quot;: surface_elo2, &quot;surface_elo_loser&quot;: surface_elo1&#10;        }&#10;    ]&#10;&#10;    best_prob = 0&#10;    best_winner = None&#10;    best_loser = None&#10;&#10;    for config in configs:&#10;        # calcular features para esta configuración&#10;        features_dict = {&#10;            &quot;elo_winner&quot;: config[&quot;elo_winner&quot;],&#10;            &quot;elo_loser&quot;: config[&quot;elo_loser&quot;],&#10;            &quot;elo_diff&quot;: config[&quot;elo_winner&quot;] - config[&quot;elo_loser&quot;],&#10;            &quot;surface_elo_winner&quot;: config[&quot;surface_elo_winner&quot;],&#10;            &quot;surface_elo_loser&quot;: config[&quot;surface_elo_loser&quot;],&#10;            &quot;surface_elo_diff&quot;: config[&quot;surface_elo_winner&quot;] - config[&quot;surface_elo_loser&quot;],&#10;        }&#10;&#10;        # features categóricas&#10;        elo_diff = config[&quot;elo_winner&quot;] - config[&quot;elo_loser&quot;]&#10;        features_dict[&quot;elo_advantage&quot;] = (2 if elo_diff &gt; 200 else&#10;                                        (1 if elo_diff &gt; 50 else&#10;                                        (-1 if elo_diff &lt; -50 else&#10;                                        (-2 if elo_diff &lt; -200 else 0))))&#10;&#10;        surface_elo_diff = config[&quot;surface_elo_winner&quot;] - config[&quot;surface_elo_loser&quot;]&#10;        features_dict[&quot;surface_elo_advantage&quot;] = (2 if surface_elo_diff &gt; 200 else&#10;                                                (1 if surface_elo_diff &gt; 50 else&#10;                                                (-1 if surface_elo_diff &lt; -50 else&#10;                                                (-2 if surface_elo_diff &lt; -200 else 0))))&#10;&#10;        # features de interacción&#10;        features_dict[&quot;elo_surface_interaction&quot;] = elo_diff * surface_elo_diff / 10000&#10;        features_dict[&quot;elo_consistency&quot;] = abs(elo_diff - surface_elo_diff)&#10;&#10;        # features de ranking (usar valores por defecto)&#10;        features_dict.update({&#10;            &quot;rank_diff&quot;: 0,&#10;            &quot;rank_advantage&quot;: 0,&#10;            &quot;rank_ratio&quot;: 1,&#10;            &quot;elo_rank_mismatch&quot;: 0&#10;        })&#10;&#10;        # features de tiers&#10;        def get_tier(elo):&#10;            if elo &lt; 1400: return 0&#10;            elif elo &lt; 1600: return 1&#10;            elif elo &lt; 1800: return 2&#10;            elif elo &lt; 2000: return 3&#10;            else: return 4&#10;&#10;        tier_winner = get_tier(config[&quot;elo_winner&quot;])&#10;        tier_loser = get_tier(config[&quot;elo_loser&quot;])&#10;        features_dict.update({&#10;            &quot;elo_tier_winner&quot;: tier_winner,&#10;            &quot;elo_tier_loser&quot;: tier_loser,&#10;            &quot;tier_diff&quot;: tier_winner - tier_loser&#10;        })&#10;&#10;        # features de competitividad&#10;        features_dict[&quot;match_competitiveness&quot;] = 1 / (1 + abs(elo_diff) / 100)&#10;        features_dict[&quot;is_upset_potential&quot;] = int(abs(elo_diff) &gt; 150)&#10;&#10;        # features h2h logarítmicas&#10;        h2h_count = h2h_data[&quot;count&quot;]&#10;        features_dict[&quot;h2h_count&quot;] = np.log1p(h2h_count)&#10;&#10;        if h2h_count == 0:&#10;            features_dict[&quot;h2h_balance&quot;] = 0&#10;        else:&#10;            winner_wins = h2h_data[&quot;winner_wins&quot;]&#10;            loser_wins = h2h_count - winner_wins&#10;&#10;            # determinar quién es quién en el historial&#10;            if config[&quot;winner&quot;] == min(pair):  # winner es el primero alfabéticamente&#10;                w_wins = winner_wins&#10;                l_wins = loser_wins&#10;            else:&#10;                w_wins = loser_wins&#10;                l_wins = winner_wins&#10;&#10;            features_dict[&quot;h2h_balance&quot;] = np.log1p(w_wins) - np.log1p(l_wins)&#10;&#10;        # crear dataframe con las features&#10;        feature_values = [features_dict.get(col, 0) for col in feature_cols]&#10;        X = pd.DataFrame([feature_values], columns=feature_cols)&#10;&#10;        # predecir probabilidad&#10;        prob = model.predict_proba(X)[0][1]&#10;&#10;        # si esta configuración es mejor, guardarla&#10;        if prob &gt; best_prob:&#10;            best_prob = prob&#10;            best_winner = config[&quot;winner&quot;]&#10;            best_loser = config[&quot;loser&quot;]&#10;&#10;    return best_winner, best_loser, best_prob&#10;&#10;def simulate_tournament_round(matches_df, model, feature_cols, round_name):&#10;    &quot;&quot;&quot;simula una ronda completa del torneo&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # predecir ganador&#10;        winner, loser, confidence = predict_match_winner(match_df, model, feature_cols)&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{match['winner_name']} vs {match['loser_name']}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence&#10;        }&#10;        results.append(result)&#10;&#10;        print(f&quot;  {match['winner_name']} vs {match['loser_name']} → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def simulate_tournament_round_with_history(matches_df, model, feature_cols, round_name,&#10;                                         current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;simula una ronda completa usando historial actualizado&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # obtener elos actuales para mostrar&#10;        player1 = match['winner_name']&#10;        player2 = match['loser_name']&#10;        elo1 = current_elos.get(player1, 1500)&#10;        elo2 = current_elos.get(player2, 1500)&#10;&#10;        # predecir ganador usando historial&#10;        winner, loser, confidence = predict_match_winner_with_history(&#10;            match_df, model, feature_cols, current_elos, current_surface_elos, current_h2h&#10;        )&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{player1} vs {player2}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence,&#10;            &quot;elo_player1&quot;: elo1,&#10;            &quot;elo_player2&quot;: elo2&#10;        }&#10;        results.append(result)&#10;&#10;        # actualizar elos y h2h después del partido&#10;        surface = match[&quot;surface&quot;]&#10;        update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos)&#10;        update_h2h_after_match(winner, loser, current_h2h)&#10;&#10;        print(f&quot;  {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f}) → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def create_next_round_matches(winners, round_name):&#10;    &quot;&quot;&quot;crea los emparejamientos de la siguiente ronda&quot;&quot;&quot;&#10;&#10;    if len(winners) % 2 != 0:&#10;        raise ValueError(f&quot;número impar de ganadores: {len(winners)}&quot;)&#10;&#10;    matches = []&#10;    for i in range(0, len(winners), 2):&#10;        match = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,&#10;            &quot;match_num&quot;: i//2 + 1,&#10;            &quot;winner_name&quot;: winners[i],&#10;            &quot;loser_name&quot;: winners[i+1],&#10;            &quot;round&quot;: round_name,&#10;            &quot;best_of&quot;: 5&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;, &quot;score&quot;, &quot;minutes&quot;]:&#10;            match[col] = None&#10;&#10;        matches.append(match)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos, k=32):&#10;    &quot;&quot;&quot;actualiza los elos después de un partido&quot;&quot;&quot;&#10;&#10;    # elos actuales&#10;    elo_w = current_elos.get(winner, 1500)&#10;    elo_l = current_elos.get(loser, 1500)&#10;&#10;    surface_elo_w = current_surface_elos.get(f&quot;{winner}_{surface}&quot;, 1500)&#10;    surface_elo_l = current_surface_elos.get(f&quot;{loser}_{surface}&quot;, 1500)&#10;&#10;    # actualizar elo global&#10;    expected_w = 1 / (1 + 10 ** ((elo_l - elo_w) / 400))&#10;    current_elos[winner] = elo_w + k * (1 - expected_w)&#10;    current_elos[loser] = elo_l + k * (0 - (1 - expected_w))&#10;&#10;    # actualizar elo de superficie&#10;    surface_expected_w = 1 / (1 + 10 ** ((surface_elo_l - surface_elo_w) / 400))&#10;    current_surface_elos[f&quot;{winner}_{surface}&quot;] = surface_elo_w + k * (1 - surface_expected_w)&#10;    current_surface_elos[f&quot;{loser}_{surface}&quot;] = surface_elo_l + k * (0 - (1 - surface_expected_w))&#10;&#10;def update_h2h_after_match(winner, loser, current_h2h):&#10;    &quot;&quot;&quot;actualiza el historial h2h después de un partido&quot;&quot;&quot;&#10;    pair = tuple(sorted([winner, loser]))&#10;    current_h2h[pair][&quot;count&quot;] += 1&#10;&#10;    # incrementar victorias del ganador&#10;    if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;        current_h2h[pair][&quot;winner_wins&quot;] += 1&#10;&#10;def simulate_australian_open_2025():&#10;    &quot;&quot;&quot;simula el torneo completo del australian open 2025 usando datos históricos&quot;&quot;&quot;&#10;&#10;    print(&quot;=== simulador australian open 2025 con datos históricos ===&quot;)&#10;&#10;    # extraer elos y h2h históricos del dataset de entrenamiento&#10;    current_elos, current_surface_elos, current_h2h = extract_historical_elos_and_h2h()&#10;&#10;    # cargar modelo entrenado y obtener sus features exactas&#10;    model, feature_cols = load_trained_model()&#10;&#10;    print(f&quot;usando features del modelo: {feature_cols}&quot;)&#10;&#10;    # generar R32&#10;    r32_df = create_ao_2025_r32()&#10;&#10;    # simular cada ronda con historial actualizado&#10;    all_results = []&#10;&#10;    # R32 (32 → 16)&#10;    r16_winners, r32_results = simulate_tournament_round_with_history(&#10;        r32_df, model, feature_cols, &quot;R32&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r32_results)&#10;&#10;    # R16 (16 → 8)&#10;    r16_df = create_next_round_matches(r16_winners, &quot;R16&quot;)&#10;    qf_winners, r16_results = simulate_tournament_round_with_history(&#10;        r16_df, model, feature_cols, &quot;R16&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r16_results)&#10;&#10;    # cuartos de final (8 → 4)&#10;    qf_df = create_next_round_matches(qf_winners, &quot;QF&quot;)&#10;    sf_winners, qf_results = simulate_tournament_round_with_history(&#10;        qf_df, model, feature_cols, &quot;QF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(qf_results)&#10;&#10;    # semifinales (4 → 2)&#10;    sf_df = create_next_round_matches(sf_winners, &quot;SF&quot;)&#10;    f_winners, sf_results = simulate_tournament_round_with_history(&#10;        sf_df, model, feature_cols, &quot;SF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(sf_results)&#10;&#10;    # final (2 → 1)&#10;    f_df = create_next_round_matches(f_winners, &quot;F&quot;)&#10;    champion, f_results = simulate_tournament_round_with_history(&#10;        f_df, model, feature_cols, &quot;F&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(f_results)&#10;&#10;    # resultados finales&#10;    print(f&quot;\ncampeón australian open 2025: {champion[0]}&quot;)&#10;    print(f&quot;finalista: {f_results[0]['loser']}&quot;)&#10;    print(f&quot;semifinalistas: {', '.join([r['loser'] for r in sf_results])}&quot;)&#10;&#10;    # mostrar algunos elos finales de jugadores top&#10;    top_players = [&quot;Jannik Sinner&quot;, &quot;Novak Djokovic&quot;, &quot;Carlos Alcaraz&quot;, &quot;Daniil Medvedev&quot;]&#10;    print(f&quot;\nelos finales después del torneo:&quot;)&#10;    for player in top_players:&#10;        if player in current_elos:&#10;            print(f&quot;  {player}: {current_elos[player]:.0f}&quot;)&#10;&#10;    # guardar resultados&#10;    results_df = pd.DataFrame(all_results)&#10;    output_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;australian_open_2025_results.csv&quot;)&#10;    os.makedirs(os.path.dirname(output_path), exist_ok=True)&#10;    results_df.to_csv(output_path, index=False)&#10;&#10;    print(f&quot;\nresultados guardados en: {output_path}&quot;)&#10;&#10;    return results_df, champion[0]&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    results, champion = simulate_australian_open_2025()&#10;    print(f&quot;\n simulación completada - campeón: {champion}&quot;)&#10;" />
              <option name="updatedContent" value="# src/australian_open_2025_simulator.py&#10;&#10;import pandas as pd&#10;import numpy as np&#10;import os&#10;from data_loader import BASE_DIR, load_train_data&#10;from preprocess import clean_data&#10;from features import add_all_features, compute_elo_ratings, compute_surface_elo, compute_h2h&#10;from utils import make_dual_rows, fillna_features&#10;from model import train_model&#10;import pickle&#10;from collections import defaultdict&#10;&#10;# simulador completo del australian open 2025 que usa datos históricos&#10;&#10;def extract_historical_elos_and_h2h():&#10;    &quot;&quot;&quot;extrae los elos finales y historial h2h de todos los datos de entrenamiento&quot;&quot;&quot;&#10;    print(&quot;extrayendo elos y h2h históricos...&quot;)&#10;&#10;    # cargar todos los datos históricos&#10;    df_historical = load_train_data()&#10;    df_historical = clean_data(df_historical)&#10;&#10;    # calcular elos progresivamente en todo el dataset histórico&#10;    df_with_features = add_all_features(df_historical)&#10;&#10;    # extraer elos finales de cada jugador&#10;    final_elos = {}&#10;    final_surface_elos = {}&#10;&#10;    # obtener el último elo de cada jugador&#10;    for _, row in df_with_features.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;&#10;        final_elos[winner] = row[&quot;elo_winner&quot;]&#10;        final_elos[loser] = row[&quot;elo_loser&quot;]&#10;&#10;        # elos de superficie&#10;        surface = row.get(&quot;surface&quot;, &quot;Hard&quot;)&#10;        final_surface_elos[f&quot;{winner}_{surface}&quot;] = row[&quot;surface_elo_winner&quot;]&#10;        final_surface_elos[f&quot;{loser}_{surface}&quot;] = row[&quot;surface_elo_loser&quot;]&#10;&#10;    # extraer historial h2h completo&#10;    h2h_history = defaultdict(lambda: {&quot;count&quot;: 0, &quot;winner_wins&quot;: 0})&#10;&#10;    for _, row in df_historical.iterrows():&#10;        winner = row[&quot;winner_name&quot;]&#10;        loser = row[&quot;loser_name&quot;]&#10;        pair = tuple(sorted([winner, loser]))&#10;&#10;        h2h_history[pair][&quot;count&quot;] += 1&#10;        # contar victorias del ganador&#10;        if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;            h2h_history[pair][&quot;winner_wins&quot;] += 1&#10;&#10;    print(f&quot;elos extraídos: {len(final_elos)} jugadores&quot;)&#10;    print(f&quot;h2h extraído: {len(h2h_history)} pares&quot;)&#10;&#10;    return final_elos, final_surface_elos, h2h_history&#10;&#10;def create_ao_2025_r32():&#10;    &quot;&quot;&quot;crea el dataframe base con los partidos de R32 del australian open 2025&quot;&quot;&quot;&#10;&#10;    # emparejamientos reales de la R32 (puedes actualizar con los datos reales)&#10;    r32_matches = [&#10;        # cuarto superior&#10;        {&quot;player1&quot;: &quot;Jannik Sinner&quot;, &quot;player2&quot;: &quot;Nicolas Jarry&quot;},&#10;        {&quot;player1&quot;: &quot;Daniil Medvedev&quot;, &quot;player2&quot;: &quot;Learner Tien&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Zverev&quot;, &quot;player2&quot;: &quot;Ugo Humbert&quot;},&#10;        {&quot;player1&quot;: &quot;Carlos Alcaraz&quot;, &quot;player2&quot;: &quot;Jack Draper&quot;},&#10;        {&quot;player1&quot;: &quot;Tommy Paul&quot;, &quot;player2&quot;: &quot;Alejandro Davidovich Fokina&quot;},&#10;        {&quot;player1&quot;: &quot;Ben Shelton&quot;, &quot;player2&quot;: &quot;Lorenzo Musetti&quot;},&#10;        {&quot;player1&quot;: &quot;Novak Djokovic&quot;, &quot;player2&quot;: &quot;Jiri Lehecka&quot;},&#10;        {&quot;player1&quot;: &quot;Taylor Fritz&quot;, &quot;player2&quot;: &quot;Gael Monfils&quot;},&#10;&#10;        # cuarto medio-superior&#10;        {&quot;player1&quot;: &quot;Casper Ruud&quot;, &quot;player2&quot;: &quot;Jenson Brooksby&quot;},&#10;        {&quot;player1&quot;: &quot;Alex de Minaur&quot;, &quot;player2&quot;: &quot;Alex Michelsen&quot;},&#10;        {&quot;player1&quot;: &quot;Stefanos Tsitsipas&quot;, &quot;player2&quot;: &quot;Thanasi Kokkinakis&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Korda&quot;, &quot;player2&quot;: &quot;Corentin Moutet&quot;},&#10;        {&quot;player1&quot;: &quot;Hubert Hurkacz&quot;, &quot;player2&quot;: &quot;Arthur Fils&quot;},&#10;        {&quot;player1&quot;: &quot;Frances Tiafoe&quot;, &quot;player2&quot;: &quot;Fabian Marozsan&quot;},&#10;        {&quot;player1&quot;: &quot;Grigor Dimitrov&quot;, &quot;player2&quot;: &quot;Rinky Hijikata&quot;},&#10;        {&quot;player1&quot;: &quot;Andrey Rublev&quot;, &quot;player2&quot;: &quot;Jakub Mensik&quot;},&#10;&#10;        # cuarto medio-inferior&#10;        {&quot;player1&quot;: &quot;Holger Rune&quot;, &quot;player2&quot;: &quot;Matteo Berrettini&quot;},&#10;        {&quot;player1&quot;: &quot;Lorenzo Sonego&quot;, &quot;player2&quot;: &quot;Facundo Diaz Acosta&quot;},&#10;        {&quot;player1&quot;: &quot;Felix Auger-Aliassime&quot;, &quot;player2&quot;: &quot;Botic van de Zandschulp&quot;},&#10;        {&quot;player1&quot;: &quot;Karen Khachanov&quot;, &quot;player2&quot;: &quot;Giovanni Mpetshi Perricard&quot;},&#10;        {&quot;player1&quot;: &quot;Sebastian Baez&quot;, &quot;player2&quot;: &quot;Pavel Kotov&quot;},&#10;        {&quot;player1&quot;: &quot;Jordan Thompson&quot;, &quot;player2&quot;: &quot;Adrian Mannarino&quot;},&#10;        {&quot;player1&quot;: &quot;Francisco Cerundolo&quot;, &quot;player2&quot;: &quot;Tomas Martin Etcheverry&quot;},&#10;        {&quot;player1&quot;: &quot;Flavio Cobolli&quot;, &quot;player2&quot;: &quot;James Duckworth&quot;},&#10;&#10;        # cuarto inferior&#10;        {&quot;player1&quot;: &quot;Alexei Popyrin&quot;, &quot;player2&quot;: &quot;Marcos Giron&quot;},&#10;        {&quot;player1&quot;: &quot;Matteo Arnaldi&quot;, &quot;player2&quot;: &quot;Zhang Yifan&quot;},&#10;        {&quot;player1&quot;: &quot;Cameron Norrie&quot;, &quot;player2&quot;: &quot;Yoshihito Nishioka&quot;},&#10;        {&quot;player1&quot;: &quot;Alexander Bublik&quot;, &quot;player2&quot;: &quot;Brandon Nakashima&quot;},&#10;        {&quot;player1&quot;: &quot;Arthur Cazaux&quot;, &quot;player2&quot;: &quot;Nuno Borges&quot;},&#10;        {&quot;player1&quot;: &quot;Daniel Evans&quot;, &quot;player2&quot;: &quot;Quentin Halys&quot;},&#10;        {&quot;player1&quot;: &quot;Roman Safiullin&quot;, &quot;player2&quot;: &quot;Roberto Carballes Baena&quot;},&#10;        {&quot;player1&quot;: &quot;Mariano Navone&quot;, &quot;player2&quot;: &quot;Christopher O'Connell&quot;}&#10;    ]&#10;&#10;    # crear dataframe base&#10;    matches = []&#10;    for i, match in enumerate(r32_matches):&#10;        # crear fila base para cada partido&#10;        row = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,  # fecha estimada&#10;            &quot;match_num&quot;: i + 1,&#10;            &quot;winner_name&quot;: match[&quot;player1&quot;],  # placeholder, se determinará por predicción&#10;            &quot;loser_name&quot;: match[&quot;player2&quot;],   # placeholder&#10;            &quot;round&quot;: &quot;R32&quot;,&#10;            &quot;best_of&quot;: 5,&#10;            &quot;score&quot;: None,&#10;            &quot;minutes&quot;: None&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;]:&#10;            row[col] = None&#10;&#10;        matches.append(row)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def load_trained_model():&#10;    &quot;&quot;&quot;carga el modelo entrenado o entrena uno nuevo&quot;&quot;&quot;&#10;    model_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;trained_model.pkl&quot;)&#10;&#10;    if os.path.exists(model_path):&#10;        print(&quot;cargando modelo preentrenado...&quot;)&#10;        with open(model_path, 'rb') as f:&#10;            model = pickle.load(f)&#10;&#10;        # obtener las features exactas que usa el modelo&#10;        if hasattr(model, 'feature_names_in_'):&#10;            model_features = list(model.feature_names_in_)&#10;            print(f&quot;modelo entrenado con features: {model_features}&quot;)&#10;            return model, model_features&#10;        else:&#10;            # fallback a features por defecto&#10;            default_features = [&#10;                &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;                &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;                &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;                &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;                &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;                &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;                &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;            ]&#10;            return model, default_features&#10;    else:&#10;        print(&quot;entrenando nuevo modelo...&quot;)&#10;        # cargar datos de entrenamiento&#10;        features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;        df_train = pd.read_csv(features_train_path)&#10;        df_train = make_dual_rows(df_train)&#10;&#10;        feature_cols = [&#10;            &quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;elo_diff&quot;,&#10;            &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;, &quot;surface_elo_diff&quot;,&#10;            &quot;elo_advantage&quot;, &quot;surface_elo_advantage&quot;,&#10;            &quot;elo_surface_interaction&quot;, &quot;elo_consistency&quot;,&#10;            &quot;rank_diff&quot;, &quot;rank_advantage&quot;, &quot;rank_ratio&quot;, &quot;elo_rank_mismatch&quot;,&#10;            &quot;elo_tier_winner&quot;, &quot;elo_tier_loser&quot;, &quot;tier_diff&quot;,&#10;            &quot;match_competitiveness&quot;, &quot;is_upset_potential&quot;,&#10;            &quot;h2h_count&quot;, &quot;h2h_balance&quot;&#10;        ]&#10;&#10;        # filtrar features disponibles&#10;        available_features = [col for col in feature_cols if col in df_train.columns]&#10;        df_train = fillna_features(df_train, available_features)&#10;&#10;        X_train = df_train[available_features]&#10;        y_train = df_train[&quot;target&quot;]&#10;&#10;        model, _ = train_model(X_train, y_train)&#10;&#10;        # guardar modelo&#10;        os.makedirs(os.path.dirname(model_path), exist_ok=True)&#10;        with open(model_path, 'wb') as f:&#10;            pickle.dump(model, f)&#10;&#10;        return model, available_features&#10;&#10;def predict_match_winner(df_match, model, feature_cols):&#10;    &quot;&quot;&quot;predice el ganador de un partido específico&quot;&quot;&quot;&#10;&#10;    # generar features&#10;    df_processed = clean_data(df_match.copy())&#10;    df_features = add_all_features(df_processed)&#10;&#10;    # crear ambas versiones del partido (A vs B y B vs A)&#10;    df_balanced = make_dual_rows(df_features)&#10;    df_balanced = fillna_features(df_balanced, feature_cols)&#10;&#10;    # solo usar la primera fila (player1 como ganador)&#10;    X = df_balanced.iloc[[0]][feature_cols]&#10;&#10;    # predecir probabilidad&#10;    prob = model.predict_proba(X)[0][1]  # probabilidad de que player1 gane&#10;&#10;    # determinar ganador&#10;    if prob &gt; 0.5:&#10;        winner = df_match.iloc[0][&quot;winner_name&quot;]&#10;        loser = df_match.iloc[0][&quot;loser_name&quot;]&#10;        confidence = prob&#10;    else:&#10;        winner = df_match.iloc[0][&quot;loser_name&quot;]&#10;        loser = df_match.iloc[0][&quot;winner_name&quot;]&#10;        confidence = 1 - prob&#10;&#10;    return winner, loser, confidence&#10;&#10;def predict_match_winner_with_history(df_match, model, feature_cols,&#10;                                    current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;predice el ganador usando elos y h2h históricos actualizados&quot;&quot;&quot;&#10;&#10;    # obtener nombres de jugadores&#10;    player1 = df_match.iloc[0][&quot;winner_name&quot;]&#10;    player2 = df_match.iloc[0][&quot;loser_name&quot;]&#10;    surface = df_match.iloc[0][&quot;surface&quot;]&#10;&#10;    # obtener elos actuales (o por defecto si es jugador nuevo)&#10;    elo1 = current_elos.get(player1, 1500)&#10;    elo2 = current_elos.get(player2, 1500)&#10;&#10;    surface_elo1 = current_surface_elos.get(f&quot;{player1}_{surface}&quot;, 1500)&#10;    surface_elo2 = current_surface_elos.get(f&quot;{player2}_{surface}&quot;, 1500)&#10;&#10;    # obtener h2h actual&#10;    pair = tuple(sorted([player1, player2]))&#10;    h2h_data = current_h2h[pair]&#10;&#10;    # calcular features manualmente para player1 como ganador&#10;    features_dict = {&#10;        &quot;elo_winner&quot;: elo1,&#10;        &quot;elo_loser&quot;: elo2,&#10;        &quot;elo_diff&quot;: elo1 - elo2,&#10;        &quot;surface_elo_winner&quot;: surface_elo1,&#10;        &quot;surface_elo_loser&quot;: surface_elo2,&#10;        &quot;surface_elo_diff&quot;: surface_elo1 - surface_elo2,&#10;    }&#10;&#10;    # features categóricas&#10;    elo_diff = elo1 - elo2&#10;    features_dict[&quot;elo_advantage&quot;] = (2 if elo_diff &gt; 200 else&#10;                                    (1 if elo_diff &gt; 50 else&#10;                                    (-1 if elo_diff &lt; -50 else&#10;                                    (-2 if elo_diff &lt; -200 else 0))))&#10;&#10;    surface_elo_diff = surface_elo1 - surface_elo2&#10;    features_dict[&quot;surface_elo_advantage&quot;] = (2 if surface_elo_diff &gt; 200 else&#10;                                            (1 if surface_elo_diff &gt; 50 else&#10;                                            (-1 if surface_elo_diff &lt; -50 else&#10;                                            (-2 if surface_elo_diff &lt; -200 else 0))))&#10;&#10;    # features de interacción&#10;    features_dict[&quot;elo_surface_interaction&quot;] = elo_diff * surface_elo_diff / 10000&#10;    features_dict[&quot;elo_consistency&quot;] = abs(elo_diff - surface_elo_diff)&#10;&#10;    # features de ranking (usar valores por defecto)&#10;    features_dict.update({&#10;        &quot;rank_diff&quot;: 0,&#10;        &quot;rank_advantage&quot;: 0,&#10;        &quot;rank_ratio&quot;: 1,&#10;        &quot;elo_rank_mismatch&quot;: 0&#10;    })&#10;&#10;    # features de tiers&#10;    def get_tier(elo):&#10;        if elo &lt; 1400: return 0&#10;        elif elo &lt; 1600: return 1&#10;        elif elo &lt; 1800: return 2&#10;        elif elo &lt; 2000: return 3&#10;        else: return 4&#10;&#10;    tier1 = get_tier(elo1)&#10;    tier2 = get_tier(elo2)&#10;    features_dict.update({&#10;        &quot;elo_tier_winner&quot;: tier1,&#10;        &quot;elo_tier_loser&quot;: tier2,&#10;        &quot;tier_diff&quot;: tier1 - tier2&#10;    })&#10;&#10;    # features de competitividad&#10;    features_dict[&quot;match_competitiveness&quot;] = 1 / (1 + abs(elo_diff) / 100)&#10;    features_dict[&quot;is_upset_potential&quot;] = int(abs(elo_diff) &gt; 150)&#10;&#10;    # features h2h logarítmicas&#10;    h2h_count = h2h_data[&quot;count&quot;]&#10;    features_dict[&quot;h2h_count&quot;] = np.log1p(h2h_count)&#10;&#10;    if h2h_count == 0:&#10;        features_dict[&quot;h2h_balance&quot;] = 0&#10;    else:&#10;        winner_wins = h2h_data[&quot;winner_wins&quot;]&#10;        loser_wins = h2h_count - winner_wins&#10;&#10;        # determinar quién es quién en el historial&#10;        if player1 == min(pair):  # player1 es el primero alfabéticamente&#10;            p1_wins = winner_wins&#10;            p2_wins = loser_wins&#10;        else:&#10;            p1_wins = loser_wins&#10;            p2_wins = winner_wins&#10;&#10;        features_dict[&quot;h2h_balance&quot;] = np.log1p(p1_wins) - np.log1p(p2_wins)&#10;&#10;    # crear dataframe con las features y predecir&#10;    feature_values = [features_dict.get(col, 0) for col in feature_cols]&#10;    X = pd.DataFrame([feature_values], columns=feature_cols)&#10;&#10;    # predecir probabilidad de que player1 gane&#10;    prob_player1_wins = model.predict_proba(X)[0][1]&#10;    &#10;    # debug: imprimir información solo para algunos casos extremos&#10;    if prob_player1_wins &gt; 0.99 or prob_player1_wins &lt; 0.01:&#10;        print(f&quot;    DEBUG - {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f})&quot;)&#10;        print(f&quot;    ELO diff: {elo_diff:.0f}, Surface ELO diff: {surface_elo_diff:.0f}&quot;)&#10;        print(f&quot;    ELO advantage: {features_dict['elo_advantage']}, Tier diff: {features_dict['tier_diff']}&quot;)&#10;        print(f&quot;    H2H count: {h2h_count}, H2H balance: {features_dict['h2h_balance']:.3f}&quot;)&#10;        print(f&quot;    Raw probability: {prob_player1_wins:.6f}&quot;)&#10;&#10;    # determinar ganador basado en probabilidad&#10;    if prob_player1_wins &gt; 0.5:&#10;        return player1, player2, prob_player1_wins&#10;    else:&#10;        return player2, player1, 1 - prob_player1_wins&#10;&#10;def simulate_tournament_round(matches_df, model, feature_cols, round_name):&#10;    &quot;&quot;&quot;simula una ronda completa del torneo&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # predecir ganador&#10;        winner, loser, confidence = predict_match_winner(match_df, model, feature_cols)&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{match['winner_name']} vs {match['loser_name']}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence&#10;        }&#10;        results.append(result)&#10;&#10;        print(f&quot;  {match['winner_name']} vs {match['loser_name']} → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def simulate_tournament_round_with_history(matches_df, model, feature_cols, round_name,&#10;                                         current_elos, current_surface_elos, current_h2h):&#10;    &quot;&quot;&quot;simula una ronda completa usando historial actualizado&quot;&quot;&quot;&#10;&#10;    print(f&quot;\n--- simulando {round_name} ---&quot;)&#10;    winners = []&#10;    results = []&#10;&#10;    for i, (_, match) in enumerate(matches_df.iterrows()):&#10;        # crear dataframe de un solo partido&#10;        match_df = pd.DataFrame([match])&#10;&#10;        # obtener elos actuales para mostrar&#10;        player1 = match['winner_name']&#10;        player2 = match['loser_name']&#10;        elo1 = current_elos.get(player1, 1500)&#10;        elo2 = current_elos.get(player2, 1500)&#10;&#10;        # predecir ganador usando historial&#10;        winner, loser, confidence = predict_match_winner_with_history(&#10;            match_df, model, feature_cols, current_elos, current_surface_elos, current_h2h&#10;        )&#10;&#10;        winners.append(winner)&#10;        result = {&#10;            &quot;round&quot;: round_name,&#10;            &quot;match&quot;: f&quot;{player1} vs {player2}&quot;,&#10;            &quot;winner&quot;: winner,&#10;            &quot;loser&quot;: loser,&#10;            &quot;confidence&quot;: confidence,&#10;            &quot;elo_player1&quot;: elo1,&#10;            &quot;elo_player2&quot;: elo2&#10;        }&#10;        results.append(result)&#10;&#10;        # actualizar elos y h2h después del partido&#10;        surface = match[&quot;surface&quot;]&#10;        update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos)&#10;        update_h2h_after_match(winner, loser, current_h2h)&#10;&#10;        print(f&quot;  {player1} ({elo1:.0f}) vs {player2} ({elo2:.0f}) → {winner} ({confidence:.3f})&quot;)&#10;&#10;    return winners, results&#10;&#10;def create_next_round_matches(winners, round_name):&#10;    &quot;&quot;&quot;crea los emparejamientos de la siguiente ronda&quot;&quot;&quot;&#10;&#10;    if len(winners) % 2 != 0:&#10;        raise ValueError(f&quot;número impar de ganadores: {len(winners)}&quot;)&#10;&#10;    matches = []&#10;    for i in range(0, len(winners), 2):&#10;        match = {&#10;            &quot;tourney_id&quot;: &quot;2025-AO&quot;,&#10;            &quot;tourney_name&quot;: &quot;Australian Open&quot;,&#10;            &quot;surface&quot;: &quot;Hard&quot;,&#10;            &quot;draw_size&quot;: 128,&#10;            &quot;tourney_level&quot;: &quot;G&quot;,&#10;            &quot;tourney_date&quot;: 20250113,&#10;            &quot;match_num&quot;: i//2 + 1,&#10;            &quot;winner_name&quot;: winners[i],&#10;            &quot;loser_name&quot;: winners[i+1],&#10;            &quot;round&quot;: round_name,&#10;            &quot;best_of&quot;: 5&#10;        }&#10;&#10;        # columnas requeridas con valores por defecto&#10;        for col in [&quot;winner_id&quot;, &quot;winner_seed&quot;, &quot;winner_hand&quot;, &quot;winner_ht&quot;, &quot;winner_ioc&quot;, &quot;winner_age&quot;,&#10;                   &quot;loser_id&quot;, &quot;loser_seed&quot;, &quot;loser_hand&quot;, &quot;loser_ht&quot;, &quot;loser_ioc&quot;, &quot;loser_age&quot;,&#10;                   &quot;w_ace&quot;, &quot;w_df&quot;, &quot;w_svpt&quot;, &quot;w_1stIn&quot;, &quot;w_1stWon&quot;, &quot;w_2ndWon&quot;, &quot;w_SvGms&quot;, &quot;w_bpSaved&quot;, &quot;w_bpFaced&quot;,&#10;                   &quot;l_ace&quot;, &quot;l_df&quot;, &quot;l_svpt&quot;, &quot;l_1stIn&quot;, &quot;l_1stWon&quot;, &quot;l_2ndWon&quot;, &quot;l_SvGms&quot;, &quot;l_bpSaved&quot;, &quot;l_bpFaced&quot;,&#10;                   &quot;winner_rank&quot;, &quot;winner_rank_points&quot;, &quot;loser_rank&quot;, &quot;loser_rank_points&quot;, &quot;score&quot;, &quot;minutes&quot;]:&#10;            match[col] = None&#10;&#10;        matches.append(match)&#10;&#10;    return pd.DataFrame(matches)&#10;&#10;def update_elos_after_match(winner, loser, surface, current_elos, current_surface_elos, k=32):&#10;    &quot;&quot;&quot;actualiza los elos después de un partido&quot;&quot;&quot;&#10;&#10;    # elos actuales&#10;    elo_w = current_elos.get(winner, 1500)&#10;    elo_l = current_elos.get(loser, 1500)&#10;&#10;    surface_elo_w = current_surface_elos.get(f&quot;{winner}_{surface}&quot;, 1500)&#10;    surface_elo_l = current_surface_elos.get(f&quot;{loser}_{surface}&quot;, 1500)&#10;&#10;    # actualizar elo global&#10;    expected_w = 1 / (1 + 10 ** ((elo_l - elo_w) / 400))&#10;    current_elos[winner] = elo_w + k * (1 - expected_w)&#10;    current_elos[loser] = elo_l + k * (0 - (1 - expected_w))&#10;&#10;    # actualizar elo de superficie&#10;    surface_expected_w = 1 / (1 + 10 ** ((surface_elo_l - surface_elo_w) / 400))&#10;    current_surface_elos[f&quot;{winner}_{surface}&quot;] = surface_elo_w + k * (1 - surface_expected_w)&#10;    current_surface_elos[f&quot;{loser}_{surface}&quot;] = surface_elo_l + k * (0 - (1 - surface_expected_w))&#10;&#10;def update_h2h_after_match(winner, loser, current_h2h):&#10;    &quot;&quot;&quot;actualiza el historial h2h después de un partido&quot;&quot;&quot;&#10;    pair = tuple(sorted([winner, loser]))&#10;    current_h2h[pair][&quot;count&quot;] += 1&#10;&#10;    # incrementar victorias del ganador&#10;    if winner == min(pair):  # si el ganador es el primero alfabéticamente&#10;        current_h2h[pair][&quot;winner_wins&quot;] += 1&#10;&#10;def simulate_australian_open_2025():&#10;    &quot;&quot;&quot;simula el torneo completo del australian open 2025 usando datos históricos&quot;&quot;&quot;&#10;&#10;    print(&quot;=== simulador australian open 2025 con datos históricos ===&quot;)&#10;&#10;    # extraer elos y h2h históricos del dataset de entrenamiento&#10;    current_elos, current_surface_elos, current_h2h = extract_historical_elos_and_h2h()&#10;&#10;    # cargar modelo entrenado y obtener sus features exactas&#10;    model, feature_cols = load_trained_model()&#10;&#10;    print(f&quot;usando features del modelo: {feature_cols}&quot;)&#10;&#10;    # generar R32&#10;    r32_df = create_ao_2025_r32()&#10;&#10;    # simular cada ronda con historial actualizado&#10;    all_results = []&#10;&#10;    # R32 (32 → 16)&#10;    r16_winners, r32_results = simulate_tournament_round_with_history(&#10;        r32_df, model, feature_cols, &quot;R32&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r32_results)&#10;&#10;    # R16 (16 → 8)&#10;    r16_df = create_next_round_matches(r16_winners, &quot;R16&quot;)&#10;    qf_winners, r16_results = simulate_tournament_round_with_history(&#10;        r16_df, model, feature_cols, &quot;R16&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(r16_results)&#10;&#10;    # cuartos de final (8 → 4)&#10;    qf_df = create_next_round_matches(qf_winners, &quot;QF&quot;)&#10;    sf_winners, qf_results = simulate_tournament_round_with_history(&#10;        qf_df, model, feature_cols, &quot;QF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(qf_results)&#10;&#10;    # semifinales (4 → 2)&#10;    sf_df = create_next_round_matches(sf_winners, &quot;SF&quot;)&#10;    f_winners, sf_results = simulate_tournament_round_with_history(&#10;        sf_df, model, feature_cols, &quot;SF&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(sf_results)&#10;&#10;    # final (2 → 1)&#10;    f_df = create_next_round_matches(f_winners, &quot;F&quot;)&#10;    champion, f_results = simulate_tournament_round_with_history(&#10;        f_df, model, feature_cols, &quot;F&quot;, current_elos, current_surface_elos, current_h2h&#10;    )&#10;    all_results.extend(f_results)&#10;&#10;    # resultados finales&#10;    print(f&quot;\ncampeón australian open 2025: {champion[0]}&quot;)&#10;    print(f&quot;finalista: {f_results[0]['loser']}&quot;)&#10;    print(f&quot;semifinalistas: {', '.join([r['loser'] for r in sf_results])}&quot;)&#10;&#10;    # mostrar algunos elos finales de jugadores top&#10;    top_players = [&quot;Jannik Sinner&quot;, &quot;Novak Djokovic&quot;, &quot;Carlos Alcaraz&quot;, &quot;Daniil Medvedev&quot;]&#10;    print(f&quot;\nelos finales después del torneo:&quot;)&#10;    for player in top_players:&#10;        if player in current_elos:&#10;            print(f&quot;  {player}: {current_elos[player]:.0f}&quot;)&#10;&#10;    # guardar resultados&#10;    results_df = pd.DataFrame(all_results)&#10;    output_path = os.path.join(BASE_DIR, &quot;outputs&quot;, &quot;australian_open_2025_results.csv&quot;)&#10;    os.makedirs(os.path.dirname(output_path), exist_ok=True)&#10;    results_df.to_csv(output_path, index=False)&#10;&#10;    print(f&quot;\nresultados guardados en: {output_path}&quot;)&#10;&#10;    return results_df, champion[0]&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    results, champion = simulate_australian_open_2025()&#10;    print(f&quot;\n simulación completada - campeón: {champion}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/generate_features_ausopen2025.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/generate_features_ausopen2025.py" />
              <option name="originalContent" value="import pandas as pd&#10;import os&#10;import json&#10;from data_loader import BASE_DIR&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;def generate_ausopen_matches_dual_df():&#10;    # --- Datos de partidos (copiado de generate_2025_data.py) ---&#10;    matches_by_round = {&#10;        &quot;F&quot;: [&#10;            (&quot;26/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;SF&quot;: [&#10;            (&quot;24/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Ben Shelton&quot;),&#10;            (&quot;24/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;0 - 1&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;QF&quot;: [&#10;            (&quot;22/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;22/01/2025&quot;, &quot;Ben Shelton&quot;, &quot;3 - 1&quot;, &quot;Lorenzo Sonego&quot;),&#10;            (&quot;21/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 1&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;21/01/2025&quot;, &quot;Tommy Paul&quot;, &quot;1 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;R16&quot;: [&#10;            (&quot;20/01/2025&quot;, &quot;Alex Michelsen&quot;, &quot;0 - 3&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Gael Monfils&quot;, &quot;1 - 2&quot;, &quot;Ben Shelton&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Lorenzo Sonego&quot;, &quot;3 - 1&quot;, &quot;Learner Tien&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 1&quot;, &quot;Holger Rune&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 0&quot;, &quot;Jiri Lehecka&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Ugo Humbert&quot;, &quot;1 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Jack Draper&quot;, &quot;0 - 2&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Alejandro Davidovich Fokina&quot;, &quot;0 - 3&quot;, &quot;Tommy Paul&quot;),&#10;        ],&#10;        &quot;R32&quot;: [&#10;            (&quot;18/01/2025&quot;, &quot;Miomir Kecmanovic&quot;, &quot;2 - 3&quot;, &quot;Holger Rune&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Marcos Giron&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Ben Shelton&quot;, &quot;3 - 1&quot;, &quot;Lorenzo Musetti&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Corentin Moutet&quot;, &quot;0 - 3&quot;, &quot;Learner Tien&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Lorenzo Sonego&quot;, &quot;3 - 1&quot;, &quot;Fabian Marozsan&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Francisco Cerundolo&quot;, &quot;1 - 3&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Taylor Fritz&quot;, &quot;1 - 3&quot;, &quot;Gael Monfils&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Alex Michelsen&quot;, &quot;3 - 0&quot;, &quot;Karen Khachanov&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jack Draper&quot;, &quot;3 - 2&quot;, &quot;Aleksandar Vukic&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jiri Lehecka&quot;, &quot;3 - 0&quot;, &quot;Benjamin Bonzi&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 0&quot;, &quot;Tomas Machac&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Ugo Humbert&quot;, &quot;2 - 1&quot;, &quot;Arthur Fils&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jakub Mensik&quot;, &quot;2 - 3&quot;, &quot;Alejandro Davidovich Fokina&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jacob Fearnley&quot;, &quot;0 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Nuno Borges&quot;, &quot;1 - 3&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Roberto Carballes Baena&quot;, &quot;0 - 3&quot;, &quot;Tommy Paul&quot;),&#10;        ],&#10;        # ... puedes añadir más rondas si lo necesitas ...&#10;    }&#10;    rows = []&#10;    round_order = {'R64': 1, 'R32': 2, 'R16': 3, 'QF': 4, 'SF': 5, 'F': 6}&#10;    for rnd, matches in matches_by_round.items():&#10;        for date_str, p1, score, p2 in matches:&#10;            score_parts = score.split('-')&#10;            p1_score = int(score_parts[0].strip())&#10;            p2_score = int(score_parts[1].strip())&#10;            if p1_score &gt; p2_score:&#10;                winner, loser, final_score = p1, p2, score.replace(' ', '')&#10;            else:&#10;                winner, loser, final_score = p2, p1, f&quot;{p2_score}-{p1_score}&quot;&#10;            date_fmt = pd.to_datetime(date_str, format='%d/%m/%Y').strftime('%Y%m%d')&#10;            # Fila para el ganador&#10;            rows.append({&#10;                'tourney_id': '2025-01-580',&#10;                'tourney_name': 'Australian Open',&#10;                'surface': 'Hard',&#10;                'tourney_level': 'G',&#10;                'tourney_date': date_fmt,&#10;                'round': rnd,&#10;                'player': winner,&#10;                'opponent': loser,&#10;                'score': final_score,&#10;                'best_of': 5,&#10;                'target': 1,&#10;                '_sort_date': date_fmt,&#10;                '_sort_round': round_order[rnd],&#10;            })&#10;            # Fila para el perdedor&#10;            rows.append({&#10;                'tourney_id': '2025-01-580',&#10;                'tourney_name': 'Australian Open',&#10;                'surface': 'Hard',&#10;                'tourney_level': 'G',&#10;                'tourney_date': date_fmt,&#10;                'round': rnd,&#10;                'player': loser,&#10;                'opponent': winner,&#10;                'score': final_score,&#10;                'best_of': 5,&#10;                'target': 0,&#10;                '_sort_date': date_fmt,&#10;                '_sort_round': round_order[rnd],&#10;            })&#10;    df = pd.DataFrame(rows)&#10;    df = df.sort_values(by=['_sort_date', '_sort_round']).reset_index(drop=True)&#10;    df = df.drop(columns=['_sort_date', '_sort_round'])&#10;    return df&#10;&#10;def generate_ausopen_features():&#10;    df = generate_ausopen_matches_dual_df()&#10;    # Cargar elos y h2h&#10;    processed_data_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;)&#10;    try:&#10;        with open(os.path.join(processed_data_path, &quot;final_global_elos.json&quot;), &quot;r&quot;) as f:&#10;            initial_global_elos = json.load(f)&#10;        with open(os.path.join(processed_data_path, &quot;final_surface_elos.json&quot;), &quot;r&quot;) as f:&#10;            initial_surface_elos = json.load(f)&#10;        print(&quot;ELOs iniciales cargados desde el entrenamiento.&quot;)&#10;    except FileNotFoundError:&#10;        initial_global_elos = None&#10;        initial_surface_elos = None&#10;        print(&quot;[Aviso] No se encontraron archivos de ELO iniciales. Se usará el ELO por defecto (1500).&quot;)&#10;    h2h_path = os.path.join(processed_data_path, &quot;final_h2h.json&quot;)&#10;    try:&#10;        with open(h2h_path, &quot;r&quot;) as f:&#10;            initial_h2h = json.load(f)&#10;        print(&quot;Historial H2H inicial cargado.&quot;)&#10;    except FileNotFoundError:&#10;        initial_h2h = None&#10;        print(&quot;[Aviso] No se encontró historial H2H inicial. Se parte de cero.&quot;)&#10;    # Limpiar datos&#10;    df = clean_data(df)&#10;    # Generar features&#10;    features_df, _, _, final_h2h = add_all_features(&#10;        df,&#10;        initial_global_elos=initial_global_elos,&#10;        initial_surface_elos=initial_surface_elos,&#10;        initial_h2h=initial_h2h&#10;    )&#10;    # Guardar features (único output)&#10;    features_path = os.path.join(processed_data_path, &quot;features_ausopen2025.csv&quot;)&#10;    features_df.to_csv(features_path, index=False)&#10;    print(f&quot;Features generadas y guardadas en: {features_path}&quot;)&#10;    # Guardar historial h2h actualizado&#10;    with open(h2h_path, &quot;w&quot;) as f:&#10;        json.dump(final_h2h, f)&#10;    print(f&quot;Historial H2H actualizado guardado en: {h2h_path}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    generate_ausopen_features()&#10;" />
              <option name="updatedContent" value="import pandas as pd&#10;import os&#10;import json&#10;from data_loader import BASE_DIR&#10;from preprocess import clean_data&#10;from features import add_all_features&#10;&#10;def generate_ausopen_matches_dual_df():&#10;    # --- Datos de partidos (copiado de generate_2025_data.py) ---&#10;    matches_by_round = {&#10;        &quot;F&quot;: [&#10;            (&quot;26/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;SF&quot;: [&#10;            (&quot;24/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Ben Shelton&quot;),&#10;            (&quot;24/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;0 - 1&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;QF&quot;: [&#10;            (&quot;22/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;22/01/2025&quot;, &quot;Ben Shelton&quot;, &quot;3 - 1&quot;, &quot;Lorenzo Sonego&quot;),&#10;            (&quot;21/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 1&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;21/01/2025&quot;, &quot;Tommy Paul&quot;, &quot;1 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;        ],&#10;        &quot;R16&quot;: [&#10;            (&quot;20/01/2025&quot;, &quot;Alex Michelsen&quot;, &quot;0 - 3&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Gael Monfils&quot;, &quot;1 - 2&quot;, &quot;Ben Shelton&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Lorenzo Sonego&quot;, &quot;3 - 1&quot;, &quot;Learner Tien&quot;),&#10;            (&quot;20/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 1&quot;, &quot;Holger Rune&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 0&quot;, &quot;Jiri Lehecka&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Ugo Humbert&quot;, &quot;1 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Jack Draper&quot;, &quot;0 - 2&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;19/01/2025&quot;, &quot;Alejandro Davidovich Fokina&quot;, &quot;0 - 3&quot;, &quot;Tommy Paul&quot;),&#10;        ],&#10;        &quot;R32&quot;: [&#10;            (&quot;18/01/2025&quot;, &quot;Miomir Kecmanovic&quot;, &quot;2 - 3&quot;, &quot;Holger Rune&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Jannik Sinner&quot;, &quot;3 - 0&quot;, &quot;Marcos Giron&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Ben Shelton&quot;, &quot;3 - 1&quot;, &quot;Lorenzo Musetti&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Corentin Moutet&quot;, &quot;0 - 3&quot;, &quot;Learner Tien&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Lorenzo Sonego&quot;, &quot;3 - 1&quot;, &quot;Fabian Marozsan&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Francisco Cerundolo&quot;, &quot;1 - 3&quot;, &quot;Alex De Minaur&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Taylor Fritz&quot;, &quot;1 - 3&quot;, &quot;Gael Monfils&quot;),&#10;            (&quot;18/01/2025&quot;, &quot;Alex Michelsen&quot;, &quot;3 - 0&quot;, &quot;Karen Khachanov&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jack Draper&quot;, &quot;3 - 2&quot;, &quot;Aleksandar Vukic&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jiri Lehecka&quot;, &quot;3 - 0&quot;, &quot;Benjamin Bonzi&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Novak Djokovic&quot;, &quot;3 - 0&quot;, &quot;Tomas Machac&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Ugo Humbert&quot;, &quot;2 - 1&quot;, &quot;Arthur Fils&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jakub Mensik&quot;, &quot;2 - 3&quot;, &quot;Alejandro Davidovich Fokina&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Jacob Fearnley&quot;, &quot;0 - 3&quot;, &quot;Alexander Zverev&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Nuno Borges&quot;, &quot;1 - 3&quot;, &quot;Carlos Alcaraz&quot;),&#10;            (&quot;17/01/2025&quot;, &quot;Roberto Carballes Baena&quot;, &quot;0 - 3&quot;, &quot;Tommy Paul&quot;),&#10;        ],&#10;        # ... puedes añadir más rondas si lo necesitas ...&#10;    }&#10;    rows = []&#10;    round_order = {'R64': 1, 'R32': 2, 'R16': 3, 'QF': 4, 'SF': 5, 'F': 6}&#10;    for rnd, matches in matches_by_round.items():&#10;        for date_str, p1, score, p2 in matches:&#10;            score_parts = score.split('-')&#10;            p1_score = int(score_parts[0].strip())&#10;            p2_score = int(score_parts[1].strip())&#10;            if p1_score &gt; p2_score:&#10;                winner, loser, final_score = p1, p2, score.replace(' ', '')&#10;            else:&#10;                winner, loser, final_score = p2, p1, f&quot;{p2_score}-{p1_score}&quot;&#10;            date_fmt = pd.to_datetime(date_str, format='%d/%m/%Y').strftime('%Y%m%d')&#10;            # Fila para el ganador&#10;            rows.append({&#10;                'tourney_id': '2025-01-580',&#10;                'tourney_name': 'Australian Open',&#10;                'surface': 'Hard',&#10;                'tourney_level': 'G',&#10;                'tourney_date': date_fmt,&#10;                'round': rnd,&#10;                'player': winner,&#10;                'opponent': loser,&#10;                'score': final_score,&#10;                'best_of': 5,&#10;                'target': 1,&#10;                'winner_name': winner,&#10;                'loser_name': loser,&#10;                '_sort_date': date_fmt,&#10;                '_sort_round': round_order[rnd],&#10;            })&#10;            # Fila para el perdedor&#10;            rows.append({&#10;                'tourney_id': '2025-01-580',&#10;                'tourney_name': 'Australian Open',&#10;                'surface': 'Hard',&#10;                'tourney_level': 'G',&#10;                'tourney_date': date_fmt,&#10;                'round': rnd,&#10;                'player': loser,&#10;                'opponent': winner,&#10;                'score': final_score,&#10;                'best_of': 5,&#10;                'target': 0,&#10;                'winner_name': winner,&#10;                'loser_name': loser,&#10;                '_sort_date': date_fmt,&#10;                '_sort_round': round_order[rnd],&#10;            })&#10;    df = pd.DataFrame(rows)&#10;    df = df.sort_values(by=['_sort_date', '_sort_round']).reset_index(drop=True)&#10;    df = df.drop(columns=['_sort_date', '_sort_round'])&#10;    return df&#10;&#10;def generate_ausopen_features():&#10;    df = generate_ausopen_matches_dual_df()&#10;    # Cargar elos y h2h&#10;    processed_data_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;)&#10;    try:&#10;        with open(os.path.join(processed_data_path, &quot;final_global_elos.json&quot;), &quot;r&quot;) as f:&#10;            initial_global_elos = json.load(f)&#10;        with open(os.path.join(processed_data_path, &quot;final_surface_elos.json&quot;), &quot;r&quot;) as f:&#10;            initial_surface_elos = json.load(f)&#10;        print(&quot;ELOs iniciales cargados desde el entrenamiento.&quot;)&#10;    except FileNotFoundError:&#10;        initial_global_elos = None&#10;        initial_surface_elos = None&#10;        print(&quot;[Aviso] No se encontraron archivos de ELO iniciales. Se usará el ELO por defecto (1500).&quot;)&#10;    h2h_path = os.path.join(processed_data_path, &quot;final_h2h.json&quot;)&#10;    try:&#10;        with open(h2h_path, &quot;r&quot;) as f:&#10;            initial_h2h = json.load(f)&#10;        print(&quot;Historial H2H inicial cargado.&quot;)&#10;    except FileNotFoundError:&#10;        initial_h2h = None&#10;        print(&quot;[Aviso] No se encontró historial H2H inicial. Se parte de cero.&quot;)&#10;    # Limpiar datos&#10;    df = clean_data(df)&#10;    # Generar features&#10;    features_df, _, _, final_h2h = add_all_features(&#10;        df,&#10;        initial_global_elos=initial_global_elos,&#10;        initial_surface_elos=initial_surface_elos,&#10;        initial_h2h=initial_h2h&#10;    )&#10;    # Guardar features (único output)&#10;    features_path = os.path.join(processed_data_path, &quot;features_ausopen2025.csv&quot;)&#10;    features_df.to_csv(features_path, index=False)&#10;    print(f&quot;Features generadas y guardadas en: {features_path}&quot;)&#10;    # Guardar historial h2h actualizado&#10;    with open(h2h_path, &quot;w&quot;) as f:&#10;        json.dump(final_h2h, f)&#10;    print(f&quot;Historial H2H actualizado guardado en: {h2h_path}&quot;)&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    generate_ausopen_features()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/generate_features_test_with_target.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/generate_features_test_with_target.py" />
              <option name="updatedContent" value="# src/generate_features_test_with_target.py&#10;import pandas as pd&#10;import os&#10;from data_loader import BASE_DIR&#10;from utils import make_dual_rows&#10;&#10;# Cargar el archivo de features ya generadas (sin target)&#10;features_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_test.csv&quot;)&#10;df = pd.read_csv(features_path)&#10;&#10;# Aplicar make_dual_rows para añadir la columna target&#10;print(&quot;Generando dataset balanceado con columna target...&quot;)&#10;df_balanced = make_dual_rows(df)&#10;&#10;# Guardar el nuevo archivo con la columna target&#10;output_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_test_with_target.csv&quot;)&#10;df_balanced.to_csv(output_path, index=False)&#10;print(f&quot;Archivo guardado en: {output_path}&quot;)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/test_without_h2h.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/test_without_h2h.py" />
              <option name="updatedContent" value="import pandas as pd&#10;import os&#10;from sklearn.metrics import accuracy_score&#10;from xgboost import XGBClassifier&#10;from data_loader import BASE_DIR&#10;&#10;# Cargar datos existentes&#10;features_train_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_train.csv&quot;)&#10;features_test_path = os.path.join(BASE_DIR, &quot;data&quot;, &quot;processed&quot;, &quot;features_test.csv&quot;)&#10;&#10;def make_dual_rows(df):&#10;    df1 = df.copy()&#10;    df1[&quot;target&quot;] = 1&#10;&#10;    df2 = df.copy()&#10;    df2[&quot;target&quot;] = 0&#10;    for col in [&quot;elo_winner&quot;, &quot;elo_loser&quot;, &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;]:&#10;        tmp = df2[col.replace(&quot;winner&quot;, &quot;loser&quot;)]&#10;        df2[col.replace(&quot;winner&quot;, &quot;loser&quot;)] = df2[col]&#10;        df2[col] = tmp&#10;    return pd.concat([df1, df2], ignore_index=True)&#10;&#10;# Cargar datos&#10;df_train = pd.read_csv(features_train_path)&#10;df_test = pd.read_csv(features_test_path)&#10;&#10;df_train = make_dual_rows(df_train)&#10;df_test[&quot;target&quot;] = 1&#10;&#10;# SOLO usar ELO ratings, sin H2H&#10;feature_cols = [&#10;    &quot;elo_winner&quot;, &quot;elo_loser&quot;,&#10;    &quot;surface_elo_winner&quot;, &quot;surface_elo_loser&quot;&#10;]&#10;&#10;print(&quot; Entrenando modelo SIN features H2H...&quot;)&#10;&#10;X_train = df_train[feature_cols]&#10;y_train = df_train[&quot;target&quot;]&#10;X_test = df_test[feature_cols]&#10;y_test = df_test[&quot;target&quot;]&#10;&#10;model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')&#10;model.fit(X_train, y_train)&#10;&#10;y_pred = model.predict(X_test)&#10;test_acc = accuracy_score(y_test, y_pred)&#10;print(f&quot; Accuracy en test (SOLO ELO): {test_acc:.4f}&quot;)&#10;&#10;# Mostrar importancia de features&#10;importances = model.feature_importances_&#10;feature_importance_df = pd.DataFrame({&#10;    'Feature': feature_cols,&#10;    'Importance': importances&#10;}).sort_values('Importance', ascending=False)&#10;&#10;print(&quot;\n Importancia de features (solo ELO):&quot;)&#10;print(feature_importance_df)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>